<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 100%;
                 background-color: #1a1a2e;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             
             #loadingBar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width: 100%;
                 height: 100%;
                 background-color:rgba(200,200,200,0.8);
                 -webkit-transition: all 0.5s ease;
                 -moz-transition: all 0.5s ease;
                 -ms-transition: all 0.5s ease;
                 -o-transition: all 0.5s ease;
                 transition: all 0.5s ease;
                 opacity:1;
             }

             #bar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width:20px;
                 height:20px;
                 margin:auto auto auto auto;
                 border-radius:11px;
                 border:2px solid rgba(30,30,30,0.05);
                 background: rgb(0, 173, 246); /* Old browsers */
                 box-shadow: 2px 0px 4px rgba(0,0,0,0.4);
             }

             #border {
                 position:absolute;
                 top:10px;
                 left:10px;
                 width:500px;
                 height:23px;
                 margin:auto auto auto auto;
                 box-shadow: 0px 0px 4px rgba(0,0,0,0.2);
                 border-radius:10px;
             }

             #text {
                 position:absolute;
                 top:8px;
                 left:530px;
                 width:30px;
                 height:50px;
                 margin:auto auto auto auto;
                 font-size:22px;
                 color: #000000;
             }

             div.outerBorder {
                 position:relative;
                 top:400px;
                 width:600px;
                 height:44px;
                 margin:auto auto auto auto;
                 border:8px solid rgba(0,0,0,0.1);
                 background: rgb(252,252,252); /* Old browsers */
                 background: -moz-linear-gradient(top,  rgba(252,252,252,1) 0%, rgba(237,237,237,1) 100%); /* FF3.6+ */
                 background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(252,252,252,1)), color-stop(100%,rgba(237,237,237,1))); /* Chrome,Safari4+ */
                 background: -webkit-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Chrome10+,Safari5.1+ */
                 background: -o-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Opera 11.10+ */
                 background: -ms-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* IE10+ */
                 background: linear-gradient(to bottom,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* W3C */
                 filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#fcfcfc', endColorstr='#ededed',GradientType=0 ); /* IE6-9 */
                 border-radius:72px;
                 box-shadow: 0px 0px 10px rgba(0,0,0,0.2);
             }
             

             

             
        </style>
    <style>html, body { height: 100%; margin: 0; padding: 0; overflow: hidden; } .card { height: 100%; }</style>
</head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
            <div id="loadingBar">
              <div class="outerBorder">
                <div id="text">0%</div>
                <div id="border">
                  <div id="bar"></div>
                </div>
              </div>
            </div>
        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"aliases": "transformer architecture, transformer language models", "borderWidth": 2.0, "color": {"background": "#42A5F5", "border": "#e86262", "highlight": {"background": "#42A5F5", "border": "#e86262"}}, "community": "Attention Mechanisms and Vision Models", "description": "The Transformer model, introduced by a team from Google Brain including Ashish Vaswani, Noam Shazeer, and Niki Parmar, revolutionized sequence transduction by relying solely on attention mechanisms. This architecture, first detailed in the 2017 paper \"Attention is All You Need,\" demonstrated superior performance in machine translation tasks, notably outperforming previous models in English-to-German and English-to-French translation tasks. The Transformer uses multi-head attention and self-attention methods, allowing for significant parallelization and achieving state-of-the-art translation quality with reduced training time.\n\nThe Transformer architecture has been widely adopted in natural language processing and computer vision, with models like BERT and GPT-2 extending its capabilities. BERT, for instance, employs a multi-layer bidirectional Transformer encoder, enhancing its ability to model various downstream tasks. Similarly, GPT-2, associated with empirical scaling laws, leverages the Transformer architecture to improve language model expressiveness and efficiency.\n\nInnovations such as FlashAttention have been developed to enhance the efficiency of Transformer models, enabling them to handle longer contexts effectively. This algorithm offers significant performance improvements, including faster training times and better model quality. The Transformer model\u0027s scalability has been further explored in works like the Vision Transformer, which applies the architecture to image recognition tasks, demonstrating its versatility across different domains.\n\nOverall, the Transformer model\u0027s introduction marked a significant shift in how sequence transduction tasks are approached, with its reliance on attention mechanisms paving the way for numerous advancements in both natural language processing and computer vision.", "entity_type": "THEORY", "font": {"color": "#e0e0e0"}, "full_name": "Transformer", "id": "theory:transformer", "label": "Transformer", "node_degree": 45, "shape": "dot", "size": 50, "title": "Transformer\nType: THEORY\nConnections: 45\nCommunity: Attention Mechanisms and Vision Models\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017, 02_bert_2018, 03_gpt2_2019\ndescription: an architecture for building language models\naliases: [\u0027transformer architecture\u0027, \u0027transformer language models\u0027]", "x": 1049.7587741271304, "y": 248.5529280367383}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "machine translation", "id": "phenomenon:machine_translation", "label": "machine translation", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "machine translation\nType: PHENOMENON\nConnections: 1\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017", "x": -135.60196335968894, "y": 98.47982276010396}, {"aliases": "BLEU scores", "borderWidth": 2.0, "color": {"background": "#FFA726", "border": "#e86262", "highlight": {"background": "#FFA726", "border": "#e86262"}}, "community": "Attention Mechanisms and Vision Models", "description": "The BLEU metric evaluates the quality of text generated by models, specifically in translation tasks. It supported the Transformer model by demonstrating a score of 28.4 on the WMT 2014 English-to-German translation task, indicating its effectiveness in assessing translation quality. The metric is mentioned in the 2017 paper \"Attention is All You Need,\" which highlights its role in achieving state-of-the-art results while improving training efficiency. Additionally, BLEU scores were used to validate the performance of Low-Rank Adaptation (LoRA) in the E2E NLG Challenge, showcasing its utility in various natural language generation contexts.", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "BLEU", "id": "finding:bleu", "label": "BLEU", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "BLEU\nType: FINDING\nConnections: 3\nCommunity: Attention Mechanisms and Vision Models\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017, 07_lora_2021\nscore: 28.4\ntask: WMT 2014 English-to-German translation\ndescription: A metric for evaluating the quality of text generated by models.\naliases: [\u0027BLEU scores\u0027]", "x": 1399.408476745767, "y": -24.174624869752904}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Ashish Vaswani", "id": "researcher:ashish_vaswani", "label": "Ashish Vaswani", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Ashish Vaswani\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017\nrole: designed and implemented the first Transformer models", "x": -185.31215735357299, "y": 128.45163218390235}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#e86262", "highlight": {"background": "#AB47BC", "border": "#e86262"}}, "community": "Attention Mechanisms and Vision Models", "description": "Noam Shazeer proposed the concepts of scaled dot-product attention and multi-head attention, which are foundational components of the Transformer architecture. He co-authored the influential research paper \"Attention Is All You Need\" in 2017, alongside a team from Google Brain and Google Research. This paper introduced the Transformer model, which has significantly impacted the field of machine learning and natural language processing.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Noam Shazeer", "id": "researcher:noam_shazeer", "label": "Noam Shazeer", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Noam Shazeer\nType: RESEARCHER\nConnections: 2\nCommunity: Attention Mechanisms and Vision Models\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017\nrole: proposed scaled dot-product attention and multi-head attention", "x": 1135.510442269605, "y": -162.3160771301842}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Jakob Uszkoreit", "id": "researcher:jakob_uszkoreit", "label": "Jakob Uszkoreit", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Jakob Uszkoreit\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017\nrole: proposed replacing RNNs with self-attention", "x": -7.573035137005633, "y": 108.27004869328147}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "tensor2tensor", "id": "system:tensor2tensor", "label": "tensor2tensor", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "tensor2tensor\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017\ndescription: A library for training and serving machine learning models.", "x": 100.62243750163043, "y": 38.74334188676437}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#e86262", "highlight": {"background": "#EF5350", "border": "#e86262"}}, "community": "Attention Mechanisms and Vision Models", "description": "Noam Shazeer proposed multi-head attention, an attention mechanism that enables models to jointly attend to information from different representation subspaces at various positions. This concept was first introduced in the 2017 paper \"Attention Is All You Need.\" Multi-head attention consists of several attention layers running in parallel, allowing for a more nuanced and comprehensive analysis of input data.\n\nThe Transformer architecture, which employs multi-head attention in three distinct ways, uses this mechanism to explain its ability to process sequences efficiently. Multi-head attention extends the concept of self-attention by linearly projecting queries, keys, and values multiple times with different learned linear projections. This extension enhances the model\u0027s capacity to capture diverse patterns and relationships within the data.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "multi-head attention", "id": "concept:multi_head_attention", "label": "multi-head attention", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "multi-head attention\nType: CONCEPT\nConnections: 3\nCommunity: Attention Mechanisms and Vision Models\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017\ndescription: An attention mechanism that allows the model to jointly attend to information from different representation subspaces at different positions.", "x": 1442.214170891013, "y": -138.0093672166528}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#e86262", "highlight": {"background": "#EF5350", "border": "#e86262"}}, "community": "Attention Mechanisms and Vision Models", "description": "Jakob Uszkoreit proposed replacing recurrent neural networks (RNNs) with self-attention, initiating efforts to evaluate this innovative idea. Self-attention, also known as intra-attention, is an attention mechanism that relates different positions within a single sequence, where all keys, values, and queries originate from the same source. This mechanism is crucial in the encoder architecture, which contains self-attention layers.\n\nThe concept of self-attention extends to multi-head attention, where it is beneficial to linearly project the queries, keys, and values multiple times with different, learned linear projections. The Transformer model, which utilizes self-attention, allows for significantly more parallelization and achieves a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "self-attention", "id": "concept:self_attention", "label": "self-attention", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "self-attention\nType: CONCEPT\nConnections: 3\nCommunity: Attention Mechanisms and Vision Models\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017\ndescription: An attention mechanism where all keys, values, and queries come from the same place.", "x": 1013.2176003499208, "y": 49.780336902743954}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "WMT 2014 English-German dataset", "id": "system:wmt_2014_english_german_dataset", "label": "WMT 2014 English-German dataset", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "WMT 2014 English-German dataset\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017\ndescription: A dataset consisting of about 4.5 million sentence pairs used for training.", "x": 228.79366736233771, "y": 165.24484517953283}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Niki Parmar", "id": "researcher:niki_parmar", "label": "Niki Parmar", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Niki Parmar\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017\nrole: Author of the paper.", "x": -172.49480523086174, "y": 98.36834832641193}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "WMT 2014 English-French dataset", "id": "system:wmt_2014_english_french_dataset", "label": "WMT 2014 English-French dataset", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "WMT 2014 English-French dataset\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017\ndescription: dataset consisting of 36M sentences for English-French translation", "x": -201.53363320674134, "y": -37.84671372404301}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "English-to-German translation task", "id": "phenomenon:english_to_german_translation_task", "label": "English-to-German translation task", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "English-to-German translation task\nType: PHENOMENON\nConnections: 1\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017\ndescription: a specific task for evaluating the performance of translation models", "x": -17.899364826684035, "y": 52.107338542447394}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "English-to-French translation task", "id": "phenomenon:english_to_french_translation_task", "label": "English-to-French translation task", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "English-to-French translation task\nType: PHENOMENON\nConnections: 1\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017\ndescription: a specific task for evaluating the performance of translation models", "x": -174.15246536545592, "y": -110.08414353422546}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Wall Street Journal portion of the Penn Treebank", "id": "system:wall_street_journal_portion_of_the_penn_treebank", "label": "Wall Street Journal portion of the Penn Treebank", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Wall Street Journal portion of the Penn Treebank\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017\ndescription: a dataset used for training the model on English constituency parsing", "x": 91.17205762202502, "y": -163.6418533518374}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "multi-headed self-attention", "id": "method:multi_headed_self_attention", "label": "multi-headed self-attention", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "multi-headed self-attention\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017\ndescription: a mechanism used in the Transformer architecture", "x": -31.135651580552917, "y": 99.21335841553508}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "dropout", "id": "method:dropout", "label": "dropout", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "dropout\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017\ndescription: a regularization technique used during training", "x": 209.8962017855058, "y": 113.77982531500987}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "beam search", "id": "method:beam_search", "label": "beam search", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "beam search\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017\ndescription: a search algorithm used during inference", "x": -161.4656965917119, "y": -1.5852282421489576}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "state-of-the-art", "id": "finding:state_of_the_art", "label": "state-of-the-art", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "state-of-the-art\nType: FINDING\nConnections: 1\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017\ndescription: the highest level of performance achieved in a specific task", "x": -117.54224946861552, "y": 31.867129784275505}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Google Brain", "id": "researcher:google_brain", "label": "Google Brain", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Google Brain\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 01_attention_is_all_you_need_2017\nrole: Research team", "x": 155.23074300215683, "y": 229.977422013521}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#62e889", "highlight": {"background": "#26C6DA", "border": "#62e889"}}, "community": "BERT and Language Model Fine-Tuning", "description": "BERT, or Bidirectional Encoder Representations from Transformers, emerged in 2018 as a groundbreaking language representation model developed by Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova at Google AI Language. This system introduced a new paradigm in natural language processing by utilizing deep bidirectional representations, which contradicted the limitations of previous unidirectional models. BERT\u0027s architecture, a multi-layer bidirectional Transformer encoder, employed innovative methods such as masked language modeling and next sentence prediction to enhance pre-training and fine-tuning processes.\n\nBERT\u0027s impact on the field was significant, as it advanced the state of the art for eleven NLP tasks, including question answering and language inference. It supported benchmarks like SQuAD and GLUE, outperforming existing models and setting new standards for language understanding. The system\u0027s fine-tuning capabilities were demonstrated through its performance on datasets such as SWAG, MultiNLI, and others, showcasing its versatility across various tasks.\n\nThe introduction of BERT marked a shift in the landscape of language models, extending the principles of transfer learning and deep bidirectional architectures. Its development was a collaborative effort by the authors, who proposed this system to address inefficiencies in existing models. BERT\u0027s influence is evident in its comparison to other notable models like GPT-2 and its role in setting benchmarks for future research in natural language processing.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "BERT", "id": "system:bert", "label": "BERT", "node_degree": 47, "shape": "dot", "size": 50, "title": "BERT\nType: SYSTEM\nConnections: 47\nCommunity: BERT and Language Model Fine-Tuning\nConfidence: 100%\nSources: 02_bert_2018, 03_gpt2_2019, 04_gpt3_few_shot_learners_2020\nfull_name: Bidirectional Encoder Representations from Transformers\nauthors: Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova\norganization: Google AI Language\ndescription: A language representation model developed by Google based on the Transformer architecture.", "x": 762.001339622891, "y": 567.9175679865582}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "ELMo", "id": "system:elmo", "label": "ELMo", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "ELMo\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018", "x": -88.24508703707195, "y": -214.20016800229791}, {"aliases": "GLUE Benchmark", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#62e889", "highlight": {"background": "#26C6DA", "border": "#62e889"}}, "community": "BERT and Language Model Fine-Tuning", "description": "The General Language Understanding Evaluation (GLUE) benchmark evaluates the performance of models across a diverse range of natural language understanding tasks. Researchers have applied GLUE to models like BERT, as evidenced by results obtained from the official GLUE website. BERT\u0027s performance on selected GLUE tasks is documented in various tables, indicating its effectiveness in natural language processing.\n\nGLUE has also been a focal point for investigating fine-tuning techniques, with plans to explore its application alongside other benchmarks like decaNLP. The benchmark\u0027s broad coverage makes it a standard metric for evaluating models such as RoBERTa and DeBERTa, as demonstrated by Low-Rank Adaptation\u0027s evaluation of different adaptation approaches on GLUE tasks. This benchmark continues to serve as a critical tool for assessing and improving natural language understanding models.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "GLUE", "id": "system:glue", "label": "GLUE", "node_degree": 8, "shape": "dot", "size": 26.0, "title": "GLUE\nType: SYSTEM\nConnections: 8\nCommunity: BERT and Language Model Fine-Tuning\nConfidence: 100%\nSources: 02_bert_2018, 03_gpt2_2019, 07_lora_2021\ntype: benchmark\ndescription: A benchmark for evaluating the performance of models across a diverse range of natural language understanding tasks.\naliases: [\u0027GLUE Benchmark\u0027]", "x": 1077.346748927691, "y": 1016.4754985229538}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "MultiNLI", "id": "system:multinli", "label": "MultiNLI", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "MultiNLI\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018\ntype: benchmark", "x": 55.85245765346946, "y": -184.7634287120345}, {"aliases": "Masked Language Model (MLM), Masked LM", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#62e889", "highlight": {"background": "#FFEE58", "border": "#62e889"}}, "community": "BERT and Language Model Fine-Tuning", "description": "The masked language model (MLM) method, inspired by the Cloze task, serves as a pre-training objective that randomly masks some of the tokens from the input. This approach is prominently utilized in BERT, where it alleviates the unidirectionality constraint by enabling the Transformer encoder to process input without knowing which words are masked. BERT\u0027s implementation of the MLM method demonstrates its effectiveness, as shown in Section 5.1 of the BERT paper, where pre-training with this objective significantly benefits tasks like question answering (QA) and natural language inference (NLI).", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "masked language model", "id": "method:masked_language_model", "label": "masked language model", "node_degree": 4, "shape": "dot", "size": 16.0, "title": "masked language model\nType: METHOD\nConnections: 4\nCommunity: BERT and Language Model Fine-Tuning\nConfidence: 100%\nSources: 02_bert_2018\ninspiration: Cloze task\ndescription: pre-training objective that randomly masks some of the tokens from the input\naliases: [\u0027Masked Language Model (MLM)\u0027, \u0027Masked LM\u0027]", "x": 1098.0318772105209, "y": 796.5299287520745}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#62e889", "highlight": {"background": "#FFEE58", "border": "#62e889"}}, "community": "BERT and Language Model Fine-Tuning", "description": "The next sentence prediction method pre-trains models to understand sentence relationships by using a binarized task. This task, which jointly pre-trains text-pair representations, is integral to the BERT model. BERT employs this method to enhance its performance in tasks such as question answering (QA) and natural language inference (NLI), demonstrating its utility despite its simplicity. The method\u0027s implementation in BERT involves illustrating the task through specific examples, which helps in training the model to predict the relationship between sentences effectively.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "next sentence prediction", "id": "method:next_sentence_prediction", "label": "next sentence prediction", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "next sentence prediction\nType: METHOD\nConnections: 2\nCommunity: BERT and Language Model Fine-Tuning\nConfidence: 100%\nSources: 02_bert_2018\ndescription: task that jointly pre-trains text-pair representations", "x": 742.4865090451974, "y": 736.4827466518731}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "bidirectional representations", "id": "concept:bidirectional_representations", "label": "bidirectional representations", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "bidirectional representations\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018\ndescription: representations that consider both left and right context", "x": 169.6837679142609, "y": 67.96145283688475}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "unidirectional language models", "id": "concept:unidirectional_language_models", "label": "unidirectional language models", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "unidirectional language models\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018\ndescription: language models that only consider context from one direction", "x": 206.77845767364238, "y": -175.74423127069315}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EC407A", "border": "#e862ab", "highlight": {"background": "#EC407A", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "OpenAI researchers, including Tom B. Brown, Benjamin Mann, and Ilya Sutskever, authored a paper that advanced natural language processing (NLP) by focusing on the capabilities of language models to perform various tasks. They demonstrated the effectiveness of these models in tasks such as question answering, machine translation, reading comprehension, and summarization, particularly in a zero-shot setting. The paper highlighted the importance of deep bidirectional representations, explaining how these improve the modeling of long-range dependencies in text.\n\nThe research discussed in the paper is connected to several key developments in NLP. The BERT model, mentioned in the 2018 paper, utilized bidirectional pre-training to enhance language representations, which was crucial for improving many NLP tasks. In 2019, the GPT-2 model was noted for using methods that allowed it to perform a wide range of NLP tasks effectively. By 2020, the GPT-3 model further extended these capabilities, showcasing few-shot learning abilities that significantly advanced the field. These developments collectively illustrate a timeline of progress in NLP, driven by the innovative work of the OpenAI team and their collaborators.", "entity_type": "FIELD", "font": {"color": "#e0e0e0"}, "full_name": "natural language processing", "id": "field:natural_language_processing", "label": "natural language processing", "node_degree": 4, "shape": "dot", "size": 16.0, "title": "natural language processing\nType: FIELD\nConnections: 4\nCommunity: In-Context Learning and Bias Studies\nConfidence: 100%\nSources: 02_bert_2018, 03_gpt2_2019, 04_gpt3_few_shot_learners_2020", "x": -1307.4992904579012, "y": -431.91757275773773}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Jacob Devlin", "id": "researcher:jacob_devlin", "label": "Jacob Devlin", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Jacob Devlin\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018\nrole: author", "x": -96.2459927437323, "y": 53.72645257650174}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Ming-Wei Chang", "id": "researcher:ming_wei_chang", "label": "Ming-Wei Chang", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Ming-Wei Chang\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018\nrole: author", "x": 43.36425025014967, "y": 168.7082545647462}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Kenton Lee", "id": "researcher:kenton_lee", "label": "Kenton Lee", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Kenton Lee\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018\nrole: author", "x": -182.51208484713905, "y": -191.10533878235486}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Kristina Toutanova", "id": "researcher:kristina_toutanova", "label": "Kristina Toutanova", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Kristina Toutanova\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018\nrole: author", "x": -73.89894576436623, "y": 90.20852460818242}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "BooksCorpus", "id": "system:bookscorpus", "label": "BooksCorpus", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "BooksCorpus\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018\ndescription: A dataset used for pre-training BERT, consisting of 800M words.", "x": -54.144094039300256, "y": -53.47902749371991}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "English Wikipedia", "id": "system:english_wikipedia", "label": "English Wikipedia", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "English Wikipedia\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018\ndescription: A dataset used for pre-training BERT, consisting of 2,500M words.", "x": 158.65803118380188, "y": 108.67707944379595}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Vaswani et al.", "id": "researcher:vaswani_et_al", "label": "Vaswani et al.", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Vaswani et al.\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018\ncontribution: explored the largest Transformer", "x": -86.51846844527006, "y": 131.9825579907427}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "SWAG", "id": "system:swag", "label": "SWAG", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "SWAG\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018\ndescription: Situations With Adversarial Generations dataset containing sentence-pair completion examples", "x": -97.55752866287602, "y": 128.66643827316847}, {"aliases": "SQuAD v1.1, SQuAD v2.0, SQuAD2.0", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#62e889", "highlight": {"background": "#26C6DA", "border": "#62e889"}}, "community": "BERT and Language Model Fine-Tuning", "description": "SQuAD, a public NLP dataset, evaluates question answering systems by drawing background information from Wikipedia. It is frequently assessed using the exact match metric, a common standard for reading comprehension datasets. SQuAD has been a focal point in the development and testing of various models, including BERT and GPT-2. BERT, in particular, advanced the state of the art for multiple NLP tasks by fine-tuning on SQuAD v1.1, outperforming previous systems by significant margins in F1 scores. Researchers extended the BERT model specifically for tasks involving SQuAD, demonstrating its adaptability and effectiveness.\n\nIn contrast, InstructGPT exhibited performance regressions on SQuAD v2, facing challenges in maintaining consistency across different datasets. Despite these setbacks, InstructGPT\u0027s initial RLHF experiments continued to explore improvements, although they still lagged behind GPT-3 on SQuAD and other tasks. The dataset\u0027s influence extends beyond individual models, as it has been a benchmark for evaluating the capabilities of various NLP systems, showing both advancements and areas needing further research.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "SQuAD", "id": "system:squad", "label": "SQuAD", "node_degree": 10, "shape": "dot", "size": 31.0, "title": "SQuAD\nType: SYSTEM\nConnections: 10\nCommunity: BERT and Language Model Fine-Tuning\nConfidence: 100%\nSources: 02_bert_2018, 03_gpt2_2019, 04_gpt3_few_shot_learners_2020\nversion: 1.1\ntype: dataset\ndescription: A public NLP dataset used for evaluating question answering systems.\naliases: [\u0027SQuAD v1.1\u0027, \u0027SQuAD v2.0\u0027, \u0027SQuAD2.0\u0027]", "x": 752.1655232037856, "y": 800.1988592482729}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#62e889", "highlight": {"background": "#26C6DA", "border": "#62e889"}}, "community": "BERT and Language Model Fine-Tuning", "description": "OpenAI GPT employs a Left-to-Right (LTR) pre-training method, utilizing the BooksCorpus dataset consisting of 800 million words. This approach is directly comparable to BERT\u0027s pre-training, which also uses the BooksCorpus but extends to include Wikipedia\u0027s 2,500 million words. Unlike BERT, OpenAI GPT does not incorporate the Next Sentence Prediction (NSP) task in its pre-training process. The model\u0027s methodology and dataset choices position it as a significant counterpart to BERT in the realm of pre-trained language models.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "OpenAI GPT", "id": "system:openai_gpt", "label": "OpenAI GPT", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "OpenAI GPT\nType: SYSTEM\nConnections: 2\nCommunity: BERT and Language Model Fine-Tuning\nConfidence: 100%\nSources: 02_bert_2018", "x": 1117.0076062645878, "y": 854.3132243020025}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "Transfer learning, a machine learning technique, reuses a model developed for one task as the starting point for another task. Recent empirical improvements have shown that transfer learning with language models, particularly through rich, unsupervised pre-training, is crucial for many language understanding systems. This approach has been mentioned in key works such as the 2018 BERT paper, which extended the concept by generalizing findings to deep bidirectional architectures.\n\nEfforts to enhance transfer learning have focused on making model adaptation more parameter- and compute-efficient. The Low-Rank Adaptation (LoRA) method, discussed in a 2021 paper, extends these efforts by optimizing the adaptation process. These developments underscore the ongoing evolution of transfer learning, as researchers continue to refine and expand its applications across various tasks.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "transfer learning", "id": "concept:transfer_learning", "label": "transfer learning", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "transfer learning\nType: CONCEPT\nConnections: 2\nConfidence: 100%\nSources: 02_bert_2018, 07_lora_2021\ndescription: A machine learning technique where a model developed for a particular task is reused as the starting point for a model on a second task.", "x": 83.80353994891357, "y": 185.33199087486827}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "deep bidirectional architectures", "id": "concept:deep_bidirectional_architectures", "label": "deep bidirectional architectures", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "deep bidirectional architectures\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018", "x": 54.59478273081254, "y": -150.77574673238956}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "deep bidirectional representations", "id": "concept:deep_bidirectional_representations", "label": "deep bidirectional representations", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "deep bidirectional representations\nType: CONCEPT\nConnections: 1\nConfidence: 90%\nSources: 02_bert_2018", "x": 248.27949522615745, "y": 93.869277587103}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#66BB6A", "border": "#62e889", "highlight": {"background": "#66BB6A", "border": "#62e889"}}, "community": "BERT and Language Model Fine-Tuning", "description": "BERT achieved state-of-the-art results in question answering and language inference, as documented in the 2018 paper. This model\u0027s performance on various benchmarks, including question answering, marked a significant advancement in natural language processing tasks. GPT-2, introduced in 2019, investigated question answering among other tasks, demonstrating substantial progress in this area. The model\u0027s evaluation on common tasks, such as question answering and translation, further underscored its capabilities. In 2020, GPT-3\u0027s few-shot learning approach was compared to its predecessors, with the model initially outperforming GPT-3 on the SQuAD v2 and DROP datasets, both of which investigate question answering. These developments highlight the evolving landscape of question answering systems, driven by advancements in transformer-based architectures and large-scale language models.", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "question answering", "id": "phenomenon:question_answering", "label": "question answering", "node_degree": 5, "shape": "dot", "size": 18.5, "title": "question answering\nType: PHENOMENON\nConnections: 5\nCommunity: BERT and Language Model Fine-Tuning\nConfidence: 100%\nSources: 02_bert_2018, 03_gpt2_2019, 04_gpt3_few_shot_learners_2020", "x": 910.04141563292, "y": 783.9689380824016}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "language inference", "id": "phenomenon:language_inference", "label": "language inference", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "language inference\nType: PHENOMENON\nConnections: 1\nConfidence: 80%\nSources: 02_bert_2018", "x": 41.62618273387153, "y": 134.7484723332429}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "unidirectional models", "id": "concept:unidirectional_models", "label": "unidirectional models", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "unidirectional models\nType: CONCEPT\nConnections: 1\nConfidence: 80%\nSources: 02_bert_2018", "x": 214.5102211407238, "y": -10.338872430947845}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "pre-training", "id": "method:pre_training", "label": "pre-training", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "pre-training\nType: METHOD\nConnections: 1\nConfidence: 70%\nSources: 02_bert_2018", "x": 46.670062632397844, "y": 119.82987156920547}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#62e889", "highlight": {"background": "#FFEE58", "border": "#62e889"}}, "community": "BERT and Language Model Fine-Tuning", "description": "Fine-tuning, a method for adapting models to specific tasks, is prominently utilized in systems like BERT and GPT-2. BERT employs an innovative approach to pre-training and fine-tuning, enhancing its performance on various tasks. Researchers have applied fine-tuning to benchmarks such as GLUE and decaNLP, demonstrating its adaptability and effectiveness. However, traditional fine-tuning methods face limitations, particularly concerning resource requirements. Low-Rank Adaptation (LoRA) addresses these limitations by offering a more resource-efficient solution. Additionally, fine-tuning significantly improves model performance compared to few-shot learning, as evidenced by comparative analyses on both large and small datasets.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "fine-tuning", "id": "method:fine_tuning", "label": "fine-tuning", "node_degree": 5, "shape": "dot", "size": 18.5, "title": "fine-tuning\nType: METHOD\nConnections: 5\nCommunity: BERT and Language Model Fine-Tuning\nConfidence: 80%\nSources: 02_bert_2018, 03_gpt2_2019, 07_lora_2021\ndescription: A traditional method for adapting models to specific tasks.", "x": 698.88266113808, "y": 707.4492399340393}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#62e889", "highlight": {"background": "#26C6DA", "border": "#62e889"}}, "community": "BERT and Language Model Fine-Tuning", "description": "MNLI, or Multi-Genre Natural Language Inference, functions as a large-scale, crowdsourced entailment classification task. It serves as a dataset specifically designed for evaluating natural language inference capabilities. The system is notably mentioned in the 2018 paper on BERT, where it is associated with testing the model\u0027s performance on entailment classification tasks. Additionally, MNLI is referenced in a 2021 study that evaluates combinations of LoRA and variants of prefix-tuning, indicating its continued relevance in assessing advancements in natural language processing methods.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "MNLI", "id": "system:mnli", "label": "MNLI", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "MNLI\nType: SYSTEM\nConnections: 1\nCommunity: BERT and Language Model Fine-Tuning\nConfidence: 100%\nSources: 02_bert_2018, 07_lora_2021\ndescription: A dataset used for evaluating natural language inference.", "x": 1164.4206853718827, "y": 557.4346726466642}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "QQP", "id": "system:qqp", "label": "QQP", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "QQP\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018\ndescription: Quora Question Pairs dataset", "x": 110.73444269796022, "y": 3.500229997163757}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "CoLA", "id": "system:cola", "label": "CoLA", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "CoLA\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018\ndescription: Corpus of Linguistic Acceptability", "x": -221.2107158770838, "y": 87.92199119452084}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "SST-2", "id": "system:sst_2", "label": "SST-2", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "SST-2\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018\ndescription: Stanford Sentiment Treebank", "x": -40.914056766905134, "y": -199.95892000651028}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "RTE", "id": "system:rte", "label": "RTE", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "RTE\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018\ndescription: Recognizing Textual Entailment dataset", "x": 46.450013222809844, "y": 82.19912924675413}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "STS-B", "id": "system:sts_b", "label": "STS-B", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "STS-B\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018\ndescription: Semantic Textual Similarity Benchmark", "x": 167.41247874786177, "y": 242.9599302400474}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "MRPC", "id": "system:mrpc", "label": "MRPC", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "MRPC\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018\ndescription: Microsoft Research Paraphrase Corpus", "x": -167.100363661208, "y": -228.04107930335994}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Left-to-Right (LTR) Pre-training", "id": "method:left_to_right_ltr_pre_training", "label": "Left-to-Right (LTR) Pre-training", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Left-to-Right (LTR) Pre-training\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018\ndescription: Pre-training method used in OpenAI GPT", "x": 148.67748585304048, "y": -15.338016381146446}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "bi-directionality", "id": "concept:bi_directionality", "label": "bi-directionality", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "bi-directionality\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 02_bert_2018\ndescription: Key feature of BERT that contributes to its performance", "x": -158.2368131427701, "y": 203.35363556122297}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#84e862", "highlight": {"background": "#EF5350", "border": "#84e862"}}, "community": "Language Model Pioneers and Publications", "description": "Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever authored the paper \"Language Models are Unsupervised Multitask Learners,\" which proposed a shift towards more general systems in language modeling. They utilized Multitask Learning to connect different lines of work, continuing the trend of developing more general methods of transfer. The team applied their language model to a new dataset called WebText, which comprised millions of webpages, to enhance the model\u0027s capabilities. This work was mentioned in the 2019 paper on GPT-2, highlighting its significance in the development of language models.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "Language Models", "id": "concept:language_models", "label": "Language Models", "node_degree": 9, "shape": "dot", "size": 28.5, "title": "Language Models\nType: CONCEPT\nConnections: 9\nCommunity: Language Model Pioneers and Publications\nConfidence: 90%\nSources: 03_gpt2_2019", "x": -494.3005818184594, "y": -816.4620872081596}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#84e862", "highlight": {"background": "#26C6DA", "border": "#84e862"}}, "community": "Language Model Pioneers and Publications", "description": "WebText, a dataset scraped from outbound links on Reddit, was used to train the GPT-2 language model. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever proposed this dataset to explore the capabilities of language models in performing various natural language processing tasks. The dataset comprises text from 45 million links, serving as a proxy for high-quality documents. WebText supports GPT-2 by providing a large corpus that enables the model to generate coherent paragraphs of text, reflecting improvements in language understanding.\n\nThe dataset\u0027s application extends to investigating zero-shot task transfer, where researchers aim to understand how language models trained on WebText perform without task-specific training. WebText\u0027s influence is evident in its mention in studies like \"Scaling Laws For Neural Language Models,\" which examine how model performance depends on dataset size rather than specific hyperparameters. Additionally, WebText is applied to the GPT-2 model, which uses Byte Pair Encoding as a method for processing the dataset. This approach highlights the potential for models trained on WebText to generalize across various tasks, showcasing the dataset\u0027s significance in advancing language model research.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "WebText", "id": "system:webtext", "label": "WebText", "node_degree": 13, "shape": "dot", "size": 38.5, "title": "WebText\nType: SYSTEM\nConnections: 13\nCommunity: Language Model Pioneers and Publications\nConfidence: 100%\nSources: 03_gpt2_2019, 04_gpt3_few_shot_learners_2020, 05_scaling_laws_2020\ntype: dataset\ndescription: the original dataset scraped from Reddit", "x": -358.154989508023, "y": -1266.0596907380175}, {"aliases": "gpt2-large", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e862ab", "highlight": {"background": "#26C6DA", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "GPT-2, developed by OpenAI and released in 2019, is a 1.5 billion parameter autoregressive language model that implements the Transformer architecture. It was proposed by a team including Tom B. Brown, Benjamin Mann, and Ilya Sutskever. GPT-2 achieved state-of-the-art results on several benchmarks, such as the Children\u2019s Book Test and the LAMBADA dataset, by significantly reducing perplexity. It also improved accuracy on the Winograd Schemas Challenge by 7%, achieving 70.70%.\n\nThe model employs various methods, including greedy decoding and top-k random sampling, to generate text. It supports zero-shot, one-shot, and few-shot learning, demonstrating strong performance across many natural language processing tasks without explicit supervision. GPT-2\u0027s ability to handle out-of-distribution contexts and perform unsupervised task learning marks a significant advancement in the field.\n\nGPT-2 extends earlier models like BERT by addressing the inefficiencies of uni-directional representations. It uses task-specific training and fine-tuning to enhance performance on benchmarks such as decaNLP and GLUE. The model\u0027s architecture and training methods have influenced subsequent systems, including GPT-3, which further scales up the capabilities demonstrated by GPT-2.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "GPT-2", "id": "system:gpt_2", "label": "GPT-2", "node_degree": 112, "shape": "dot", "size": 50, "title": "GPT-2\nType: SYSTEM\nConnections: 112\nCommunity: In-Context Learning and Bias Studies\nConfidence: 100%\nSources: 03_gpt2_2019, 04_gpt3_few_shot_learners_2020, 05_scaling_laws_2020\ntype: autoregressive language model\nversion: 175B\nparameters: 175B\ndescription: A large language model used for evaluation.", "x": -1202.149135599056, "y": -266.4312643363647}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#84e862", "highlight": {"background": "#EF5350", "border": "#84e862"}}, "community": "Language Model Pioneers and Publications", "description": "Multitask learning, proposed by Alec Radford and initially introduced by Caruana in 1997, serves as a framework aimed at enhancing general performance across tasks. This concept is mentioned in the context of GPT-2, a language model that utilizes multitask learning to improve its capabilities. The method connects various lines of work, continuing the trend towards more generalized methods of transfer learning.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "Multitask Learning", "id": "concept:multitask_learning", "label": "Multitask Learning", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Multitask Learning\nType: CONCEPT\nConnections: 2\nCommunity: Language Model Pioneers and Publications\nConfidence: 90%\nSources: 03_gpt2_2019", "x": -700.7201575707497, "y": -937.7999213261604}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "Conditional Probability", "id": "concept:conditional_probability", "label": "Conditional Probability", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Conditional Probability\nType: CONCEPT\nConnections: 1\nConfidence: 80%\nSources: 03_gpt2_2019", "x": 26.524877642471097, "y": -67.71328165555758}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#84e862", "highlight": {"background": "#AB47BC", "border": "#84e862"}}, "community": "Language Model Pioneers and Publications", "description": "Alec Radford developed the optimized Transformer implementation alongside Tom Brown, Rewon Child, and Scott Gray. He authored the research paper titled \"Language Models are Unsupervised Multitask Learners,\" which explored the capabilities of language models in performing various natural language processing tasks. Radford demonstrated that few-shot learning occurs in language models, showcasing their potential in multitask learning. His contributions to the field include proposing the use of WebText for language model training, further advancing the understanding and application of language models in AI research.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Alec Radford", "id": "researcher:alec_radford", "label": "Alec Radford", "node_degree": 5, "shape": "dot", "size": 18.5, "title": "Alec Radford\nType: RESEARCHER\nConnections: 5\nCommunity: Language Model Pioneers and Publications\nConfidence: 100%\nSources: 03_gpt2_2019, 05_scaling_laws_2020\nrole: contributor", "x": -559.4244745727025, "y": -1142.7210811668351}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#84e862", "highlight": {"background": "#AB47BC", "border": "#84e862"}}, "community": "Language Model Pioneers and Publications", "description": "Jeffrey Wu authored a paper discussing the capabilities of language models, particularly focusing on their ability to perform various natural language processing tasks. His work is mentioned in connection with the 2019 paper on GPT-2, a significant development in the field of artificial intelligence. Wu\u0027s contributions include proposing the use of WebText, a dataset that enhances the performance of language models in understanding and generating human-like text.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Jeffrey Wu", "id": "researcher:jeffrey_wu", "label": "Jeffrey Wu", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Jeffrey Wu\nType: RESEARCHER\nConnections: 2\nCommunity: Language Model Pioneers and Publications\nConfidence: 90%\nSources: 03_gpt2_2019\nrole: author", "x": -718.7515712565405, "y": -1002.5639520662303}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#84e862", "highlight": {"background": "#AB47BC", "border": "#84e862"}}, "community": "Language Model Pioneers and Publications", "description": "Rewon Child contributed to the development of an optimized Transformer implementation alongside Tom Brown, Scott Gray, and Alec Radford. He authored papers discussing the capabilities of language models, particularly their proficiency in performing various natural language processing tasks. Child\u0027s work is mentioned in the context of significant research papers such as \"03_gpt2_2019\" and \"05_scaling_laws_2020,\" indicating his involvement in advancing the understanding and application of language models. Additionally, he proposed the use of WebText in exploring these capabilities, further demonstrating his active role in the field of artificial intelligence research.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Rewon Child", "id": "researcher:rewon_child", "label": "Rewon Child", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Rewon Child\nType: RESEARCHER\nConnections: 2\nCommunity: Language Model Pioneers and Publications\nConfidence: 100%\nSources: 03_gpt2_2019, 05_scaling_laws_2020\nrole: contributor", "x": -477.3420915805321, "y": -1090.867961254755}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#84e862", "highlight": {"background": "#AB47BC", "border": "#84e862"}}, "community": "Language Model Pioneers and Publications", "description": "David Luan authored a paper discussing the capabilities of language models, emphasizing their proficiency in executing various natural language processing tasks. His work is specifically mentioned in connection with the 2019 paper on GPT-2, a significant development in the field of artificial intelligence. Luan\u0027s contributions include proposing the use of WebText, a dataset that enhances the understanding and performance of language models. Through these efforts, he has played a crucial role in advancing the capabilities of language models in processing and understanding human language.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "David Luan", "id": "researcher:david_luan", "label": "David Luan", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "David Luan\nType: RESEARCHER\nConnections: 2\nCommunity: Language Model Pioneers and Publications\nConfidence: 90%\nSources: 03_gpt2_2019\nrole: author", "x": -500.1738026268047, "y": -1149.8738473497438}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#84e862", "highlight": {"background": "#AB47BC", "border": "#84e862"}}, "community": "Language Model Pioneers and Publications", "description": "Dario Amodei authored papers that explored the capabilities of language models, focusing on their ability to perform various natural language processing tasks. He provided guidance throughout projects that examined the scaling laws of AI models. His work is mentioned in significant research documents such as the 2019 GPT-2 paper and the 2020 scaling laws paper. Amodei\u0027s contributions include proposing the use of WebText to enhance language model capabilities.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Dario Amodei", "id": "researcher:dario_amodei", "label": "Dario Amodei", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Dario Amodei\nType: RESEARCHER\nConnections: 2\nCommunity: Language Model Pioneers and Publications\nConfidence: 100%\nSources: 03_gpt2_2019, 05_scaling_laws_2020\nrole: guidance", "x": -486.188718662343, "y": -1227.11684566105}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#84e862", "highlight": {"background": "#AB47BC", "border": "#84e862"}}, "community": "Language Model Pioneers and Publications", "description": "Ilya Sutskever advocated for scaling large generative likelihood models and co-authored significant research papers at OpenAI. He contributed to the development of GPT-2, a language model capable of performing various natural language processing tasks. Sutskever\u0027s work on GPT-2, alongside other key contributors at OpenAI, demonstrated the potential of language models to handle diverse tasks, showcasing their capabilities in natural language understanding. Additionally, he was involved in proposing the use of WebText, further advancing the field of language models.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Ilya Sutskever", "id": "researcher:ilya_sutskever", "label": "Ilya Sutskever", "node_degree": 4, "shape": "dot", "size": 16.0, "title": "Ilya Sutskever\nType: RESEARCHER\nConnections: 4\nCommunity: Language Model Pioneers and Publications\nConfidence: 100%\nSources: 03_gpt2_2019, 04_gpt3_few_shot_learners_2020\nrole: co-author", "x": -794.0977330948881, "y": -1089.8924137626727}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Byte Pair Encoding", "id": "method:byte_pair_encoding", "label": "Byte Pair Encoding", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Byte Pair Encoding\nType: METHOD\nConnections: 1\nConfidence: 80%\nSources: 03_gpt2_2019\ndescription: A method for tokenizing text that effectively interpolates between character and word level language modeling.", "x": 96.17343040768196, "y": -183.4089012018244}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "zero-shot task transfer", "id": "phenomenon:zero_shot_task_transfer", "label": "zero-shot task transfer", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "zero-shot task transfer\nType: PHENOMENON\nConnections: 1\nConfidence: 80%\nSources: 03_gpt2_2019\ndescription: The ability of a model to perform tasks it has not been explicitly trained on.", "x": -152.9182261844162, "y": -118.77349860174263}, {"aliases": "CommonCrawl", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e862ab", "highlight": {"background": "#26C6DA", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "Common Crawl, a dataset sourced from web data, constitutes nearly a trillion words and serves as a critical resource for training language models. It was notably applied in the development of GPT-2, where the dataset and model size were about two orders of magnitude larger than previous iterations, incorporating a substantial amount of Common Crawl data. Researchers employed techniques to enhance the quality of this dataset, acknowledging its potential as a diverse and nearly unlimited text source. Despite these efforts, biases were expected to persist from Common Crawl, even after multiple filtering steps. The dataset\u0027s influence extended to the training of LLaMA, which followed methods inspired by the Chinchilla scaling laws.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Common Crawl", "id": "system:common_crawl", "label": "Common Crawl", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "Common Crawl\nType: SYSTEM\nConnections: 3\nCommunity: In-Context Learning and Bias Studies\nConfidence: 100%\nSources: 03_gpt2_2019, 04_gpt3_few_shot_learners_2020, 11_llama_2023\ndescription: A dataset used for training language models, sourced from web data.\ntype: dataset\naliases: [\u0027CommonCrawl\u0027]", "x": -997.4849708385868, "y": -252.23920242287392}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e862ab", "highlight": {"background": "#26C6DA", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "The LAMBADA dataset tests the ability of systems to model long-range dependencies in text. It appeared to have substantial genuine contamination, which may affect its reliability as a benchmark. LAMBADA\u0027s accuracy was reported by Hoang et al. in 2018, while its perplexity was documented by Grave et al. in 2016. The dataset is mentioned in the context of GPT-2 and GPT-3 research, where GPT-2 improved the state of the art from 99.8 to 8.6 perplexity on LAMBADA. Additionally, LAMBADA demonstrates the flexibility of few-shot learning, showcasing its relevance in evaluating advanced language models.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "LAMBADA", "id": "system:lambada", "label": "LAMBADA", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "LAMBADA\nType: SYSTEM\nConnections: 2\nCommunity: In-Context Learning and Bias Studies\nConfidence: 100%\nSources: 03_gpt2_2019, 04_gpt3_few_shot_learners_2020\ndescription: A dataset that tests the modeling of long-range dependencies in text.", "x": -1303.1339392303432, "y": -253.30266950087457}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e862ab", "highlight": {"background": "#26C6DA", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "The Children\u2019s Book Test (CBT) was created to evaluate the performance of language models on various categories of words. Bajgar et al. (2016) enhanced the results on the CBT by developing a significantly larger training dataset. This benchmark, along with several other language modeling benchmarks, showed almost complete overlap in testing capabilities. GPT-2 improved the state of the art on the CBT, reducing perplexity from 99.8 to 8.6, demonstrating its effectiveness in language modeling tasks.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Children\u2019s Book Test", "id": "system:children_s_book_test", "label": "Children\u2019s Book Test", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Children\u2019s Book Test\nType: SYSTEM\nConnections: 1\nCommunity: In-Context Learning and Bias Studies\nConfidence: 100%\nSources: 03_gpt2_2019, 04_gpt3_few_shot_learners_2020\ndescription: A test designed to examine the performance of language models on different categories of words.\ntype: benchmark", "x": -1178.990613612658, "y": -171.4477768485475}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e862ab", "highlight": {"background": "#26C6DA", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "The Winograd Schemas Challenge, a task designed to evaluate a system\u0027s ability to perform commonsense reasoning, was mentioned in the context of advancements in natural language processing. GPT-2, a language model, improved the state-of-the-art accuracy on this challenge by 7%, achieving a score of 70.70%. This improvement was noted in the 2019 paper on GPT-2, highlighting its capability in handling such tasks. The challenge was also referenced in the 2020 paper on GPT-3, which explored few-shot learning capabilities.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Winograd Schemas Challenge", "id": "system:winograd_schemas_challenge", "label": "Winograd Schemas Challenge", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Winograd Schemas Challenge\nType: SYSTEM\nConnections: 1\nCommunity: In-Context Learning and Bias Studies\nConfidence: 90%\nSources: 03_gpt2_2019, 04_gpt3_few_shot_learners_2020\ndescription: A challenge constructed to measure the capability of a system to perform commonsense reasoning.\ntype: task", "x": -1301.6021093084405, "y": -405.82110518567754}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Conversation Question Answering dataset", "id": "system:conversation_question_answering_dataset", "label": "Conversation Question Answering dataset", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Conversation Question Answering dataset\nType: SYSTEM\nConnections: 1\nConfidence: 90%\nSources: 03_gpt2_2019\ndescription: A dataset that tests reading comprehension capabilities.", "x": -185.28545761866377, "y": 120.20969824728172}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Top-k random sampling", "id": "method:top_k_random_sampling", "label": "Top-k random sampling", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Top-k random sampling\nType: METHOD\nConnections: 1\nConfidence: 80%\nSources: 03_gpt2_2019\ndescription: A method used to generate summaries by selecting top-k tokens.", "x": -47.32483009315547, "y": -45.119050089734316}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#6862e8", "highlight": {"background": "#FFEE58", "border": "#6862e8"}}, "community": "Question Answering and Evaluation Datasets", "description": "Greedy decoding generates sequences by selecting the most probable next token, as demonstrated in its application with GPT-2 and LLaMA. GPT-2 employs greedy decoding when conditioned on a document, effectively utilizing this method to produce coherent text sequences. Similarly, LLaMA generates answers using greedy decoding, showcasing its utility in producing responses. These instances highlight the method\u0027s role in sequence generation within these systems.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "greedy decoding", "id": "method:greedy_decoding", "label": "greedy decoding", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "greedy decoding\nType: METHOD\nConnections: 2\nCommunity: Question Answering and Evaluation Datasets\nConfidence: 100%\nSources: 03_gpt2_2019, 11_llama_2023\ndescription: A method used for generating sequences by selecting the most probable next token.", "x": 26.903188200726532, "y": -981.4884370920589}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "long-range dependencies", "id": "concept:long_range_dependencies", "label": "long-range dependencies", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "long-range dependencies\nType: CONCEPT\nConnections: 1\nConfidence: 90%\nSources: 03_gpt2_2019", "x": 209.09964791099907, "y": 149.89443311874652}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#e862ab", "highlight": {"background": "#EF5350", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "Reading comprehension has been a focal point in the advancement of natural language processing (NLP), as evidenced by its mention in key research documents such as the GPT-2 paper from 2019 and the GPT-3 few-shot learners paper from 2020. These documents highlight the progress made in NLP tasks, including reading comprehension, which is tested to evaluate the capabilities of language models. The GPT-2 model, in particular, investigates this progress by tackling challenging NLP tasks, demonstrating substantial advancements in understanding and processing human language.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "reading comprehension", "id": "concept:reading_comprehension", "label": "reading comprehension", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "reading comprehension\nType: CONCEPT\nConnections: 2\nCommunity: In-Context Learning and Bias Studies\nConfidence: 100%\nSources: 03_gpt2_2019, 04_gpt3_few_shot_learners_2020", "x": -1200.6333346867882, "y": -343.1609273623728}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#6862e8", "highlight": {"background": "#26C6DA", "border": "#6862e8"}}, "community": "Question Answering and Evaluation Datasets", "description": "The Natural Questions dataset, introduced by Kwiatkowski et al. in 2019, serves as a benchmark for evaluating language models. It comprises 3,610 questions designed to test the capabilities of models in understanding and generating human-like responses. GPT-3 was evaluated on this dataset, along with Web Questions and TriviaQA, as part of the research documented in 2020. Despite its advanced architecture, GPT-2 achieved only a 4% success rate on Natural Questions, highlighting the dataset\u0027s challenging nature. In 2023, researchers applied the LLaMA model to Natural Questions and TriviaQA, demonstrating ongoing interest in using this dataset to assess and improve language model performance.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Natural Questions", "id": "system:natural_questions", "label": "Natural Questions", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Natural Questions\nType: SYSTEM\nConnections: 2\nCommunity: Question Answering and Evaluation Datasets\nConfidence: 100%\nSources: 03_gpt2_2019, 04_gpt3_few_shot_learners_2020, 11_llama_2023\ntype: dataset\nquestions: 3610\ndescription: dataset used for evaluating language models", "x": 425.9051711865899, "y": -1375.528829479033}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "Dai and Le improved RNN-based fine-tuning approaches in 2015, contributing to the development of recurrent neural networks as a method for processing sequential data. Their work laid the groundwork for further advancements in RNN methodologies. In 2016, Jozefowicz et al. expanded on this foundation by developing techniques that enabled RNNs to learn task performance directly, enhancing the method\u0027s applicability and efficiency. These contributions collectively advanced the capabilities of RNNs, influencing subsequent research and applications in the field of machine learning.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "RNN", "id": "method:rnn", "label": "RNN", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "RNN\nType: METHOD\nConnections: 2\nConfidence: 90%\nSources: 03_gpt2_2019\ntype: model architecture", "x": -2.371787910978469, "y": -37.57689424658557}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#FFA726", "border": "#e862ab", "highlight": {"background": "#FFA726", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "The zero-shot performance of GPT-2 establishes a baseline for its potential capabilities, despite being described as \"still far from usable.\" This finding supports the notion that pre-training techniques contribute significantly to the success of downstream NLP tasks. The evidence suggests that while GPT-2\u0027s zero-shot performance may not yet meet practical usability standards, it provides a foundational measure of what the model can achieve without explicit supervision.", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "zero-shot performance", "id": "finding:zero_shot_performance", "label": "zero-shot performance", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "zero-shot performance\nType: FINDING\nConnections: 2\nCommunity: In-Context Learning and Bias Studies\nConfidence: 100%\nSources: 03_gpt2_2019\ndescription: performance without explicit supervision", "x": -1163.6791548011256, "y": -554.9176889921132}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "unsupervised task learning", "id": "concept:unsupervised_task_learning", "label": "unsupervised task learning", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "unsupervised task learning\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 03_gpt2_2019\ndescription: learning tasks without explicit supervision", "x": -232.62004992069552, "y": 154.64341090009663}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "pre-training techniques", "id": "concept:pre_training_techniques", "label": "pre-training techniques", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "pre-training techniques\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 03_gpt2_2019\ndescription: techniques for training models on large datasets before fine-tuning", "x": -204.08241012428863, "y": -196.6153467465177}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e862ab", "highlight": {"background": "#26C6DA", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "CoQA, a free-form conversational dataset, was utilized by GPT-3 to achieve an 81.5 F1 score in a zero-shot setting, demonstrating its effectiveness in handling conversational tasks. GPT-3\u0027s performance on CoQA was notable, coming within three points of the human baseline, highlighting its advanced capabilities in natural language understanding. Additionally, approximately 15% of the documents in CoQA\u0027s news domain were already present in WebText, indicating some overlap in the data sources used for training these models.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "CoQA", "id": "system:coqa", "label": "CoQA", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "CoQA\nType: SYSTEM\nConnections: 1\nCommunity: In-Context Learning and Bias Studies\nConfidence: 100%\nSources: 03_gpt2_2019, 04_gpt3_few_shot_learners_2020\ntype: dataset\ndescription: a free-form conversational dataset", "x": -1155.6700739311816, "y": -174.95267585365121}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Dai \u0026 Le", "id": "researcher:dai_le", "label": "Dai \u0026 Le", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Dai \u0026 Le\nType: RESEARCHER\nConnections: 1\nConfidence: 90%\nSources: 03_gpt2_2019\nrole: proposed RNN based fine-tuning approaches", "x": 60.94822209928719, "y": 226.8120541136368}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Jozefowicz et al.", "id": "researcher:jozefowicz_et_al", "label": "Jozefowicz et al.", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Jozefowicz et al.\nType: RESEARCHER\nConnections: 1\nConfidence: 80%\nSources: 03_gpt2_2019\nrole: proposed scaling RNN based language models", "x": 46.241074178932365, "y": 169.1782386513006}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "translation", "id": "phenomenon:translation", "label": "translation", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "translation\nType: PHENOMENON\nConnections: 1\nConfidence: 80%\nSources: 03_gpt2_2019", "x": 248.16074708795566, "y": 123.90984428398053}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Liu et al.", "id": "researcher:liu_et_al", "label": "Liu et al.", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Liu et al.\nType: RESEARCHER\nConnections: 1\nConfidence: 80%\nSources: 03_gpt2_2019\ncontribution: observed that a model trained to generate Wikipedia articles also learned to translate names between languages", "x": 221.07867556164575, "y": -62.761513880706104}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#66BB6A", "border": "#e862ab", "highlight": {"background": "#66BB6A", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "GPT-2 exhibits memorizing behavior by reproducing longer strings that appear frequently in its training data. This phenomenon is investigated in the context of GPT-2\u0027s performance, where it was observed that the model tends to memorize and repeat text from its dataset. However, analysis of overlap rates supports the finding that GPT-2 repeats text from its training set less often than the baseline rate of held-out articles.", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "text memorization", "id": "phenomenon:text_memorization", "label": "text memorization", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "text memorization\nType: PHENOMENON\nConnections: 2\nCommunity: In-Context Learning and Bias Studies\nConfidence: 90%\nSources: 03_gpt2_2019\ndescription: The behavior of the model to memorize and reproduce text from its training data.", "x": -1175.1615702039712, "y": -529.3706300894553}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "overlap rates", "id": "concept:overlap_rates", "label": "overlap rates", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "overlap rates\nType: CONCEPT\nConnections: 1\nConfidence: 80%\nSources: 03_gpt2_2019\ndescription: The measure of how much generated text matches the training data.", "x": 4.4296362406323055, "y": -165.23772636910545}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#9CCC65", "border": "#84e862", "highlight": {"background": "#9CCC65", "border": "#84e862"}}, "community": "Language Model Pioneers and Publications", "description": "In 2019, Alec Radford, along with Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever, authored the research paper \"Language Models are Unsupervised Multitask Learners.\" This paper proposed a significant shift in the understanding of language models by demonstrating their ability to perform various natural language processing tasks in a zero-shot setting without explicit supervision. The authors focused on the capabilities of these models, particularly highlighting the development of GPT-2, which they proposed as a system capable of executing multiple tasks without task-specific training. This work underscored the potential of language models to function as more general systems, moving beyond traditional task-specific approaches.", "entity_type": "PUBLICATION", "font": {"color": "#e0e0e0"}, "full_name": "Language Models are Unsupervised Multitask Learners", "id": "publication:language_models_are_unsupervised_multitask_learners", "label": "Language Models are Unsupervised Multitask Learners", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Language Models are Unsupervised Multitask Learners\nType: PUBLICATION\nConnections: 2\nCommunity: Language Model Pioneers and Publications\nConfidence: 100%\nSources: 03_gpt2_2019\nyear: 2019\nauthors: [\u0027Alec Radford\u0027, \u0027Jeffrey Wu\u0027, \u0027Rewon Child\u0027, \u0027David Luan\u0027, \u0027Dario Amodei\u0027, \u0027Ilya Sutskever\u0027]\nimportance: Discusses the capabilities of language models and proposes a shift towards more general systems.", "x": -653.7722346360098, "y": -1164.945896127991}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "zero-shot setting", "id": "concept:zero_shot_setting", "label": "zero-shot setting", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "zero-shot setting\nType: CONCEPT\nConnections: 1\nConfidence: 80%\nSources: 03_gpt2_2019", "x": 92.13155140090117, "y": 244.95967226296494}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#84e862", "highlight": {"background": "#EF5350", "border": "#84e862"}}, "community": "Language Model Pioneers and Publications", "description": "Current machine learning systems face limitations due to their reliance on task-specific training. This concept is mentioned in the context of GPT-2, which uses methods that highlight these limitations. The authors of the source material argue for a shift towards more general systems, suggesting that such systems could extend beyond the constraints imposed by task-specific training.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "task-specific training", "id": "concept:task_specific_training", "label": "task-specific training", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "task-specific training\nType: CONCEPT\nConnections: 2\nCommunity: Language Model Pioneers and Publications\nConfidence: 100%\nSources: 03_gpt2_2019", "x": -364.131164555292, "y": -1254.77415470981}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#84e862", "highlight": {"background": "#EF5350", "border": "#84e862"}}, "community": "Language Model Pioneers and Publications", "description": "Researchers proposed a shift towards more general systems that can learn from naturally occurring demonstrations, as mentioned in the 2019 paper on GPT-2. This proposal aims to address the limitations of current machine learning systems, which heavily rely on task-specific training. By advocating for general systems, the authors suggest that these models could better generalize across tasks, particularly in a zero-shot setting, using large datasets like WebText. This approach extends beyond traditional task-specific methods, offering a broader framework for developing more versatile language models.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "general systems", "id": "concept:general_systems", "label": "general systems", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "general systems\nType: CONCEPT\nConnections: 3\nCommunity: Language Model Pioneers and Publications\nConfidence: 100%\nSources: 03_gpt2_2019", "x": -460.13088915547513, "y": -963.0925975829789}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "meta-learning", "id": "method:meta_learning", "label": "meta-learning", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "meta-learning\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: a method where models develop a broad set of skills and pattern recognition abilities", "x": 194.91858313579473, "y": -3.910422383242974}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#e862ab", "highlight": {"background": "#FFEE58", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "Tom B. Brown proposed the method known as \"in-context learning,\" which involves using the text input of a pretrained language model as a form of task specification. This approach was mentioned in the 2020 paper \"04_gpt3_few_shot_learners.\" In-context learning is exemplified by models like GPT-2, which utilize this method by conditioning on natural language instructions or a few demonstrations of the task.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "in-context learning", "id": "method:in_context_learning", "label": "in-context learning", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "in-context learning\nType: METHOD\nConnections: 2\nCommunity: In-Context Learning and Bias Studies\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: using the text input of a pretrained language model as a form of task specification", "x": -1193.6977595856927, "y": -408.7258450538041}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#e862ab", "highlight": {"background": "#AB47BC", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "Tom B. Brown contributed significantly to the development and implementation of large-scale models at OpenAI. He worked alongside Ben Mann, Prafulla Dhariwal, Dario Amodei, Nick Ryder, Daniel M Ziegler, and Jeffrey Wu to implement these models, which include the well-known GPT-2. Brown also collaborated with Rewon Child, Scott Gray, and Alec Radford to develop an optimized Transformer implementation, a crucial step in advancing neural language models.\n\nIn addition to his work on model implementation, Brown was a key contributor to the research paper \"Scaling Laws for Neural Language Models,\" authored by Jared Kaplan, Sam McCandlish, and others. This paper explored the scaling laws that govern neural language models, providing insights into how model performance improves with increased size and computational resources. Brown\u0027s involvement in these projects highlights his role in pushing the boundaries of artificial intelligence research at OpenAI.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Tom B. Brown", "id": "researcher:tom_b_brown", "label": "Tom B. Brown", "node_degree": 5, "shape": "dot", "size": 18.5, "title": "Tom B. Brown\nType: RESEARCHER\nConnections: 5\nCommunity: In-Context Learning and Bias Studies\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020, 05_scaling_laws_2020\nrole: contributor", "x": -1033.1759543715448, "y": -517.3282582938123}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#e862ab", "highlight": {"background": "#AB47BC", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "Benjamin Mann co-authored a research paper with a team from OpenAI, contributing significantly to the development of GPT-2. His involvement in this project is documented in multiple sources, emphasizing his role in proposing the GPT-2 model. Additionally, Mann\u0027s work is mentioned in the context of the 2020 paper on few-shot learners, further highlighting his contributions to advancements in artificial intelligence research at OpenAI.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Benjamin Mann", "id": "researcher:benjamin_mann", "label": "Benjamin Mann", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Benjamin Mann\nType: RESEARCHER\nConnections: 2\nCommunity: In-Context Learning and Bias Studies\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020\nrole: co-author", "x": -1140.8034088185777, "y": -305.9627842436011}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "textual entailment", "id": "phenomenon:textual_entailment", "label": "textual entailment", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "textual entailment\nType: PHENOMENON\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020", "x": -166.69357496761558, "y": 101.66376043431256}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#e862ab", "highlight": {"background": "#FFEE58", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "Few-shot learning, a method advantageous when only a handful of training samples are available, has been significantly advanced by the development of large language models like GPT-3. Alec Radford originally demonstrated that few-shot learning occurs in language models, showing that these models can perform tasks with minimal examples. The scaling up of language models, as seen with GPT-3, greatly enhances their few-shot learning capabilities, achieving an impressive 86.4% accuracy in this setting. This improvement is evident in GPT-3\u0027s performance, which surpasses previous models like GPT-2 by an additional 3.2%.\n\nThe method extends the concept of one-shot learning, where only one demonstration is allowed, by allowing a few examples to guide the learning process. Few-shot learning is particularly relevant in contexts where data is scarce, such as correcting English grammar or performing well on benchmarks like LAMBADA. Despite its advantages, there is ambiguity about whether few-shot learning truly learns new tasks \u0027from scratch\u0027 or merely adapts pre-existing knowledge.\n\nFew-shot learning is contrasted with fine-tuning, which drastically improves model performance on both large and small datasets. While fine-tuning involves adjusting model parameters with additional data, few-shot learning relies on the model\u0027s inherent ability to generalize from limited examples. This distinction highlights the flexibility and efficiency of few-shot learning in scenarios where extensive data collection and model retraining are impractical.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "few-shot learning", "id": "method:few_shot_learning", "label": "few-shot learning", "node_degree": 14, "shape": "dot", "size": 41.0, "title": "few-shot learning\nType: METHOD\nConnections: 14\nCommunity: In-Context Learning and Bias Studies\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020, 07_lora_2021\ndescription: A method advantageous when only a handful of training samples are available.", "x": -1103.3170998008566, "y": -641.1875463476977}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FF7043", "border": "#333", "highlight": {"background": "#FF7043", "border": "#333"}}, "community": "", "description": "", "entity_type": "DATASET", "font": {"color": "#e0e0e0"}, "full_name": "ANLI", "id": "dataset:anli", "label": "ANLI", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "ANLI\nType: DATASET\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: dataset for natural language inference tasks", "x": 214.65565576337303, "y": 63.462453927112506}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FF7043", "border": "#333", "highlight": {"background": "#FF7043", "border": "#333"}}, "community": "", "description": "", "entity_type": "DATASET", "font": {"color": "#e0e0e0"}, "full_name": "RACE", "id": "dataset:race", "label": "RACE", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "RACE\nType: DATASET\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: dataset for reading comprehension", "x": 79.7191080245214, "y": 157.5952020551204}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "data contamination", "id": "phenomenon:data_contamination", "label": "data contamination", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "data contamination\nType: PHENOMENON\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: problem when training high capacity models on datasets", "x": -215.56816674189668, "y": 207.79999186554664}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#e862ab", "highlight": {"background": "#EF5350", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "One-shot learning, a concept allowing only one demonstration for learning, extends the idea of zero-shot learning by incorporating a single example to guide the learning process. This method is prominently mentioned in the context of GPT-3\u0027s capabilities, where it achieved a performance score of 28.3 in one-shot settings. The concept of one-shot learning supports the development of systems like GPT-2, which utilizes this method to achieve strong performance across various natural language processing tasks and benchmarks. Furthermore, one-shot learning is closely related to few-shot learning, differing only in the number of demonstrations allowed, with one-shot permitting just one.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "one-shot learning", "id": "concept:one_shot_learning", "label": "one-shot learning", "node_degree": 5, "shape": "dot", "size": 18.5, "title": "one-shot learning\nType: CONCEPT\nConnections: 5\nCommunity: In-Context Learning and Bias Studies\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020", "x": -966.3671892449256, "y": -249.6463682211135}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#e862ab", "highlight": {"background": "#EF5350", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "Zero-shot learning, a concept where no demonstrations are allowed, is prominently featured in the performance of GPT-3. In a zero-shot setting, GPT-3 achieved 76% on the LAMBADA benchmark, demonstrating its capability to understand tasks with only a natural language description. This approach contrasts with one-shot learning, which extends zero-shot learning by allowing a single demonstration. The zero-shot performance of GPT-3 significantly outperformed few-shot learning for all smaller models, highlighting its efficiency in handling various NLP tasks and benchmarks without prior examples.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "zero-shot learning", "id": "concept:zero_shot_learning", "label": "zero-shot learning", "node_degree": 4, "shape": "dot", "size": 16.0, "title": "zero-shot learning\nType: CONCEPT\nConnections: 4\nCommunity: In-Context Learning and Bias Studies\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020", "x": -1013.7916629580316, "y": -619.9062315283932}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Books1", "id": "system:books1", "label": "Books1", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Books1\nType: SYSTEM\nConnections: 1\nConfidence: 80%\nSources: 04_gpt3_few_shot_learners_2020\nsize: 12 billion", "x": -25.97097999960957, "y": -45.736062211673044}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Books2", "id": "system:books2", "label": "Books2", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Books2\nType: SYSTEM\nConnections: 1\nConfidence: 80%\nSources: 04_gpt3_few_shot_learners_2020\nsize: 55 billion", "x": 7.191763876751224, "y": 115.29789025421627}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#6862e8", "highlight": {"background": "#26C6DA", "border": "#6862e8"}}, "community": "Question Answering and Evaluation Datasets", "description": "Wikipedia, a dataset described as \"Wikipedia 3 billion,\" was utilized in training language models, specifically mentioned in the context of GPT-2. This dataset, comprising dumps from the June-August 2022 period, was applied to LLaMA, highlighting its role in advancing language model capabilities.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Wikipedia", "id": "system:wikipedia", "label": "Wikipedia", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Wikipedia\nType: SYSTEM\nConnections: 2\nCommunity: Question Answering and Evaluation Datasets\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020, 11_llama_2023\nsize: 3 billion\ndescription: a dataset used for training language models", "x": 178.83678453421282, "y": -1300.2807466123882}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#42A5F5", "border": "#333", "highlight": {"background": "#42A5F5", "border": "#333"}}, "community": "", "description": "", "entity_type": "THEORY", "font": {"color": "#e0e0e0"}, "full_name": "Sparse Transformer", "id": "theory:sparse_transformer", "label": "Sparse Transformer", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Sparse Transformer\nType: THEORY\nConnections: 1\nConfidence: 70%\nSources: 04_gpt3_few_shot_learners_2020", "x": -205.4737260203113, "y": 176.75589972500575}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#9CCC65", "border": "#e88f62", "highlight": {"background": "#9CCC65", "border": "#e88f62"}}, "community": "Scaling Laws and Efficiency Research", "description": "Jared Kaplan and Sam McCandlish authored the 2020 research paper \"Scaling Laws for Neural Language Models,\" which investigates how language model performance scales with model size, dataset size, and compute resources. This study, conducted with contributions from Tom Henighan, Tom B. Brown, and others from Johns Hopkins University and OpenAI, focuses on empirical scaling laws, particularly in relation to cross-entropy loss. The research utilizes the Transformer architecture, applying it to datasets such as WebText, and examines the impact of model shape and hyperparameters.\n\nThe paper\u0027s findings are mentioned in subsequent works, including \"04_gpt3_few_shot_learners_2020\" and \"05_scaling_laws_2020,\" showing its influence on the development of larger language models. Tom Henighan\u0027s involvement included conducting LSTM experiments, which provided additional insights into the scaling behavior of different architectures. The study\u0027s exploration of scaling laws has implications for the design and training of future neural language models, extending the understanding of how computational resources and data influence model performance.", "entity_type": "PUBLICATION", "font": {"color": "#e0e0e0"}, "full_name": "Scaling Laws For Neural Language Models", "id": "publication:scaling_laws_for_neural_language_models", "label": "Scaling Laws For Neural Language Models", "node_degree": 11, "shape": "dot", "size": 33.5, "title": "Scaling Laws For Neural Language Models\nType: PUBLICATION\nConnections: 11\nCommunity: Scaling Laws and Efficiency Research\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020, 05_scaling_laws_2020\nauthors: [\u0027Jared Kaplan\u0027, \u0027Sam McCandlish\u0027, \u0027Tom Henighan\u0027, \u0027Tom B. Brown\u0027, \u0027Benjamin Chess\u0027, \u0027Rewon Child\u0027, \u0027Scott Gray\u0027, \u0027Alec Radford\u0027, \u0027Jeff Wu\u0027, \u0027Dario Amodei\u0027]\nyear: 2020", "x": 766.9280567746338, "y": -724.5896527212259}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#e88f62", "highlight": {"background": "#EF5350", "border": "#e88f62"}}, "community": "Scaling Laws and Efficiency Research", "description": "Power-law relationships in language modeling demonstrate predictable scaling in performance relative to training compute. This concept is highlighted in the context of language modeling performance, where it is observed that the loss scales predictably as a power-law in T, as noted in the 2020 papers \"GPT-3 Few-Shot Learners\" and \"Scaling Laws.\" The power-law behavior provides insights into sample efficiency, suggesting potential benefits from training on larger contexts. Additionally, it explains the cross-entropy loss, with the behavior continuing for an additional two orders of magnitude with minimal deviations from the predicted curve. The power-law fit to the learning curve offers a straightforward approach for compute-efficient training, emphasizing its utility in optimizing training processes.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "power-law", "id": "concept:power_law", "label": "power-law", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "power-law\nType: CONCEPT\nConnections: 3\nCommunity: Scaling Laws and Efficiency Research\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020, 05_scaling_laws_2020\ndescription: predictable relationships in scaling", "x": 1057.2243300728924, "y": -829.6157856413168}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e862ab", "highlight": {"background": "#26C6DA", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "SuperGLUE, developed in 2019 by Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman, serves as a benchmark suite for evaluating natural language understanding systems. Researchers have utilized SuperGLUE to assess the performance of models like GPT-3, as noted in the evaluation of GPT-3 on this standardized collection of datasets. The benchmark\u0027s design aims to provide a more challenging evaluation than its predecessor, GLUE, hence the description of SuperGLUE as \"a stickier benchmark for general-purpose language understanding systems.\"\n\nThe benchmark\u0027s effectiveness is demonstrated by the observation that the few-shot SuperGLUE score improves with both the model size and the number of examples, indicating its utility in measuring the scalability and adaptability of language models. SuperGLUE\u0027s relevance is further highlighted by its mention in studies such as \"04_gpt3_few_shot_learners_2020\" and \"05_scaling_laws_2020,\" where it is used to gauge the capabilities of advanced language models.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "SuperGLUE", "id": "system:superglue", "label": "SuperGLUE", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "SuperGLUE\nType: SYSTEM\nConnections: 1\nCommunity: In-Context Learning and Bias Studies\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020, 05_scaling_laws_2020\ndescription: A benchmark suite for evaluating natural language understanding systems.\nauthors: [\u0027Alex Wang\u0027, \u0027Yada Pruksachatkun\u0027, \u0027Nikita Nangia\u0027, \u0027Amanpreet Singh\u0027, \u0027Julian Michael\u0027, \u0027Felix Hill\u0027, \u0027Omer Levy\u0027, \u0027Samuel R. Bowman\u0027]\nyear: 2019\nurl: http://arxiv.org/abs/1905.00537", "x": -1123.5080928515597, "y": -606.9933245556975}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#62d2e8", "highlight": {"background": "#26C6DA", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "HellaSwag evaluates language models by requiring them to select the most appropriate ending for a story or set of instructions. This dataset is mentioned in the context of few-shot learning research, specifically in the 2020 paper on GPT-3, and in the 2022 paper on InstructGPT, which applies reinforcement learning from human feedback (RLHF). Despite advancements, the PPO-ptx model, which is part of the InstructGPT framework, still underperforms compared to GPT-3 on other datasets like DROP and SQuAD v2, indicating ongoing challenges in achieving consistent performance across different language tasks.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "HellaSwag", "id": "system:hellaswag", "label": "HellaSwag", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "HellaSwag\nType: SYSTEM\nConnections: 1\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020, 10_instructgpt_rlhf_2022\ndescription: A dataset used for evaluating language models.", "x": -1185.7928885622728, "y": 183.28902721819335}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#6862e8", "highlight": {"background": "#26C6DA", "border": "#6862e8"}}, "community": "Question Answering and Evaluation Datasets", "description": "TriviaQA serves as a dataset used to evaluate the performance of language models like GPT-3 and LLaMA. GPT-3 achieved a 64.3% accuracy rate on TriviaQA in a zero-shot setting, demonstrating its ability to handle questions without prior specific training on the dataset. Researchers also applied LLaMA to TriviaQA, assessing its capabilities alongside other datasets such as Natural Questions. These evaluations highlight TriviaQA\u0027s role in testing and benchmarking the effectiveness of advanced language models in understanding and generating human-like responses.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "TriviaQA", "id": "system:triviaqa", "label": "TriviaQA", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "TriviaQA\nType: SYSTEM\nConnections: 2\nCommunity: Question Answering and Evaluation Datasets\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020, 11_llama_2023\ntype: dataset", "x": 226.57841312309674, "y": -1165.0491622518848}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#62d2e8", "highlight": {"background": "#FFEE58", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "Proximal Policy Optimization (PPO) optimizes policies against reward models, as demonstrated in its application to InstructGPT, where it was used with a pretraining mix to enhance performance. The algorithm employs a KL-constrained reward maximization objective, a standard approach in reinforcement learning from human feedback (RLHF) algorithms. In the context of InstructGPT, PPO was fine-tuned using a reward function derived from preference data, showcasing its adaptability in various environments.\n\nPPO\u0027s effectiveness is evident in its comparison to Direct Preference Optimization (DPO), which performs similarly or better than PPO-based RLHF algorithms, particularly in controlling sentiment generation. Despite its strengths, PPO can experience instabilities, a common issue with standard actor-critic algorithms used in RLHF. The algorithm\u0027s clip ratio is set to 0.2, and it utilizes a 6B reward model and value function across different policy sizes, indicating its scalability and precision in policy optimization tasks.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "PPO", "id": "method:ppo", "label": "PPO", "node_degree": 5, "shape": "dot", "size": 18.5, "title": "PPO\nType: METHOD\nConnections: 5\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020, 10_instructgpt_rlhf_2022, 12_dpo_2023\ntype: algorithm\ndescription: Proximal Policy Optimization, a reinforcement learning algorithm.", "x": -959.3673422704063, "y": 399.13787355393686}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "Winograd Schema Challenge", "id": "phenomenon:winograd_schema_challenge", "label": "Winograd Schema Challenge", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Winograd Schema Challenge\nType: PHENOMENON\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: a classical task in NLP that involves determining which word a pronoun refers to when the pronoun is grammatically ambiguous but semantically unambiguous to a human", "x": -74.27762767180846, "y": 176.52498907728312}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e862ab", "highlight": {"background": "#26C6DA", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "PIQA, a dataset designed to ask commonsense questions about the physical world, was flagged for further investigation in an analysis that included benchmarks like Word Scrambling and Reading Comprehension (QuAC, SQuAD2, DROP). This dataset was mentioned in the context of GPT-3\u0027s performance, where the model achieved varying accuracy rates: 81.0% zero-shot, 80.5% one-shot, and 82.8% few-shot. The investigation into PIQA also revealed a decrease in performance with a 25x smaller model, leading researchers to suspect statistical bias rather than memorization as the cause.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "PIQA", "id": "system:piqa", "label": "PIQA", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "PIQA\nType: SYSTEM\nConnections: 3\nCommunity: In-Context Learning and Bias Studies\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: a dataset that asks commonsense questions about how the physical world works", "x": -936.7973230625623, "y": -189.68818090669293}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "ARC", "id": "system:arc", "label": "ARC", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "ARC\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: a dataset of multiple-choice questions collected from 3rd to 9th grade science exams", "x": -28.734144921763402, "y": -139.3194452769902}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "OpenBookQA", "id": "system:openbookqa", "label": "OpenBookQA", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "OpenBookQA\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: a dataset for question answering", "x": 59.776756089697415, "y": -181.231146180392}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "RoBERTa optimized the pre-training recipe originally proposed in BERT, enhancing its robustness and performance. Developed by Liu et al. in 2019, RoBERTa serves as a robustly optimized BERT pretraining approach. Researchers have applied Low-Rank Adaptation (LoRA) to RoBERTa, evaluating its downstream task performance on tasks from the GLUE benchmark. LoRA performs on par or better than fine-tuning in model quality on RoBERTa, as well as on other models like DeBERTa, GPT-2, and GPT-3. When adapting to tasks such as MRPC, RTE, and STS-B, researchers start with the pre-trained RoBERTa large model, demonstrating its foundational role in various natural language processing tasks.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "RoBERTa", "id": "system:roberta", "label": "RoBERTa", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "RoBERTa\nType: SYSTEM\nConnections: 2\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020, 07_lora_2021\ndescription: A robustly optimized BERT pretraining approach.", "x": 94.02043851851363, "y": 233.3516895334065}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#62d2e8", "highlight": {"background": "#26C6DA", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "DROP, a dataset used for evaluating language models, has been a focal point in assessing the performance of various models. In a few-shot setting, GPT-3 outperformed the fine-tuned BERT baseline on DROP, demonstrating its capability in handling complex reading comprehension tasks. However, the dataset presents challenges, as noted by the observation that 94% of its examples are considered \"dirty,\" which complicates the extraction of clear signals.\n\nThe dataset has been flagged for potential contamination, with over 90% of its task examples identified as such in initial analyses involving models like GPT-2. This contamination issue has implications for the reliability of results obtained from models trained or evaluated on DROP. InstructGPT, when applied to DROP, showed performance regressions, indicating that further refinement is necessary to address these challenges.\n\nDespite these issues, DROP remains a critical benchmark for testing the robustness of language models. The performance of models like PPO-ptx still lags behind GPT-3 on DROP, highlighting the need for continued research to overcome these performance gaps. These findings underscore the complexity of DROP as a reading comprehension task and its role in advancing the development of more sophisticated language models.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "DROP", "id": "system:drop", "label": "DROP", "node_degree": 5, "shape": "dot", "size": 18.5, "title": "DROP\nType: SYSTEM\nConnections: 5\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020, 10_instructgpt_rlhf_2022\ndescription: A dataset used for evaluating language models.", "x": -924.6663982478948, "y": 636.4439835594371}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e8d862", "highlight": {"background": "#26C6DA", "border": "#e8d862"}}, "community": "Efficient Attention Mechanisms and Implementations", "description": "FlashAttention accelerates the training of BERT-Large, achieving a 15% end-to-end wall-clock speedup compared to existing baselines. BERT-Large, a large pre-trained Transformer model, is utilized for various natural language processing tasks. The comparison between BERT-Large and BERT++ is noted to be roughly equivalent to the difference between GPT-3, highlighting the model\u0027s significance in the landscape of NLP systems.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "BERT-Large", "id": "system:bert_large", "label": "BERT-Large", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "BERT-Large\nType: SYSTEM\nConnections: 1\nCommunity: Efficient Attention Mechanisms and Implementations\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020, 09_flash_attention_2022\ndescription: A large pre-trained Transformer model used for various NLP tasks.", "x": -365.08507041247213, "y": 1054.364867114791}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "Natural Language Inference (NLI)", "id": "concept:natural_language_inference_nli", "label": "Natural Language Inference (NLI)", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Natural Language Inference (NLI)\nType: CONCEPT\nConnections: 1\nConfidence: 80%\nSources: 04_gpt3_few_shot_learners_2020", "x": -191.34578116604035, "y": 40.31660360273969}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Adversarial Natural Language Inference (ANLI)", "id": "system:adversarial_natural_language_inference_anli", "label": "Adversarial Natural Language Inference (ANLI)", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Adversarial Natural Language Inference (ANLI)\nType: SYSTEM\nConnections: 1\nConfidence: 80%\nSources: 04_gpt3_few_shot_learners_2020", "x": -147.8387139548076, "y": 213.63772517312833}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "Arithmetic", "id": "phenomenon:arithmetic", "label": "Arithmetic", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Arithmetic\nType: PHENOMENON\nConnections: 1\nConfidence: 80%\nSources: 04_gpt3_few_shot_learners_2020", "x": 49.87897202630512, "y": -219.12137579429114}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "character manipulation tasks", "id": "phenomenon:character_manipulation_tasks", "label": "character manipulation tasks", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "character manipulation tasks\nType: PHENOMENON\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020", "x": 95.4517812890196, "y": 206.49683292097626}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "SAT analogy problems", "id": "phenomenon:sat_analogy_problems", "label": "SAT analogy problems", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "SAT analogy problems\nType: PHENOMENON\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020", "x": -95.43865901746972, "y": 66.68291955981414}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "news article generation", "id": "phenomenon:news_article_generation", "label": "news article generation", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "news article generation\nType: PHENOMENON\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020", "x": 153.4351901793915, "y": -70.72299275657474}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "human ability to detect model-generated text", "id": "finding:human_ability_to_detect_model_generated_text", "label": "human ability to detect model-generated text", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "human ability to detect model-generated text\nType: FINDING\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020", "x": 117.24931601412072, "y": 137.02759375960306}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#e862ab", "highlight": {"background": "#EF5350", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "Human accuracy in detecting model-generated content was measured at approximately 86% when participants evaluated intentionally bad articles. This finding supports the capabilities of GPT-2, as humans were able to discern its outputs with a high degree of accuracy. However, when faced with longer articles produced by GPT-3 175B, human accuracy dropped significantly to around 52%, indicating a challenge in distinguishing these more sophisticated outputs from human-written content. These results were mentioned in the 2020 paper \"04_gpt3_few_shot_learners,\" highlighting the evolving complexity of AI-generated text and its impact on human evaluative performance.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "human accuracy", "id": "concept:human_accuracy", "label": "human accuracy", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "human accuracy\nType: CONCEPT\nConnections: 2\nCommunity: In-Context Learning and Bias Studies\nConfidence: 90%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: The ratio of correct assignments to non-neutral assignments per participant.", "x": -1358.7043501685835, "y": -349.3764689228095}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "GROVER", "id": "system:grover", "label": "GROVER", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "GROVER\nType: SYSTEM\nConnections: 1\nConfidence: 80%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: An automatic discriminator for detecting model-generated text.", "x": 70.69949800936945, "y": -64.71331438020061}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "GLTR", "id": "system:gltr", "label": "GLTR", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "GLTR\nType: SYSTEM\nConnections: 1\nConfidence: 80%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: An automatic discriminator for detecting model-generated text.", "x": 194.85370800498458, "y": -100.63184390386698}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "learning and using novel words", "id": "phenomenon:learning_and_using_novel_words", "label": "learning and using novel words", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "learning and using novel words\nType: PHENOMENON\nConnections: 1\nConfidence: 90%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: The ability to learn and utilize new words.", "x": -64.50806905807039, "y": -81.56597228145651}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "Ippolito et al. conducted research on language model detection, focusing on the effectiveness of automatic discriminators. Their work is associated with the development of systems like GROVER and GLTR, which are designed to improve the success rate of detecting language models. This research is mentioned in the context of the 2020 paper \"04_gpt3_few_shot_learners,\" highlighting its relevance to advancements in language model detection technologies.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Ippolito et al.", "id": "researcher:ippolito_et_al", "label": "Ippolito et al.", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Ippolito et al.\nType: RESEARCHER\nConnections: 2\nConfidence: 90%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: Researchers who conducted related work on language model detection.", "x": 59.514800896699626, "y": 209.71560520619568}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "GPT-3 175B", "id": "system:gpt_3_175b", "label": "GPT-3 175B", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "GPT-3 175B\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: The 175 billion parameter version of the GPT-3 model.", "x": 186.46461643284653, "y": -236.5431270363079}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "control model", "id": "system:control_model", "label": "control model", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "control model\nType: SYSTEM\nConnections: 1\nConfidence: 90%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: An unconditioned GPT-3 Small model with increased output randomness.", "x": -229.0842580386443, "y": -89.42770617222163}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e862ab", "highlight": {"background": "#26C6DA", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "QuAC, a dataset designed for reading comprehension tasks, was flagged in an analysis for potential contamination, with over 90% of its task examples identified as such. This dataset was mentioned in the context of few-shot learning challenges, particularly with models like GPT-3, which struggled with performance on reading comprehension datasets including QuAC. Additionally, GPT-2 was applied to QuAC, further investigating the dataset\u0027s integrity and performance issues.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "QuAC", "id": "system:quac", "label": "QuAC", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "QuAC\nType: SYSTEM\nConnections: 2\nCommunity: In-Context Learning and Bias Studies\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: A dataset for reading comprehension tasks.", "x": -939.9792894791551, "y": -258.9962984090486}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "German-English translation", "id": "phenomenon:german_english_translation", "label": "German-English translation", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "German-English translation\nType: PHENOMENON\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: The task of translating text from German to English.", "x": -39.434962687562205, "y": 83.14280064574427}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "Word Scrambling", "id": "phenomenon:word_scrambling", "label": "Word Scrambling", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Word Scrambling\nType: PHENOMENON\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: A task where words are scrambled and need to be unscrambled.", "x": 193.04205381914494, "y": 63.40150801588743}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Winograd", "id": "system:winograd", "label": "Winograd", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Winograd\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: A dataset used for evaluating commonsense reasoning.", "x": 204.80360291888405, "y": 235.28563398328805}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "statistical bias", "id": "concept:statistical_bias", "label": "statistical bias", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "statistical bias\nType: CONCEPT\nConnections: 1\nConfidence: 70%\nSources: 04_gpt3_few_shot_learners_2020", "x": -243.4734946113054, "y": -45.41037237227263}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "text synthesis", "id": "phenomenon:text_synthesis", "label": "text synthesis", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "text synthesis\nType: PHENOMENON\nConnections: 1\nConfidence: 80%\nSources: 04_gpt3_few_shot_learners_2020", "x": 178.80632056669992, "y": 230.369459498727}, {"aliases": "reinforcement learning from human feedback, RLHF", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#62d2e8", "highlight": {"background": "#FFEE58", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "Reinforcement learning (RL) is a method that enhances models\u0027 abilities to follow instructions, as demonstrated by its application in InstructGPT, which utilizes reinforcement learning from human feedback (RLHF). This approach, proposed by key contributors from OpenAI, including Long Ouyang, Jeff Wu, and Paul Christiano, aims to align language models with human intentions. InstructGPT implements RLHF to improve its instruction-following capabilities, showcasing a practical application of this method.\n\nRLHF extends existing methods such as control codes, expert iteration, behavior cloning, and constrained optimization, offering a promising path for enhancing model steerability and controllability. However, Direct Preference Optimization (DPO) contradicts RLHF by presenting a simpler, more stable, and effective alternative for aligning language models with human preferences. Despite this, RLHF supports alignment techniques by providing a low-tax solution for aligning AI systems with human intentions.\n\nThe method appears in several research documents, including those from 2020 to 2023, demonstrating its relevance in the field. InstructGPT\u0027s use of RLHF supports the broader research program aimed at aligning AI systems with human intentions, demonstrating the method\u0027s practical impact. While DPO offers a competing approach, RLHF remains a significant method for enhancing AI alignment with human feedback.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "reinforcement learning", "id": "method:reinforcement_learning", "label": "reinforcement learning", "node_degree": 28, "shape": "dot", "size": 50, "title": "reinforcement learning\nType: METHOD\nConnections: 28\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020, 07_lora_2021, 10_instructgpt_rlhf_2022\ndescription: A method used to enhance the model\u0027s ability to follow instructions.\nabbreviation: RLHF\naliases: [\u0027reinforcement learning from human feedback\u0027, \u0027RLHF\u0027]", "x": -1330.6749101723892, "y": 248.79896503391086}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "distillation", "id": "method:distillation", "label": "distillation", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "distillation\nType: METHOD\nConnections: 1\nConfidence: 90%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: A process to reduce the size of large models for specific tasks.", "x": 80.4147938872888, "y": -69.11062769213177}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#e862ab", "highlight": {"background": "#EF5350", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "Bias in language models arises from the prejudiced content embedded in their training data. Researchers investigating GPT-2 discovered that these models learned biases, such as associating female pronouns with participant roles more frequently than male pronouns. This finding highlights the model\u0027s tendency to perpetuate gender stereotypes. Additionally, an analysis of co-reference resolution capabilities revealed that models perform better with neutral pronouns like \u0027their/them/someone\u0027 compared to gender-specific pronouns \u0027her/her/she\u0027 and \u0027his/him/he\u0027. These observations underscore the challenges in achieving fairness and representation in language models, as evidenced by the ongoing investigations into GPT-3\u0027s limitations.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "bias", "id": "concept:bias", "label": "bias", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "bias\nType: CONCEPT\nConnections: 2\nCommunity: In-Context Learning and Bias Studies\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020, 11_llama_2023\ndescription: Prejudiced content generated by models due to biases present in training data.", "x": -1078.8827602799108, "y": -519.0671240083674}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#e862ab", "highlight": {"background": "#EF5350", "border": "#e862ab"}}, "community": "In-Context Learning and Bias Studies", "description": "Researchers investigated gender bias in GPT-3 by examining how the model associates specific occupations with male or female identifiers. This study, which also considered race and religion, aimed to highlight subjective biases in AI models. The investigation into GPT-3\u0027s gender bias was informed by earlier work on GPT-2, where similar biases were explored.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "gender bias", "id": "concept:gender_bias", "label": "gender bias", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "gender bias\nType: CONCEPT\nConnections: 2\nCommunity: In-Context Learning and Bias Studies\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: The tendency of models to associate certain occupations with a male or female identifier.", "x": -1359.698084734157, "y": -340.47744949514123}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Winogender dataset", "id": "system:winogender_dataset", "label": "Winogender dataset", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Winogender dataset\nType: SYSTEM\nConnections: 1\nConfidence: 80%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: A dataset used for testing pronoun resolution.", "x": -43.50306378861424, "y": -126.99278785499834}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "SentiWordNet", "id": "system:sentiwordnet", "label": "SentiWordNet", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "SentiWordNet\nType: SYSTEM\nConnections: 1\nConfidence: 80%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: A lexical resource for sentiment analysis.", "x": -106.11516795244003, "y": -46.51410651780964}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "racial bias", "id": "concept:racial_bias", "label": "racial bias", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "racial bias\nType: CONCEPT\nConnections: 1\nConfidence: 90%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: The tendency of the language model to produce text with differing sentiment based on racial features.", "x": 233.83078398881634, "y": 104.95551786914035}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "Model Cards for Model Reporting", "id": "concept:model_cards_for_model_reporting", "label": "Model Cards for Model Reporting", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Model Cards for Model Reporting\nType: CONCEPT\nConnections: 1\nConfidence: 90%\nSources: 04_gpt3_few_shot_learners_2020", "x": -95.56777014741425, "y": 1.442934155000728}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "bias mitigation", "id": "concept:bias_mitigation", "label": "bias mitigation", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "bias mitigation\nType: CONCEPT\nConnections: 1\nConfidence: 80%\nSources: 04_gpt3_few_shot_learners_2020", "x": -81.52888938989739, "y": 4.529642482303359}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#e86262", "highlight": {"background": "#EF5350", "border": "#e86262"}}, "community": "Attention Mechanisms and Vision Models", "description": "Scaling, described as the process of increasing model and dataset sizes, has been systematically studied to understand its effect on language model performance. This concept is particularly relevant in the context of transformer-based language models, which have a long history of scaling. The significance of scaling is evident in its mention in key works such as the 2020 paper on GPT-3 few-shot learners and the 2023 paper on LLaMA. These studies explore how scaling impacts the capabilities and efficiencies of language models, providing insights into the transformative potential of larger models and datasets.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "scaling", "id": "concept:scaling", "label": "scaling", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "scaling\nType: CONCEPT\nConnections: 1\nCommunity: Attention Mechanisms and Vision Models\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020, 11_llama_2023\ndescription: the process of increasing model and dataset sizes", "x": 1075.1907855263057, "y": -164.25843593213716}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#e88f62", "highlight": {"background": "#EF5350", "border": "#e88f62"}}, "community": "Scaling Laws and Efficiency Research", "description": "Jared Kaplan and Sam McCandlish authored the research paper \"Scaling Laws for Neural Language Models,\" which proposed empirical scaling laws to describe how language model performance improves with increased model size, data, and compute resources. These scaling laws revealed predictable power-law relationships, providing insights into optimal training strategies for neural language models. The research applied these laws to guide decisions on model and data scaling, supporting the development of systems like GPT-2.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "scaling laws", "id": "concept:scaling_laws", "label": "scaling laws", "node_degree": 4, "shape": "dot", "size": 16.0, "title": "scaling laws\nType: CONCEPT\nConnections: 4\nCommunity: Scaling Laws and Efficiency Research\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020, 05_scaling_laws_2020", "x": 1113.196250734598, "y": -995.5518207681005}, {"aliases": "Adam optimizer", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#e86262", "highlight": {"background": "#FFEE58", "border": "#e86262"}}, "community": "Attention Mechanisms and Vision Models", "description": "Adam, an optimization algorithm, computes adaptive learning rates for each parameter and has been extensively utilized in training various models. It was employed to train all versions of GPT-3, as noted in the 2020 paper on few-shot learners. The algorithm\u0027s use is further highlighted in the 2020 Vision Transformer paper and the 2021 Low-Rank Adaptation study, where tuning \u03b1 with Adam is equated to adjusting the learning rate.\n\nAdam\u0027s association with the Transformer architecture is evident from its application with specific parameters (\u03b2 = 0.9, \u03b2 = 0.98, and \u03f5 = 10\u22129) as described in the seminal 2017 paper \"Attention is All You Need.\" This optimization method is also integral to the training of GPT-2 and InstructGPT, as well as unconventional applications in ResNet models. The widespread adoption of Adam across these systems underscores its versatility and effectiveness in optimizing complex neural networks.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Adam", "id": "method:adam", "label": "Adam", "node_degree": 7, "shape": "dot", "size": 23.5, "title": "Adam\nType: METHOD\nConnections: 7\nCommunity: Attention Mechanisms and Vision Models\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020, 06_vision_transformer_2020, 07_lora_2021\ntype: optimization algorithm\ndescription: An optimization algorithm that computes adaptive learning rates for each parameter.\naliases: [\u0027Adam optimizer\u0027]", "x": 1192.9046603252982, "y": 16.59603030591734}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "logistic regression", "id": "method:logistic_regression", "label": "logistic regression", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "logistic regression\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020", "x": -191.23033355228986, "y": 134.75072342417127}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "weight decay", "id": "method:weight_decay", "label": "weight decay", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "weight decay\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020", "x": 244.0071932009717, "y": 162.1528115377521}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "clean-only examples", "id": "concept:clean_only_examples", "label": "clean-only examples", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "clean-only examples\nType: CONCEPT\nConnections: 1\nConfidence: 90%\nSources: 04_gpt3_few_shot_learners_2020", "x": 221.91211281829686, "y": -82.1239439753806}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "language modeling benchmarks", "id": "concept:language_modeling_benchmarks", "label": "language modeling benchmarks", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "language modeling benchmarks\nType: CONCEPT\nConnections: 1\nConfidence: 80%\nSources: 04_gpt3_few_shot_learners_2020", "x": -219.74252904379438, "y": -46.79675507186383}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "human detection", "id": "phenomenon:human_detection", "label": "human detection", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "human detection\nType: PHENOMENON\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020", "x": 197.82068834460722, "y": 240.42263107769816}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Python", "id": "method:python", "label": "Python", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Python\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: A programming language used for implementing statistical tests.", "x": 61.692238638984065, "y": 174.00756247516904}, {"aliases": "two-sample Student\u2019s T-Test", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "Researchers employed the two-sample t-test to compare means on different runs, specifically testing for significant differences between the means of participant accuracies against a control model. This statistical method, also known as the two-sample Student\u2019s T-Test, was implemented using Python\u0027s scipy.stats.ttest_ind function. The method was mentioned in the context of the 2020 study on GPT-3 few-shot learners, highlighting its application in evaluating model performance.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "two-sample t-test", "id": "method:two_sample_t_test", "label": "two-sample t-test", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "two-sample t-test\nType: METHOD\nConnections: 2\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: A statistical test used to compare means on the different runs.\naliases: [\u0027two-sample Student\u2019s T-Test\u0027]", "x": 165.4133477283201, "y": -46.35302680903723}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "average participant accuracy", "id": "finding:average_participant_accuracy", "label": "average participant accuracy", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "average participant accuracy\nType: FINDING\nConnections: 1\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020", "x": 71.67311608812281, "y": 158.08515446828164}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "scaling up language models", "id": "method:scaling_up_language_models", "label": "scaling up language models", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "scaling up language models\nType: METHOD\nConnections: 1\nConfidence: 70%\nSources: 04_gpt3_few_shot_learners_2020\ndescription: the process of increasing the size and complexity of language models to improve performance", "x": -182.30973635976366, "y": 15.223566695310637}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#62d2e8", "highlight": {"background": "#AB47BC", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "OpenAI developed GPT-3, a significant advancement in natural language processing, as detailed in their 2020 research paper. The organization also proposed InstructGPT, a system designed to improve AI alignment with human instructions, as documented in their 2022 work on reinforcement learning from human feedback (RLHF). These efforts underscore OpenAI\u0027s role in advancing AI technologies through innovative methods and systems.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "OpenAI", "id": "researcher:openai", "label": "OpenAI", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "OpenAI\nType: RESEARCHER\nConnections: 1\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 04_gpt3_few_shot_learners_2020, 10_instructgpt_rlhf_2022\nrole: Research team responsible for developing GPT-3.\ndescription: The organization behind the development of InstructGPT.", "x": -1104.7037774965686, "y": 507.7464977231074}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#e88f62", "highlight": {"background": "#EF5350", "border": "#e88f62"}}, "community": "Scaling Laws and Efficiency Research", "description": "Power-law relationships describe how one quantity varies as a power of another, and they are crucial in understanding performance dynamics in various contexts. In the 2020 study \"05_scaling_laws_2020,\" researchers presented power-law relationships between performance and context position, revealing predictable patterns that have significant implications for optimal training strategies. These relationships explain the degree of performance improvement expected as systems scale up, particularly in relation to cross-entropy loss.\n\nFurthermore, power-law relationships support the concept of compute-efficient training by demonstrating that the amount of data required grows slowly with the compute budget. This insight is vital for developing strategies that maximize performance while minimizing computational resources. The study\u0027s findings underscore the importance of power-law dynamics in optimizing training processes and resource allocation in computational systems.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "power-law relationships", "id": "concept:power_law_relationships", "label": "power-law relationships", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "power-law relationships\nType: CONCEPT\nConnections: 2\nCommunity: Scaling Laws and Efficiency Research\nConfidence: 100%\nSources: 05_scaling_laws_2020\ndescription: A relationship where one quantity varies as a power of another.", "x": 730.7254670541796, "y": -554.9923675694808}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#e88f62", "highlight": {"background": "#AB47BC", "border": "#e88f62"}}, "community": "Scaling Laws and Efficiency Research", "description": "Jared Kaplan led the research on \"Scaling Laws for Neural Language Models,\" collaborating closely with Sam McCandlish. This work, documented in a research paper co-authored by Kaplan, McCandlish, and several others, proposed the concept of scaling laws in neural language models. The research focused on understanding how the performance of neural language models improves with increased computational resources and data, a significant contribution to the field of artificial intelligence.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Jared Kaplan", "id": "researcher:jared_kaplan", "label": "Jared Kaplan", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "Jared Kaplan\nType: RESEARCHER\nConnections: 3\nCommunity: Scaling Laws and Efficiency Research\nConfidence: 100%\nSources: 05_scaling_laws_2020\nrole: lead researcher", "x": 680.2415844454603, "y": -777.9141508302571}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#e88f62", "highlight": {"background": "#AB47BC", "border": "#e88f62"}}, "community": "Scaling Laws and Efficiency Research", "description": "Sam McCandlish co-led the research on \"Scaling Laws for Neural Language Models\" alongside Jared Kaplan. This work, documented in a research paper authored by both McCandlish and Kaplan, along with several other contributors, proposed significant insights into the scaling laws governing neural language models. McCandlish\u0027s role as a lead researcher in this study highlights his active involvement in advancing the understanding of how neural language models can be effectively scaled.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Sam McCandlish", "id": "researcher:sam_mccandlish", "label": "Sam McCandlish", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "Sam McCandlish\nType: RESEARCHER\nConnections: 3\nCommunity: Scaling Laws and Efficiency Research\nConfidence: 100%\nSources: 05_scaling_laws_2020\nrole: lead researcher", "x": 766.448347692532, "y": -810.6852204737988}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Tom Henighan", "id": "researcher:tom_henighan", "label": "Tom Henighan", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Tom Henighan\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 05_scaling_laws_2020\nrole: contributor", "x": -212.88751820252662, "y": -15.38083755725566}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#62d2e8", "highlight": {"background": "#AB47BC", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "Jeff Wu contributed to the development of text datasets alongside Benjamin Chess and Alec Radford. As a primary author, he collaborated with Long Ouyang, Xu Jiang, and Diogo Almeida on research papers at OpenAI. Wu\u0027s work is prominently featured in documents such as \"05_scaling_laws_2020\" and \"10_instructgpt_rlhf_2022,\" where he is recognized as a key contributor. His involvement in proposing reinforcement learning and the InstructGPT system underscores his significant contributions to these projects.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Jeff Wu", "id": "researcher:jeff_wu", "label": "Jeff Wu", "node_degree": 4, "shape": "dot", "size": 16.0, "title": "Jeff Wu\nType: RESEARCHER\nConnections: 4\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 05_scaling_laws_2020, 10_instructgpt_rlhf_2022\nrole: Primary author", "x": -1159.0243408846493, "y": 256.59807431099694}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e86262", "highlight": {"background": "#26C6DA", "border": "#e86262"}}, "community": "Attention Mechanisms and Vision Models", "description": "WebText2, an extended version of the WebText dataset, was utilized to train language models to near convergence without signs of overfitting, even with its full 22 billion tokens. Researchers applied the Adam optimizer for most training processes, while Adafactor was employed for models exceeding 1 billion parameters due to memory constraints. The dataset was primarily used to train decoder-only Transformer models, which were tested for overfitting and showed no such issues. Additionally, LSTM models and Universal Transformers were trained on WebText2 for comparative analysis. This dataset was mentioned in the 2020 study on scaling laws, highlighting its role in advancing language model training methodologies.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "WebText2", "id": "system:webtext2", "label": "WebText2", "node_degree": 7, "shape": "dot", "size": 23.5, "title": "WebText2\nType: SYSTEM\nConnections: 7\nCommunity: Attention Mechanisms and Vision Models\nConfidence: 100%\nSources: 05_scaling_laws_2020\ndescription: an extended version of the WebText dataset", "x": 1243.4993671491584, "y": 237.59280131724057}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Universal Transformers", "id": "system:universal_transformers", "label": "Universal Transformers", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Universal Transformers\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 05_scaling_laws_2020", "x": 48.57785012659082, "y": 86.62891450478486}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Adafactor", "id": "method:adafactor", "label": "Adafactor", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Adafactor\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 05_scaling_laws_2020", "x": -105.82257219216106, "y": -95.19984141756842}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "learning curves", "id": "concept:learning_curves", "label": "learning curves", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "learning curves\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 05_scaling_laws_2020", "x": 209.63144230582338, "y": 88.65824503029654}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "batch size", "id": "concept:batch_size", "label": "batch size", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "batch size\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 05_scaling_laws_2020", "x": -115.53636691177621, "y": -161.2356350291799}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#42A5F5", "border": "#e88f62", "highlight": {"background": "#42A5F5", "border": "#e88f62"}}, "community": "Scaling Laws and Efficiency Research", "description": "LSTM models were applied to experiments conducted by Tom Henighan, as part of research on scaling laws for neural language models. These experiments involved training LSTM models alongside Universal Transformers to compare their performance. The comparison focused on how LSTM and Transformer models performed relative to the non-embedding parameter count, denoted as N. Additionally, LSTM models were trained using the WebText2 dataset to further evaluate their capabilities.", "entity_type": "THEORY", "font": {"color": "#e0e0e0"}, "full_name": "LSTM", "id": "theory:lstm", "label": "LSTM", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "LSTM\nType: THEORY\nConnections: 2\nCommunity: Scaling Laws and Efficiency Research\nConfidence: 90%\nSources: 05_scaling_laws_2020", "x": 943.8293237628449, "y": -651.7536055289008}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "optimal training strategies", "id": "concept:optimal_training_strategies", "label": "optimal training strategies", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "optimal training strategies\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 05_scaling_laws_2020", "x": -135.1020923370626, "y": 188.32262353165464}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#66BB6A", "border": "#e86262", "highlight": {"background": "#66BB6A", "border": "#e86262"}}, "community": "Attention Mechanisms and Vision Models", "description": "Overfitting emerges as a critical phenomenon when model performance ceases to improve with increasing data size, as noted in the context of smaller fixed dimensions (D). The phenomenon is particularly evident when performance, initially following a power law with respect to data size (N), begins to plateau and degrade, indicating overfitting. This issue is further compounded in compute-efficient training scenarios, where overfitting becomes an inevitable challenge as computational resources are optimized.\n\nThe extent of overfitting is quantitatively supported by Equation (4.3), which predicts that overfitting is primarily influenced by the ratio N\u03b1D/D. This mathematical relationship underscores the dependency of overfitting on the interplay between data size and model complexity. However, in practical applications, such as training with the extensive 22 billion token WebText2 dataset, no signs of overfitting were observed, suggesting that sufficiently large datasets can mitigate the risk of overfitting.\n\nThese insights into overfitting are documented in the 2020 study on scaling laws, which provides a framework for understanding how model performance scales with data and computational resources. The study highlights the delicate balance required to optimize model training without succumbing to overfitting, emphasizing the importance of dataset size and model architecture in achieving robust performance.", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "overfitting", "id": "phenomenon:overfitting", "label": "overfitting", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "overfitting\nType: PHENOMENON\nConnections: 2\nCommunity: Attention Mechanisms and Vision Models\nConfidence: 100%\nSources: 05_scaling_laws_2020", "x": 1411.7731404881715, "y": -45.581402991893896}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#e88f62", "highlight": {"background": "#FFEE58", "border": "#e88f62"}}, "community": "Scaling Laws and Efficiency Research", "description": "Equation (1.5) predicts the early-stopped test loss L(N,D) by considering both the dataset size D and the model size N. This method is detailed in the 2020 paper \"Scaling Laws for Neural Language Models,\" where it provides guidance on the necessary data volume to train models of varying sizes while managing overfitting. The equation effectively explains the behavior of cross-entropy loss in relation to these variables. The researchers assert that their equation for L(N,D) aligns well with empirical data, serving as the primary justification for their proposed ansatz.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Equation (1.5)", "id": "method:equation_1_5", "label": "Equation (1.5)", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Equation (1.5)\nType: METHOD\nConnections: 2\nCommunity: Scaling Laws and Efficiency Research\nConfidence: 100%\nSources: 05_scaling_laws_2020", "x": 1162.425253891164, "y": -668.5398065540152}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Equation (4.3)", "id": "method:equation_4_3", "label": "Equation (4.3)", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Equation (4.3)\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 05_scaling_laws_2020", "x": 233.85167424738802, "y": -166.06757837283146}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "critical batch size", "id": "concept:critical_batch_size", "label": "critical batch size", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "critical batch size\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 05_scaling_laws_2020", "x": 64.06762608752945, "y": 233.3805692856061}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "L(N,D)", "id": "concept:l_n_d", "label": "L(N,D)", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "L(N,D)\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 05_scaling_laws_2020", "x": -66.44425691543276, "y": 30.623300662182544}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#42A5F5", "border": "#e88f62", "highlight": {"background": "#42A5F5", "border": "#e88f62"}}, "community": "Scaling Laws and Efficiency Research", "description": "L(N,S) explains the behavior of cross-entropy loss when either total compute or the number of training steps is held constant, as described in Equation (5.6). This theory extends the Transformer architecture by utilizing S from Equation (5.4) to create a universal fit for loss dependence on model size and training time in the infinite data limit. Additionally, the results derived from L(N,S) support the establishment of a lower-bound estimate for the early stopping step in data-limited training scenarios.", "entity_type": "THEORY", "font": {"color": "#e0e0e0"}, "full_name": "L(N,S)", "id": "theory:l_n_s", "label": "L(N,S)", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "L(N,S)\nType: THEORY\nConnections: 3\nCommunity: Scaling Laws and Efficiency Research\nConfidence: 100%\nSources: 05_scaling_laws_2020", "x": 903.3004475196402, "y": -896.8475021695255}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "lower-bound on early stopping step", "id": "finding:lower_bound_on_early_stopping_step", "label": "lower-bound on early stopping step", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "lower-bound on early stopping step\nType: FINDING\nConnections: 1\nConfidence: 100%\nSources: 05_scaling_laws_2020", "x": -159.68363677321668, "y": 10.95729958287842}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "data requirements of compute-efficient training", "id": "concept:data_requirements_of_compute_efficient_training", "label": "data requirements of compute-efficient training", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "data requirements of compute-efficient training\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 05_scaling_laws_2020", "x": -167.0651852582809, "y": 183.81082207112172}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "L(C)", "id": "concept:l_c", "label": "L(C)", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "L(C)\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 05_scaling_laws_2020", "x": -106.94803718408147, "y": 119.77117587742674}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "L(D(C))", "id": "concept:l_d_c", "label": "L(D(C))", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "L(D(C))\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 05_scaling_laws_2020", "x": 141.8882721845527, "y": -169.78666674820806}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "power-law scaling", "id": "concept:power_law_scaling", "label": "power-law scaling", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "power-law scaling\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 05_scaling_laws_2020", "x": 89.56531728518627, "y": -198.94772449580566}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "natural language data", "id": "concept:natural_language_data", "label": "natural language data", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "natural language data\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 05_scaling_laws_2020", "x": -77.43540442503604, "y": -84.1051251016564}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#66BB6A", "border": "#e88f62", "highlight": {"background": "#66BB6A", "border": "#e88f62"}}, "community": "Scaling Laws and Efficiency Research", "description": "Cross-entropy loss serves as a critical measure of model performance, particularly in natural language processing tasks where the output is a probability value between 0 and 1. Researchers have demonstrated that improvements in cross-entropy loss consistently lead to performance gains across a wide range of natural language tasks. The phenomenon is deeply intertwined with empirical scaling laws, which describe how language model performance, specifically in terms of cross-entropy loss, scales with model size, dataset size, and compute resources. These scaling laws are further explained by power-law relationships, which predict the degree of performance improvement as models are scaled up.\n\nThe study of cross-entropy loss is prominently featured in works such as \"Scaling Laws For Neural Language Models,\" which delves into how performance metrics like cross-entropy loss are affected by variables such as model size and dataset size. The research highlights that learning curves can be accurately modeled, and the early-stopped test loss L(N,D) depends predictably on dataset size D and model size N, as articulated in Equation (1.5). Additionally, when either total compute or the number of training steps is held constant, performance follows the pattern described by L(N,S) from Equation (5.6).\n\nThe Transformer architecture, a foundational theory in modern language models, explains that its performance is relatively insensitive to shape parameters when the total non-embedding parameter count is fixed. This insight aligns with the broader understanding of scaling laws and cross-entropy loss, reinforcing the importance of model size and resource allocation in achieving optimal performance. The research underscores the significance of cross-entropy loss as a benchmark for evaluating and improving language models, providing a framework for understanding how various factors contribute to model efficacy.", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "cross-entropy loss", "id": "phenomenon:cross_entropy_loss", "label": "cross-entropy loss", "node_degree": 8, "shape": "dot", "size": 26.0, "title": "cross-entropy loss\nType: PHENOMENON\nConnections: 8\nCommunity: Scaling Laws and Efficiency Research\nConfidence: 100%\nSources: 05_scaling_laws_2020, 04_gpt3_few_shot_learners_2020\ndescription: A measure of the performance of a model whose output is a probability value between 0 and 1.", "x": 906.3431167857237, "y": -592.4666663874402}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#e88f62", "highlight": {"background": "#FFEE58", "border": "#e88f62"}}, "community": "Scaling Laws and Efficiency Research", "description": "Compute-efficient training employs a power-law fit to the learning curve, which provides a straightforward approach to optimizing training processes. This method is characterized by its use of relatively few optimization steps, suggesting that further research into accelerating early training dynamics could enhance its efficiency. The relationship between compute budget and data usage in compute-efficient training is supported by power-law relationships, indicating that data requirements increase slowly as compute resources expand. Additionally, the concept of critical batch size is associated with compute-efficient training, as evidenced by measurements taken from specific data sets. These elements collectively form the foundation of compute-efficient training, as discussed in the 2020 paper on scaling laws.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "compute-efficient training", "id": "method:compute_efficient_training", "label": "compute-efficient training", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "compute-efficient training\nType: METHOD\nConnections: 3\nCommunity: Scaling Laws and Efficiency Research\nConfidence: 80%\nSources: 05_scaling_laws_2020", "x": 1056.7062575909392, "y": -706.9878034965224}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#42A5F5", "border": "#e88f62", "highlight": {"background": "#42A5F5", "border": "#e88f62"}}, "community": "Scaling Laws and Efficiency Research", "description": "Empirical scaling laws describe how language model performance, particularly in terms of cross-entropy loss, scales with model size, dataset size, and compute resources. Despite their significance, researchers have yet to establish a solid theoretical understanding of these scaling laws. The 2020 study on scaling laws highlighted this gap, noting the lack of a comprehensive theoretical framework to explain the observed phenomena.\n\nThe research compared the performance of standard Transformers to current Transformers, focusing on how these models\u0027 performance metrics change with varying scales. This comparison underscores the empirical nature of the scaling laws, which are derived from observed data rather than theoretical predictions. The study\u0027s findings emphasize the need for further theoretical exploration to understand the underlying principles governing these scaling behaviors.", "entity_type": "THEORY", "font": {"color": "#e0e0e0"}, "full_name": "empirical scaling laws", "id": "theory:empirical_scaling_laws", "label": "empirical scaling laws", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "empirical scaling laws\nType: THEORY\nConnections: 2\nCommunity: Scaling Laws and Efficiency Research\nConfidence: 80%\nSources: 05_scaling_laws_2020", "x": 712.3759224544716, "y": -782.8002503013671}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "recurrent Transformers", "id": "system:recurrent_transformers", "label": "recurrent Transformers", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "recurrent Transformers\nType: SYSTEM\nConnections: 1\nConfidence: 80%\nSources: 05_scaling_laws_2020", "x": 32.15344433817455, "y": 220.46360118146907}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#e88f62", "highlight": {"background": "#EF5350", "border": "#e88f62"}}, "community": "Scaling Laws and Efficiency Research", "description": "Large models demonstrate significant sample efficiency by training faster and requiring less data. This efficiency is highlighted in the 2020 study on scaling laws, which notes that optimally compute-efficient training involves using very large models with a relatively modest amount of data. The study also investigates batch size, measuring the critical batch size to understand its impact on training efficiency. Additionally, the power-law relationship is suggested to explain the benefits of training on larger contexts, further supporting the notion that larger models are more sample-efficient.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "sample efficiency", "id": "concept:sample_efficiency", "label": "sample efficiency", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "sample efficiency\nType: CONCEPT\nConnections: 2\nCommunity: Scaling Laws and Efficiency Research\nConfidence: 80%\nSources: 05_scaling_laws_2020", "x": 1048.2476352870892, "y": -825.4179066239718}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e86262", "highlight": {"background": "#26C6DA", "border": "#e86262"}}, "community": "Attention Mechanisms and Vision Models", "description": "The Vision Transformer (ViT) applies the Transformer architecture, originally developed for natural language processing, to image classification tasks. Proposed in 2021 by Alexey Dosovitskiy, Lucas Beyer, and Neil Houlsby from Google Research\u0027s Brain Team, ViT challenges the traditional reliance on convolutional neural networks (CNNs) by demonstrating that a pure transformer can effectively handle sequences of image patches. This approach contradicts the necessity of CNNs and outperforms ResNets with equivalent computational budgets.\n\nViT supports its efficacy through pre-training on large datasets like JFT-300M and ImageNet-21k, achieving strong performance on various benchmarks, including CIFAR-10, CIFAR-100, Oxford-IIIT Pets, Oxford Flowers-102, and VTAB. The system employs methods such as self-supervised pre-training and masked patch prediction, incorporating Axial Attention to process inputs in a two-dimensional shape. By implementing the Transformer architecture, ViT extends its application from language to vision, supporting its capabilities across multiple image recognition tasks.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Vision Transformer", "id": "system:vision_transformer", "label": "Vision Transformer", "node_degree": 20, "shape": "dot", "size": 50, "title": "Vision Transformer\nType: SYSTEM\nConnections: 20\nCommunity: Attention Mechanisms and Vision Models\nConfidence: 100%\nSources: 06_vision_transformer_2020\ndescription: A model that applies the Transformer architecture to image classification tasks.\nyear: 2021", "x": 1191.0438878097402, "y": 42.15065164648439}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e86262", "highlight": {"background": "#26C6DA", "border": "#e86262"}}, "community": "Attention Mechanisms and Vision Models", "description": "ImageNet, a large dataset used for image classification tasks, serves as a benchmark for evaluating the performance of various models. The Vision Transformer (ViT) model, when pre-trained on the public ImageNet-21k dataset, achieves excellent results, demonstrating the dataset\u0027s utility in enhancing model performance. Specifically, the smaller ViT-B/16 model attains a 79.9% accuracy on ImageNet, marking a significant 2% improvement over training from scratch, which underscores the effectiveness of self-supervised pre-training on this dataset.\n\nAdditionally, the performance of Axial-ViT-B/32 and Axial-ViT-B/16 models on ImageNet in a 5-shot linear setting further illustrates the dataset\u0027s role in facilitating advanced image classification capabilities. These findings highlight ImageNet\u0027s critical function as a foundational resource for developing and testing cutting-edge image recognition systems.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "ImageNet", "id": "system:imagenet", "label": "ImageNet", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "ImageNet\nType: SYSTEM\nConnections: 3\nCommunity: Attention Mechanisms and Vision Models\nConfidence: 100%\nSources: 06_vision_transformer_2020\ndescription: A large dataset used for image classification tasks.\ntype: benchmark", "x": 1214.1340028335107, "y": -194.17611203900196}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "CIFAR-100", "id": "system:cifar_100", "label": "CIFAR-100", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "CIFAR-100\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 06_vision_transformer_2020\ndescription: A dataset used for image classification tasks.\ntype: benchmark", "x": 209.53905873010848, "y": 81.08539193311861}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "CNN", "id": "concept:cnn", "label": "CNN", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "CNN\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 06_vision_transformer_2020\ndescription: Convolutional Neural Networks, a class of deep neural networks commonly used for image processing.", "x": -97.49212751808679, "y": -230.2773287427317}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Alexey Dosovitskiy", "id": "researcher:alexey_dosovitskiy", "label": "Alexey Dosovitskiy", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Alexey Dosovitskiy\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 06_vision_transformer_2020\nrole: co-author", "x": 134.47680705285592, "y": 241.12011308071766}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Lucas Beyer", "id": "researcher:lucas_beyer", "label": "Lucas Beyer", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Lucas Beyer\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 06_vision_transformer_2020\nrole: co-author", "x": 26.45366071294717, "y": 194.50698974621736}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Neil Houlsby", "id": "researcher:neil_houlsby", "label": "Neil Houlsby", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Neil Houlsby\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 06_vision_transformer_2020\nrole: co-author", "x": -120.34933981141123, "y": -204.90137883948105}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "JFT-300M", "id": "system:jft_300m", "label": "JFT-300M", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "JFT-300M\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 06_vision_transformer_2020\ndescription: A large dataset used for pre-training Vision Transformers.", "x": -175.59987677880707, "y": 28.51778946133129}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "BiT", "id": "system:bit", "label": "BiT", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "BiT\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 06_vision_transformer_2020\ndescription: A model that co-trains ResNet on ImageNet and YouTube.", "x": -234.17854367079732, "y": 198.30339925383942}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "CIFAR-10", "id": "system:cifar_10", "label": "CIFAR-10", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "CIFAR-10\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 06_vision_transformer_2020\ndescription: A dataset used for image classification.", "x": -33.511991332964016, "y": 148.23094809266968}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Oxford-IIIT Pets", "id": "system:oxford_iiit_pets", "label": "Oxford-IIIT Pets", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Oxford-IIIT Pets\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 06_vision_transformer_2020\ndescription: A dataset used for image classification.", "x": -151.45242535528723, "y": 188.6863849168097}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Oxford Flowers-102", "id": "system:oxford_flowers_102", "label": "Oxford Flowers-102", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Oxford Flowers-102\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 06_vision_transformer_2020\ndescription: A dataset used for image classification.", "x": 241.23605586942824, "y": -45.67778332746758}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "VTAB", "id": "system:vtab", "label": "VTAB", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "VTAB\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 06_vision_transformer_2020\ndescription: A benchmark for evaluating transfer learning across various tasks.", "x": 9.044436919105294, "y": 32.29876781870979}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#e86262", "highlight": {"background": "#FFEE58", "border": "#e86262"}}, "community": "Attention Mechanisms and Vision Models", "description": "Self-supervised pre-training enables models to learn from unlabeled data, significantly enhancing their scalability and performance. This method supports the Vision Transformer (ViT), which achieves a 79.9% accuracy on ImageNet, marking a 2% improvement over models trained from scratch. Despite this success, self-supervised pre-training still lags behind large-scale supervised pre-training, indicating a gap in performance. The Vision Transformer utilizes self-supervised pre-training to match or exceed state-of-the-art results on various image classification datasets, while maintaining cost-effectiveness during pre-training.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "self-supervised pre-training", "id": "method:self_supervised_pre_training", "label": "self-supervised pre-training", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "self-supervised pre-training\nType: METHOD\nConnections: 3\nCommunity: Attention Mechanisms and Vision Models\nConfidence: 100%\nSources: 06_vision_transformer_2020\ndescription: A technique that allows models to learn from unlabeled data.", "x": 950.9520525106617, "y": 69.67537503441935}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "large-scale supervised pre-training", "id": "method:large_scale_supervised_pre_training", "label": "large-scale supervised pre-training", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "large-scale supervised pre-training\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 06_vision_transformer_2020\ndescription: A technique that involves training models on large labeled datasets.", "x": 22.227002605074745, "y": 228.33020471642646}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "self-supervised learning", "id": "method:self_supervised_learning", "label": "self-supervised learning", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "self-supervised learning\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 06_vision_transformer_2020\ndescription: A type of unsupervised learning where the model learns from the data itself.", "x": -174.47964129987588, "y": 0.2594891980335774}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "masked patch prediction", "id": "method:masked_patch_prediction", "label": "masked patch prediction", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "masked patch prediction\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 06_vision_transformer_2020\ndescription: An objective used in self-supervised learning where parts of the input are masked and predicted.", "x": 211.07060377109394, "y": 182.74112407580316}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#42A5F5", "border": "#e86262", "highlight": {"background": "#42A5F5", "border": "#e86262"}}, "community": "Attention Mechanisms and Vision Models", "description": "ResNet, a type of convolutional neural network architecture, typically employs stochastic gradient descent (SGD) for training. This method choice is conventional, although some implementations have experimented with Adam as an optimizer, which is considered unconventional for ResNets. Despite its widespread use, ResNet faces competition from Vision Transformers, which generally outperform ResNets when operating within the same computational budget.", "entity_type": "THEORY", "font": {"color": "#e0e0e0"}, "full_name": "ResNet", "id": "theory:resnet", "label": "ResNet", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "ResNet\nType: THEORY\nConnections: 3\nCommunity: Attention Mechanisms and Vision Models\nConfidence: 90%\nSources: 06_vision_transformer_2020\ndescription: A type of convolutional neural network architecture.", "x": 952.9849018595794, "y": -63.67246196475162}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "SGD", "id": "method:sgd", "label": "SGD", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "SGD\nType: METHOD\nConnections: 1\nConfidence: 90%\nSources: 06_vision_transformer_2020\ndescription: Stochastic Gradient Descent, an optimization method.", "x": -132.58838967611229, "y": 86.3400430809188}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "ViT-L/16, a Vision Transformer model, was utilized in performance analysis to determine its efficiency in handling images. It was specifically applied to the JFT dataset, where it underwent pretraining to enhance its capabilities. Additionally, ViT-L/16 was tested on the VTAB-1k tasks, with Table 9 documenting the scores it achieved across these tasks. This model\u0027s application in these datasets highlights its role in advancing image processing and analysis within the field of computer vision.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "ViT-L/16", "id": "system:vit_l_16", "label": "ViT-L/16", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "ViT-L/16\nType: SYSTEM\nConnections: 2\nConfidence: 100%\nSources: 06_vision_transformer_2020\ntype: Vision Transformer model\ndetails: used in performance analysis", "x": 37.648058883267424, "y": -213.93720075238232}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Axial Attention", "id": "method:axial_attention", "label": "Axial Attention", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Axial Attention\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 06_vision_transformer_2020\ndescription: a technique to run self-attention on large inputs organized as multidimensional tensors", "x": -99.19796227294142, "y": 20.330437262319947}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Axial ResNet", "id": "system:axial_resnet", "label": "Axial ResNet", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Axial ResNet\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 06_vision_transformer_2020\ntype: model\ndetails: proposed by Wang et al. (2020b)", "x": 98.13162191183011, "y": -184.1155341698639}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "JFT dataset", "id": "system:jft_dataset", "label": "JFT dataset", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "JFT dataset\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 06_vision_transformer_2020\ntype: dataset\ndetails: used for pretraining", "x": -46.94478662309436, "y": -215.53250433312655}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "VTAB-1k", "id": "system:vtab_1k", "label": "VTAB-1k", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "VTAB-1k\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 06_vision_transformer_2020\ntype: benchmark\ndetails: used for performance evaluation", "x": 123.47789046345787, "y": -235.73267872812121}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "Low-Rank Adaptation (LoRA) emerged as a method to efficiently adapt large pre-trained language models by freezing model weights and injecting trainable rank decomposition matrices. Proposed by Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen from Microsoft Corporation, LoRA addresses the limitations of traditional fine-tuning methods, particularly their resource demands. The method significantly reduces the number of trainable parameters while maintaining or improving model performance, demonstrated by its application to models like GPT-2, RoBERTa, and DeBERTa.\n\nLoRA extends the concept of transfer learning by offering a parameter-efficient adaptation strategy that does not introduce inference latency or reduce input sequence length. The method supports the notion of rank-deficiency in language model adaptation, providing empirical evidence of its efficacy. By using a similar bottleneck structure to impose a low-rank constraint on weight updates, LoRA explains the process of parameter-efficient adaptation, offering a competitive alternative to full fine-tuning on natural language understanding tasks.\n\nThe research also investigates the effect of rank on model performance and evaluates LoRA\u0027s performance on tasks from the GLUE benchmark. The method\u0027s empirical advantage is further supported by validation loss and test metrics achieved on the E2E NLG Challenge dataset. LoRA\u0027s integration with PyTorch models facilitates its application, and the method uses optimization techniques like Adam and AdamW to fine-tune learning rates effectively.\n\nLoRA\u0027s development involved investigating various aspects of model adaptation, such as weight matrices and parameter updates, to optimize performance under a parameter budget constraint. The method also explores contemporary extensions like COMPACTER and investigates alternative approaches like prefix tuning. Through these efforts, LoRA not only supports empirical investigations but also extends the landscape of efficient model adaptation strategies.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Low-Rank Adaptation", "id": "method:low_rank_adaptation", "label": "Low-Rank Adaptation", "node_degree": 48, "shape": "dot", "size": 50, "title": "Low-Rank Adaptation\nType: METHOD\nConnections: 48\nConfidence: 100%\nSources: 07_lora_2021\ndescription: A method for efficiently adapting large pre-trained language models by freezing model weights and injecting trainable rank decomposition matrices.", "x": -96.7841463916958, "y": -223.5052727455783}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "DeBERTa, a model developed as a variant of BERT, enhances its predecessors BERT and RoBERTa by incorporating disentangled attention. This improvement aims to refine the model\u0027s ability to process and understand language. Researchers applied Low-Rank Adaptation (LoRA) to DeBERTa to assess its downstream task performance, as documented in the study by He et al. (2021). The evaluation revealed that LoRA could match or surpass the performance of a fully fine-tuned DeBERTa XXL, demonstrating the model\u0027s robustness and adaptability. Additionally, the training process for DeBERTa involved using the AdamW optimizer with a linear learning rate decay schedule, further optimizing its performance.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "DeBERTa", "id": "system:deberta", "label": "DeBERTa", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "DeBERTa\nType: SYSTEM\nConnections: 2\nConfidence: 100%\nSources: 07_lora_2021\ndescription: A model that improves BERT and RoBERTa by using disentangled attention.", "x": 236.2885441972623, "y": 30.313493253254876}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "rank-deficiency in language model adaptation", "id": "finding:rank_deficiency_in_language_model_adaptation", "label": "rank-deficiency in language model adaptation", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "rank-deficiency in language model adaptation\nType: FINDING\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\ndescription: An empirical investigation that sheds light on the efficacy of LoRA.", "x": -125.3750229329671, "y": -168.17171052352847}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "conditional language modeling", "id": "phenomenon:conditional_language_modeling", "label": "conditional language modeling", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "conditional language modeling\nType: PHENOMENON\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\ndescription: The task of predicting the next word in a sequence given the previous words.", "x": 104.24060454991888, "y": 178.12307944926818}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "PyTorch, an open-source machine learning library, facilitates the integration of Low-Rank Adaptation (LoRA) models, as evidenced by the release of a package specifically designed for this purpose. Researchers have utilized PyTorch to implement the DPO loss, demonstrating its straightforward application in machine learning tasks. Additionally, PyTorch\u0027s reference implementations for exact attention are compared against FlashAttention, highlighting its role in advancing attention mechanisms in machine learning.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "PyTorch", "id": "system:pytorch", "label": "PyTorch", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "PyTorch\nType: SYSTEM\nConnections: 2\nConfidence: 100%\nSources: 07_lora_2021, 09_flash_attention_2022, 12_dpo_2023\ndescription: An open-source machine learning library used for applications such as computer vision and natural language processing.", "x": 132.43632433288013, "y": -196.69658418430618}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "prefix tuning", "id": "method:prefix_tuning", "label": "prefix tuning", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "prefix tuning\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\ndescription: A method that involves reserving part of the sequence length for adaptation.", "x": 175.81197906600613, "y": 36.85507079366545}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Aghajanyan et al. (2020)", "id": "researcher:aghajanyan_et_al_2020", "label": "Aghajanyan et al. (2020)", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Aghajanyan et al. (2020)\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\ncontribution: showed that pre-trained language models have a low intrinsic dimension.", "x": 232.89002139702365, "y": 100.04196051543892}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "E2E NLG Challenge", "id": "system:e2e_nlg_challenge", "label": "E2E NLG Challenge", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "E2E NLG Challenge\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021", "x": -180.07007117659052, "y": 45.708979346881165}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Adapter tuning", "id": "method:adapter_tuning", "label": "Adapter tuning", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Adapter tuning\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021", "x": -24.44985088666536, "y": 113.47013069295252}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "AdapterL", "id": "system:adapterl", "label": "AdapterL", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "AdapterL\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021", "x": 64.57371686639573, "y": -217.8894236150451}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "AdapterP", "id": "system:adapterp", "label": "AdapterP", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "AdapterP\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021", "x": 38.80258366635212, "y": -127.78145650942201}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "In 2019, Houlsby et al. proposed the method of adapter tuning, which has been influential in the field of machine learning. This method involves adding small, trainable layers, known as adapters, to a pre-trained model, allowing for efficient fine-tuning on new tasks without altering the original model\u0027s parameters significantly. The concept of adapter tuning was further explored in the context of Low-Rank Adaptation, which was also proposed by Houlsby et al. in the same year. This innovative approach has been referenced in subsequent research, including the work titled \"07_lora_2021,\" indicating its impact and continued relevance in the development of adaptive machine learning systems.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Houlsby et al.", "id": "researcher:houlsby_et_al", "label": "Houlsby et al.", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Houlsby et al.\nType: RESEARCHER\nConnections: 2\nConfidence: 100%\nSources: 07_lora_2021\nyear: 2019", "x": 163.0676397690617, "y": 240.94195544492135}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Lin et al.", "id": "researcher:lin_et_al", "label": "Lin et al.", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Lin et al.\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\nyear: 2020", "x": 74.77819127950352, "y": -244.87677718909873}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Pfeiffer et al.", "id": "researcher:pfeiffer_et_al", "label": "Pfeiffer et al.", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Pfeiffer et al.\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\nyear: 2021", "x": 169.86531393406517, "y": -78.53611991816956}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Gardent et al.", "id": "researcher:gardent_et_al", "label": "Gardent et al.", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Gardent et al.\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\nyear: 2017", "x": 73.98496355635814, "y": -147.08607875444545}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Nan et al.", "id": "researcher:nan_et_al", "label": "Nan et al.", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Nan et al.\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\nyear: 2020", "x": -13.17375195657354, "y": 215.0581103992884}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "COMPACTER", "id": "system:compacter", "label": "COMPACTER", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "COMPACTER\nType: SYSTEM\nConnections: 1\nConfidence: 80%\nSources: 07_lora_2021\ndescription: A contemporary extension of adapter that parametrizes the adapter layers using Kronecker products.", "x": 165.58012044766093, "y": 209.5741890206951}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "parameter-efficient adaptation", "id": "method:parameter_efficient_adaptation", "label": "parameter-efficient adaptation", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "parameter-efficient adaptation\nType: METHOD\nConnections: 1\nConfidence: 80%\nSources: 07_lora_2021\ndescription: Inserting adapter layers between existing layers in a neural network.", "x": 46.04200984091506, "y": -18.360414939611104}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "empirical advantage", "id": "finding:empirical_advantage", "label": "empirical advantage", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "empirical advantage\nType: FINDING\nConnections: 1\nConfidence: 80%\nSources: 07_lora_2021\ndescription: The observed benefits of using LoRA in terms of performance.", "x": 112.28803279686349, "y": -241.55318156949153}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "weight matrices", "id": "concept:weight_matrices", "label": "weight matrices", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "weight matrices\nType: CONCEPT\nConnections: 1\nConfidence: 70%\nSources: 07_lora_2021\ndescription: Matrices in a neural network that are adjusted during training.", "x": 58.20623139428676, "y": -51.080255844064936}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "rank", "id": "concept:rank", "label": "rank", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "rank\nType: CONCEPT\nConnections: 1\nConfidence: 70%\nSources: 07_lora_2021\ndescription: A measure of the dimensionality of a matrix.", "x": -129.18169697561754, "y": 220.64208830057498}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Edward Hu", "id": "researcher:edward_hu", "label": "Edward Hu", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Edward Hu\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\nrole: author", "x": -217.42220326852885, "y": -57.81300382444721}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Yelong Shen", "id": "researcher:yelong_shen", "label": "Yelong Shen", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Yelong Shen\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\nrole: author", "x": -136.89099330843885, "y": 131.0437329675932}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Phillip Wallis", "id": "researcher:phillip_wallis", "label": "Phillip Wallis", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Phillip Wallis\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\nrole: author", "x": 41.20745899250875, "y": 186.62751631257345}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Zeyuan Allen-Zhu", "id": "researcher:zeyuan_allen_zhu", "label": "Zeyuan Allen-Zhu", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Zeyuan Allen-Zhu\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\nrole: author", "x": -100.15106252547656, "y": 206.48298216618775}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Yuanzhi Li", "id": "researcher:yuanzhi_li", "label": "Yuanzhi Li", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Yuanzhi Li\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\nrole: author", "x": -159.62966762716178, "y": 88.08514400906506}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Shean Wang", "id": "researcher:shean_wang", "label": "Shean Wang", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Shean Wang\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\nrole: author", "x": -61.09134308921267, "y": 37.46019632793883}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Lu Wang", "id": "researcher:lu_wang", "label": "Lu Wang", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Lu Wang\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\nrole: author", "x": -224.69822471197503, "y": 120.83925384832804}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Weizhu Chen", "id": "researcher:weizhu_chen", "label": "Weizhu Chen", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Weizhu Chen\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\nrole: author", "x": -73.96362575943795, "y": -190.86033287503935}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "subspace similarity", "id": "concept:subspace_similarity", "label": "subspace similarity", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "subspace similarity\nType: CONCEPT\nConnections: 1\nConfidence: 90%\nSources: 07_lora_2021\ndescription: A measure of how much two subspaces overlap.", "x": -91.32333909046548, "y": -145.63874581006547}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "Frobenius norm", "id": "concept:frobenius_norm", "label": "Frobenius norm", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Frobenius norm\nType: CONCEPT\nConnections: 1\nConfidence: 90%\nSources: 07_lora_2021\ndescription: A measure used to compare matrices.", "x": 100.28117631655664, "y": 211.19635730585645}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "empirical investigations", "id": "finding:empirical_investigations", "label": "empirical investigations", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "empirical investigations\nType: FINDING\nConnections: 1\nConfidence: 70%\nSources: 07_lora_2021\ndescription: Results from studies that provide evidence for the effectiveness of LoRA.", "x": 100.69351942441682, "y": 226.06215382863576}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#6862e8", "highlight": {"background": "#FFEE58", "border": "#6862e8"}}, "community": "Question Answering and Evaluation Datasets", "description": "AdamW, an optimizer used for training models, was developed by Loshchilov and Hutter in 2017. It has been employed in various significant systems, including GPT-2, where it was specifically mentioned as the method used for training. Additionally, AdamW was utilized in the training of models for Low-Rank Adaptation, as indicated by the reference to \"Optimizer - AdamW.\" The LLaMA models also relied on AdamW for their training processes, demonstrating the optimizer\u0027s widespread application in contemporary machine learning systems.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "AdamW", "id": "method:adamw", "label": "AdamW", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "AdamW\nType: METHOD\nConnections: 3\nCommunity: Question Answering and Evaluation Datasets\nConfidence: 100%\nSources: 07_lora_2021, 11_llama_2023\ndescription: an optimizer used for training models", "x": 95.9000173153969, "y": -947.7469752731575}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "Parameter updates", "id": "phenomenon:parameter_updates", "label": "Parameter updates", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Parameter updates\nType: PHENOMENON\nConnections: 1\nConfidence: 70%\nSources: 07_lora_2021\ndescription: The need for updates in large language models.", "x": -127.93956405792068, "y": 241.5873215852355}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "Adapter layers function as external modules added sequentially to pre-trained models. This approach is mentioned in the 2021 document titled \"07_lora_2021.\" However, the concept of adapter layers faces criticism from proponents of Low-Rank Adaptation (LoRA), who argue that adapter layers introduce inference latency. LoRA, described as external modules added in a parallel manner, is presented as an alternative that addresses this latency issue.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Adapter layers", "id": "system:adapter_layers", "label": "Adapter layers", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Adapter layers\nType: SYSTEM\nConnections: 2\nConfidence: 80%\nSources: 07_lora_2021\ndescription: External modules added to a pre-trained model.", "x": -125.93408502503223, "y": -132.13701735119676}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "DART", "id": "system:dart", "label": "DART", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "DART\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\ndescription: A dataset used for evaluating natural language generation.", "x": -106.12979725827975, "y": -77.62327860911722}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "WebNLG", "id": "system:webnlg", "label": "WebNLG", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "WebNLG\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\ndescription: A dataset used for evaluating natural language generation.", "x": -224.7037843447031, "y": 15.870968641582635}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "LoRA+PrefixEmbed", "id": "system:lora_prefixembed", "label": "LoRA+PrefixEmbed", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "LoRA+PrefixEmbed\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\ndescription: Combination of LoRA with prefix-embedding tuning.", "x": 24.777483811118827, "y": 112.92362331700065}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "LoRA+PrefixLayer", "id": "system:lora_prefixlayer", "label": "LoRA+PrefixLayer", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "LoRA+PrefixLayer\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\ndescription: Combination of LoRA with prefix-layer tuning.", "x": 122.04420427172903, "y": 145.949541513834}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "Validation loss", "id": "finding:validation_loss", "label": "Validation loss", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Validation loss\nType: FINDING\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\ndescription: A metric used to evaluate model performance.", "x": 115.17352235784324, "y": -149.30464272680234}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "NIST", "id": "finding:nist", "label": "NIST", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "NIST\nType: FINDING\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\ndescription: A metric for evaluating machine translation.", "x": -128.52209835418603, "y": 67.08531592420775}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "METEOR", "id": "finding:meteor", "label": "METEOR", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "METEOR\nType: FINDING\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\ndescription: A metric for evaluating machine translation.", "x": -198.61274828461052, "y": 64.87960129329088}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "ROUGE L", "id": "finding:rouge_l", "label": "ROUGE L", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "ROUGE L\nType: FINDING\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\ndescription: A metric for evaluating automatic summarization.", "x": 94.30260377547103, "y": 189.86897843075377}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "CIDEr", "id": "finding:cider", "label": "CIDEr", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "CIDEr\nType: FINDING\nConnections: 1\nConfidence: 100%\nSources: 07_lora_2021\ndescription: A metric for evaluating image captioning.", "x": -106.83611561798563, "y": 121.88224452076514}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#b062e8", "highlight": {"background": "#FFEE58", "border": "#b062e8"}}, "community": "Chain-of-Thought and Reasoning Techniques", "description": "Chain-of-Thought Prompting, proposed by Jason Wei, Xuezhi Wang, Denny Zhou, and others, enhances the reasoning capabilities of large language models by incorporating intermediate reasoning steps into prompts. This method significantly improves performance on complex tasks such as arithmetic and commonsense reasoning, as demonstrated by its success on benchmarks like GSM8K for math word problems. By facilitating length generalization beyond seen chains of thought, Chain-of-Thought Prompting supports the emergent ability of model scale, leading to larger performance gains for more complicated problems.\n\nThe method has been applied to various reasoning tasks, including arithmetic, commonsense, and symbolic reasoning, where it enables language models to perform multi-step reasoning tasks. Chain-of-Thought Prompting extends the concept of natural language explanations by allowing models to decompose multi-hop reasoning tasks into multiple steps. This approach has been associated with program synthesis and execution, as well as numeric and logical reasoning, which have long been studied in machine learning and natural language processing.\n\nChain-of-Thought Prompting has been tested on models such as LaMDA, GPT-3, and PaLM, with PaLM 540B achieving strong performance relative to baselines. The method\u0027s effectiveness is evident in its ability to outperform traditional prompting methods, achieving state-of-the-art results on benchmarks like GSM8K. The improvement over standard prompting remains robust, demonstrating the method\u0027s potential to enhance the reasoning capabilities of large language models across various tasks.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Chain-of-Thought Prompting", "id": "method:chain_of_thought_prompting", "label": "Chain-of-Thought Prompting", "node_degree": 39, "shape": "dot", "size": 50, "title": "Chain-of-Thought Prompting\nType: METHOD\nConnections: 39\nCommunity: Chain-of-Thought and Reasoning Techniques\nConfidence: 100%\nSources: 08_chain_of_thought_2022\ndescription: A method that enhances reasoning capabilities of large language models by providing intermediate reasoning steps in prompts.", "x": 17.599858526530227, "y": 1085.1551948819226}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#b062e8", "highlight": {"background": "#26C6DA", "border": "#b062e8"}}, "community": "Chain-of-Thought and Reasoning Techniques", "description": "GSM8K serves as a benchmark consisting of middle school mathematical problems, utilized to evaluate the performance of various models in mathematical reasoning tasks. Researchers applied Chain-of-Thought Prompting to models like GPT-3 175B and PaLM 540B, achieving state-of-the-art accuracy on GSM8K. This method significantly outperformed traditional prompting techniques, demonstrating its effectiveness in solving math word problems. Additionally, the LLaMA model was evaluated using GSM8K, further underscoring the benchmark\u0027s role in assessing mathematical reasoning capabilities.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "GSM8K", "id": "system:gsm8k", "label": "GSM8K", "node_degree": 4, "shape": "dot", "size": 16.0, "title": "GSM8K\nType: SYSTEM\nConnections: 4\nCommunity: Chain-of-Thought and Reasoning Techniques\nConfidence: 100%\nSources: 08_chain_of_thought_2022, 11_llama_2023\ndescription: a set of middle school mathematical problems", "x": 21.09029603432765, "y": 1024.7702333782897}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#66BB6A", "border": "#b062e8", "highlight": {"background": "#66BB6A", "border": "#b062e8"}}, "community": "Chain-of-Thought and Reasoning Techniques", "description": "Chain-of-thought prompting significantly enhances arithmetic reasoning by improving performance on complex tasks such as solving math word problems. This method, which involves breaking down problems into sequential steps, has been shown to outperform traditional prompting techniques, particularly on challenging benchmarks like GSM8K. The utility of chain-of-thought prompting is evident as it remains robust across different exemplar orders, leading to substantial performance gains, especially for large models like PaLM 540B. In contrast, standard prompting methods fail to achieve similar results, highlighting the effectiveness of this approach in tackling multi-step arithmetic problems.", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "arithmetic reasoning", "id": "phenomenon:arithmetic_reasoning", "label": "arithmetic reasoning", "node_degree": 4, "shape": "dot", "size": 16.0, "title": "arithmetic reasoning\nType: PHENOMENON\nConnections: 4\nCommunity: Chain-of-Thought and Reasoning Techniques\nConfidence: 100%\nSources: 08_chain_of_thought_2022\ndescription: A type of reasoning that involves solving math word problems.", "x": 110.14969039800309, "y": 1132.3312064366332}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#66BB6A", "border": "#b062e8", "highlight": {"background": "#66BB6A", "border": "#b062e8"}}, "community": "Chain-of-Thought and Reasoning Techniques", "description": "Researchers evaluated the capability of systems to perform commonsense reasoning by using eight standard benchmarks. They applied chain-of-thought prompting, which demonstrated significant improvements over traditional methods. This approach, characterized by its linguistic nature, proved broadly applicable to commonsense reasoning tasks, as well as complex tasks like arithmetic. The findings from these experiments highlighted the utility of chain-of-thought prompting in achieving state-of-the-art results on benchmarks such as GSM8K for math word problems. Additionally, the LLaMA model supported these evaluations by considering the eight standard commonsense reasoning benchmarks, further validating the effectiveness of this method.", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "CommonSense Reasoning", "id": "phenomenon:commonsense_reasoning", "label": "CommonSense Reasoning", "node_degree": 5, "shape": "dot", "size": 18.5, "title": "CommonSense Reasoning\nType: PHENOMENON\nConnections: 5\nCommunity: Chain-of-Thought and Reasoning Techniques\nConfidence: 100%\nSources: 08_chain_of_thought_2022, 11_llama_2023\ndescription: a type of reasoning task evaluated in the study", "x": 1.145967031486947, "y": 1031.287263937875}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#66BB6A", "border": "#b062e8", "highlight": {"background": "#66BB6A", "border": "#b062e8"}}, "community": "Chain-of-Thought and Reasoning Techniques", "description": "Chain-of-thought prompting enables language models to perform symbolic reasoning tasks, as demonstrated in the research focusing on multi-step reasoning tasks such as arithmetic, commonsense, and symbolic reasoning. This method supports out-of-distribution generalization to longer sequence lengths, highlighting its utility in handling tasks that are simple for humans but challenging for language models. The study, mentioned in the 2022 paper \"08_chain_of_thought,\" explores the application of chain-of-thought prompting in symbolic reasoning, emphasizing its role in facilitating complex reasoning processes.", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "symbolic reasoning", "id": "phenomenon:symbolic_reasoning", "label": "symbolic reasoning", "node_degree": 4, "shape": "dot", "size": 16.0, "title": "symbolic reasoning\nType: PHENOMENON\nConnections: 4\nCommunity: Chain-of-Thought and Reasoning Techniques\nConfidence: 100%\nSources: 08_chain_of_thought_2022\ndescription: A type of reasoning that involves manipulating symbols and abstract concepts.", "x": 163.36456728593018, "y": 1236.3117732522305}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#b062e8", "highlight": {"background": "#FFEE58", "border": "#b062e8"}}, "community": "Chain-of-Thought and Reasoning Techniques", "description": "Standard prompting, a method where a language model receives input-output pairs, was popularized by Brown et al. in 2020. This traditional approach has been scrutinized for its limitations, particularly in complex tasks. Evidence shows that standard prompting fails in arithmetic reasoning tasks, highlighting its inadequacy in certain contexts. Furthermore, the method is contradicted by the advancements of chain-of-thought prompting, which demonstrates robust improvements over standard prompting. These findings suggest that while standard prompting laid foundational groundwork, it is often surpassed by more sophisticated techniques in handling intricate reasoning tasks.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "standard prompting", "id": "method:standard_prompting", "label": "standard prompting", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "standard prompting\nType: METHOD\nConnections: 2\nCommunity: Chain-of-Thought and Reasoning Techniques\nConfidence: 100%\nSources: 08_chain_of_thought_2022\ndescription: A traditional method of prompting where a language model is given input-output pairs.", "x": 249.31056911397292, "y": 1218.870689111725}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Jason Wei", "id": "researcher:jason_wei", "label": "Jason Wei", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Jason Wei\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 08_chain_of_thought_2022\nrole: Author", "x": -169.45450462188316, "y": 91.68940907169042}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Xuezhi Wang", "id": "researcher:xuezhi_wang", "label": "Xuezhi Wang", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Xuezhi Wang\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 08_chain_of_thought_2022\nrole: Author", "x": 23.874112265970894, "y": 87.93034648224415}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Denny Zhou", "id": "researcher:denny_zhou", "label": "Denny Zhou", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Denny Zhou\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 08_chain_of_thought_2022\nrole: Author", "x": -15.789134436498216, "y": -73.3681297869066}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#b062e8", "highlight": {"background": "#AB47BC", "border": "#b062e8"}}, "community": "Chain-of-Thought and Reasoning Techniques", "description": "Brown et al. (2020) developed methods for zero-shot and few-shot tasks, which have been referenced in subsequent research on large-scale language models. Their work on few-shot prompting has been particularly influential, as seen in its application in later studies like \"08_chain_of_thought_2022\" and \"11_llama_2023.\" Brown et al. also contributed to the growing interest in enhancing task performance through prompting, a technique that has been further explored in the context of Chain-of-Thought Prompting.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Brown et al.", "id": "researcher:brown_et_al", "label": "Brown et al.", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Brown et al.\nType: RESEARCHER\nConnections: 1\nCommunity: Chain-of-Thought and Reasoning Techniques\nConfidence: 100%\nSources: 08_chain_of_thought_2022, 11_llama_2023\nrole: previous work reference", "x": 127.47295964198477, "y": 936.6587232897407}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#b062e8", "highlight": {"background": "#AB47BC", "border": "#b062e8"}}, "community": "Chain-of-Thought and Reasoning Techniques", "description": "Cobbe et al. proposed the GSM8k benchmark, which is used to evaluate mathematical reasoning models. Their work is mentioned in the context of chain-of-thought prompting, particularly with the PaLM 540B model, which significantly outperforms standard prompting methods. This connection highlights the relevance of GSM8k in advancing state-of-the-art performance in mathematical reasoning tasks.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Cobbe et al.", "id": "researcher:cobbe_et_al", "label": "Cobbe et al.", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Cobbe et al.\nType: RESEARCHER\nConnections: 1\nCommunity: Chain-of-Thought and Reasoning Techniques\nConfidence: 100%\nSources: 08_chain_of_thought_2022, 11_llama_2023\nrole: proposed GSM8k", "x": 324.4739127168215, "y": 1050.749620163422}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#b062e8", "highlight": {"background": "#26C6DA", "border": "#b062e8"}}, "community": "Chain-of-Thought and Reasoning Techniques", "description": "LaMDA, a large language model developed by Thoppilan et al. in 2022, was evaluated in various parameter sizes, including 422M, 2B, 8B, 68B, and 137B. The model utilized Chain-of-Thought Prompting, a method that improved its performance when compared to other models like GPT-3 and PaLM. This method supported LaMDA\u0027s ability to produce both correct and incorrect chains of thought, as demonstrated in examples from the study. Results for LaMDA\u0027s performance, alongside those of GPT-3 and different model scales, were detailed in tables within the research, highlighting the model\u0027s capabilities and limitations.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "LaMDA", "id": "system:lamda", "label": "LaMDA", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "LaMDA\nType: SYSTEM\nConnections: 2\nCommunity: Chain-of-Thought and Reasoning Techniques\nConfidence: 100%\nSources: 08_chain_of_thought_2022\ndescription: a large language model with various parameter sizes evaluated in the study", "x": 437.6150796101722, "y": 994.9326230444701}, {"aliases": "PaLM 540B, PaLM540B", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#b062e8", "highlight": {"background": "#26C6DA", "border": "#b062e8"}}, "community": "Chain-of-Thought and Reasoning Techniques", "description": "PaLM, a large language model with 540 billion parameters, demonstrates strong performance through the use of chain-of-thought prompting. This method significantly enhances its problem-solving capabilities, achieving nearly 100% solver rates on tasks like GSM8K. Despite its prowess, PaLM faces competition from models like LLaMA-65B, which is noted for being competitive with PaLM-540B and other leading models such as Chinchilla-70B. PaLM\u0027s performance is further scrutinized through error analysis, as evidenced by a manual review of 45 errors made by its 62B parameter variant. This analysis provides insights into the model\u0027s limitations and areas for improvement.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "PaLM", "id": "system:palm", "label": "PaLM", "node_degree": 6, "shape": "dot", "size": 21.0, "title": "PaLM\nType: SYSTEM\nConnections: 6\nCommunity: Chain-of-Thought and Reasoning Techniques\nConfidence: 100%\nSources: 08_chain_of_thought_2022, 11_llama_2023\ndescription: a large language model\nparameters: 540B\naliases: [\u0027PaLM 540B\u0027, \u0027PaLM540B\u0027]", "x": 344.47239833575316, "y": 1316.7951946247213}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "emergent ability of model scale", "id": "finding:emergent_ability_of_model_scale", "label": "emergent ability of model scale", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "emergent ability of model scale\nType: FINDING\nConnections: 1\nConfidence: 100%\nSources: 08_chain_of_thought_2022\ndescription: chain-of-thought prompting is an emergent ability that does not positively impact performance for small models", "x": 14.075384292435274, "y": 227.57750011274914}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "performance gains for complicated problems", "id": "finding:performance_gains_for_complicated_problems", "label": "performance gains for complicated problems", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "performance gains for complicated problems\nType: FINDING\nConnections: 1\nConfidence: 100%\nSources: 08_chain_of_thought_2022\ndescription: chain-of-thought prompting has larger performance gains for more complicated problems", "x": 58.90047898336189, "y": -227.17989732518922}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "intermediate steps", "id": "concept:intermediate_steps", "label": "intermediate steps", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "intermediate steps\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 08_chain_of_thought_2022", "x": 123.47541416784799, "y": 212.1802628865766}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "model scale", "id": "concept:model_scale", "label": "model scale", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "model scale\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 08_chain_of_thought_2022", "x": 37.46822631813973, "y": -201.30204400806113}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#b062e8", "highlight": {"background": "#AB47BC", "border": "#b062e8"}}, "community": "Chain-of-Thought and Reasoning Techniques", "description": "Ling et al. (2017) pioneered the use of natural language rationales to solve math word problems, marking a significant advancement in the intersection of language processing and mathematical reasoning. Their innovative approach laid the groundwork for subsequent research, as evidenced by Cobbe et al. (2021), who extended Ling et al.\u0027s work by creating a larger dataset to further explore and validate these methods. Ling et al.\u0027s contribution is also recognized in later works, such as the 2022 study on chain of thought reasoning, which mentions their foundational role in developing intermediate steps for problem-solving in this domain.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Ling et al. (2017)", "id": "researcher:ling_et_al_2017", "label": "Ling et al. (2017)", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Ling et al. (2017)\nType: RESEARCHER\nConnections: 2\nCommunity: Chain-of-Thought and Reasoning Techniques\nConfidence: 100%\nSources: 08_chain_of_thought_2022\ncontribution: pioneered the idea of using natural language rationales to solve math word problems", "x": 252.20871568556157, "y": 1156.675121107968}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Nye et al. (2021)", "id": "researcher:nye_et_al_2021", "label": "Nye et al. (2021)", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Nye et al. (2021)\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 08_chain_of_thought_2022\ncontribution: leveraged language models to predict the final outputs of Python programs", "x": -28.711105177706543, "y": -164.11642037375458}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "arithmetic and commonsense reasoning", "id": "phenomenon:arithmetic_and_commonsense_reasoning", "label": "arithmetic and commonsense reasoning", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "arithmetic and commonsense reasoning\nType: PHENOMENON\nConnections: 1\nConfidence: 80%\nSources: 08_chain_of_thought_2022", "x": -15.371204832525137, "y": -51.22035893596805}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "large language models", "id": "phenomenon:large_language_models", "label": "large language models", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "large language models\nType: PHENOMENON\nConnections: 1\nConfidence: 80%\nSources: 08_chain_of_thought_2022\ndescription: models that process and generate human-like text", "x": -92.30808262877233, "y": 169.06880081235875}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "error analysis", "id": "method:error_analysis", "label": "error analysis", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "error analysis\nType: METHOD\nConnections: 1\nConfidence: 70%\nSources: 08_chain_of_thought_2022\ndescription: a process of reviewing and categorizing errors made by models", "x": -199.42114303685776, "y": -148.1961242194615}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#9CCC65", "border": "#b062e8", "highlight": {"background": "#9CCC65", "border": "#b062e8"}}, "community": "Chain-of-Thought and Reasoning Techniques", "description": "Cobbe et al. (2021) expanded upon the work of Ling et al. (2017) by developing a larger dataset, known as the GSM8K dataset, which includes reasoning chains crafted by crowd compute workers. This dataset serves as a training set and is instrumental in the study of reasoning processes. Cobbe et al. (2021) also explored the application of an external calculator to equations, a method that was noted in their research. Their work is referenced in the context of Chain-of-Thought Prompting, where similar observations were made, and it is mentioned in the 08_chain_of_thought_2022 publication.", "entity_type": "PUBLICATION", "font": {"color": "#e0e0e0"}, "full_name": "Cobbe et al. (2021)", "id": "publication:cobbe_et_al_2021", "label": "Cobbe et al. (2021)", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "Cobbe et al. (2021)\nType: PUBLICATION\nConnections: 3\nCommunity: Chain-of-Thought and Reasoning Techniques\nConfidence: 100%\nSources: 08_chain_of_thought_2022\ndescription: a study that provides a training set with reasoning chains written by crowd compute workers", "x": 281.43448221741073, "y": 1211.0044174067004}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "LaMDA137B", "id": "system:lamda137b", "label": "LaMDA137B", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "LaMDA137B\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 08_chain_of_thought_2022\ndescription: a large language model used in the experiments", "x": 152.4808867380022, "y": 173.7005448517686}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "natural language explanations", "id": "concept:natural_language_explanations", "label": "natural language explanations", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "natural language explanations\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 08_chain_of_thought_2022\ndescription: explanations provided in natural language to improve model interpretability", "x": 49.674165404922746, "y": -50.49146049032444}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "program synthesis and execution", "id": "concept:program_synthesis_and_execution", "label": "program synthesis and execution", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "program synthesis and execution\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 08_chain_of_thought_2022\ndescription: the process of generating and executing programs, often involving intermediate reasoning steps", "x": 147.84164904178448, "y": 77.97055451153216}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "numeric and logical reasoning", "id": "concept:numeric_and_logical_reasoning", "label": "numeric and logical reasoning", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "numeric and logical reasoning\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 08_chain_of_thought_2022\ndescription: tasks in machine learning and natural language processing that involve numerical and logical reasoning", "x": 3.9704876934290496, "y": 207.54236648284245}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "intermediate language steps", "id": "concept:intermediate_language_steps", "label": "intermediate language steps", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "intermediate language steps\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 08_chain_of_thought_2022\ndescription: the ability of neural networks to produce intermediate steps during reasoning", "x": 147.89743556183782, "y": 81.73593961981885}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "calculator error", "id": "finding:calculator_error", "label": "calculator error", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "calculator error\nType: FINDING\nConnections: 1\nConfidence: 80%\nSources: 08_chain_of_thought_2022\ndescription: errors that can be corrected by applying an external calculator to equations", "x": 151.30303687631277, "y": 198.84951412709847}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#b062e8", "highlight": {"background": "#EF5350", "border": "#b062e8"}}, "community": "Chain-of-Thought and Reasoning Techniques", "description": "Thoppilan et al. (2022) proposed the concept of multi-step reasoning abilities in language models, emphasizing the potential improvements through training verifiers. This concept is mentioned in the 2022 paper \"Chain-of-Thought Prompting,\" which explores enhancing the factuality of language model generations. The paper suggests that improving context and world knowledge could potentially enhance multi-step reasoning abilities.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "multi-step reasoning abilities", "id": "concept:multi_step_reasoning_abilities", "label": "multi-step reasoning abilities", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "multi-step reasoning abilities\nType: CONCEPT\nConnections: 2\nCommunity: Chain-of-Thought and Reasoning Techniques\nConfidence: 80%\nSources: 08_chain_of_thought_2022\ndescription: the capability of language models to perform reasoning across multiple steps", "x": 389.3170318204456, "y": 976.0365515238059}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#9CCC65", "border": "#333", "highlight": {"background": "#9CCC65", "border": "#333"}}, "community": "", "description": "", "entity_type": "PUBLICATION", "font": {"color": "#e0e0e0"}, "full_name": "Thoppilan et al. (2022)", "id": "publication:thoppilan_et_al_2022", "label": "Thoppilan et al. (2022)", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Thoppilan et al. (2022)\nType: PUBLICATION\nConnections: 1\nConfidence: 70%\nSources: 08_chain_of_thought_2022\ndescription: a reference to a study related to improving language model outputs", "x": -107.68273765825194, "y": 130.51506393607332}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "math word problems", "id": "phenomenon:math_word_problems", "label": "math word problems", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "math word problems\nType: PHENOMENON\nConnections: 1\nConfidence: 100%\nSources: 08_chain_of_thought_2022\ndescription: problems that require mathematical reasoning to solve", "x": -87.33675196876601, "y": 134.265218549826}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e8d862", "highlight": {"background": "#26C6DA", "border": "#e8d862"}}, "community": "Efficient Attention Mechanisms and Implementations", "description": "FlashAttention, an innovative attention algorithm, significantly enhances the efficiency of Transformer models by being up to three times faster than standard attention implementations across sequence lengths from 128 to 2K, and it scales up to 64K. Proposed by Tri Dao, Daniel Y. Fu, Stefano Ermon, Atri Rudra, and Christopher R\u00e9, FlashAttention is designed to be IO-aware, utilizing techniques such as tiling to reduce memory reads and writes, thereby optimizing the computation of attention on GPUs.\n\nThe algorithm extends the capabilities of Transformer models and block-sparse attention, offering a useful primitive for handling block-sparse attention. It supports various systems, including BERT-Large and GPT-2, by providing the same validation curves as baseline implementations and achieving a 15% end-to-end wall-clock speedup on BERT-large. FlashAttention also investigates challenges like Path-X and Path-256, where it enables Transformers to achieve better-than-chance performance.\n\nFlashAttention employs methods such as kernel fusion, softmax, and gradient checkpointing to enhance performance. It reduces I/O complexity by minimizing HBM accesses during both forward and backward passes on GPUs. The algorithm\u0027s efficiency is further demonstrated by its performance improvements on datasets like MIMIC-III and ECtHR, and it achieves up to a 2.4\u00d7 speed-up in the Long-range arena compared to standard attention.\n\nDespite its advancements, FlashAttention contradicts other attention mechanisms like Linformer, Performer, Local Attention, Reformer, and SMYRF by being twice as efficient. It supports these systems by providing substantial performance metrics, showcasing its superiority in handling long sequences and improving overall computational efficiency.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "FlashAttention", "id": "system:flashattention", "label": "FlashAttention", "node_degree": 63, "shape": "dot", "size": 50, "title": "FlashAttention\nType: SYSTEM\nConnections: 63\nCommunity: Efficient Attention Mechanisms and Implementations\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: An IO-aware exact attention algorithm that enhances the efficiency of Transformer models.", "x": -616.4310520954457, "y": 1184.8859207151304}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "Path-X challenge", "id": "phenomenon:path_x_challenge", "label": "Path-X challenge", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Path-X challenge\nType: PHENOMENON\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: A challenge that tests the performance of models on long sequences.", "x": -177.37117327178765, "y": 224.78676890232543}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "kernel fusion", "id": "method:kernel_fusion", "label": "kernel fusion", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "kernel fusion\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: An approach to accelerate memory-bound operations by combining multiple operations into a single kernel.", "x": 237.87889511303575, "y": -12.392742717548316}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "softmax", "id": "method:softmax", "label": "softmax", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "softmax\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: A mathematical function that converts a vector of numbers into probabilities.", "x": -171.708789576532, "y": 132.84120336126585}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "block-sparse attention", "id": "concept:block_sparse_attention", "label": "block-sparse attention", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "block-sparse attention\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: A variant of attention that focuses on a sparse subset of the input.", "x": 207.30576285969386, "y": 224.56346250288317}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Algorithm 1", "id": "method:algorithm_1", "label": "Algorithm 1", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Algorithm 1\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: The algorithm used to implement FlashAttention.", "x": -191.60671081382867, "y": 17.679391812799395}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Tri Dao", "id": "researcher:tri_dao", "label": "Tri Dao", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Tri Dao\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\nrole: Author of the paper.", "x": -60.362826673836366, "y": -0.5329483626774163}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Daniel Y. Fu", "id": "researcher:daniel_y_fu", "label": "Daniel Y. Fu", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Daniel Y. Fu\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\nrole: Author of the paper.", "x": -173.52893514722177, "y": 53.674406592819935}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#62d2e8", "highlight": {"background": "#AB47BC", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "Stefano Ermon co-authored the research paper \"FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness,\" collaborating with Tri Dao, Daniel Y. Fu, Atri Rudra, and Christopher R\u00e9. This work, which proposes the FlashAttention method, highlights Ermon\u0027s involvement in advancing efficient computational techniques. Additionally, Ermon contributed to the development of Direct Preference Optimization, a method presented at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023). In this project, he worked alongside Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D. Manning, and Chelsea Finn, showcasing his active engagement in cutting-edge research within the field of neural information processing.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Stefano Ermon", "id": "researcher:stefano_ermon", "label": "Stefano Ermon", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Stefano Ermon\nType: RESEARCHER\nConnections: 2\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 09_flash_attention_2022, 12_dpo_2023\nrole: author", "x": -1011.2286165936146, "y": 552.5121649604697}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Atri Rudra", "id": "researcher:atri_rudra", "label": "Atri Rudra", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Atri Rudra\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\nrole: Author of the paper.", "x": -177.82953225195513, "y": 13.969166794835473}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Christopher R\u00e9", "id": "researcher:christopher_re", "label": "Christopher R\u00e9", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Christopher R\u00e9\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\nrole: Author of the paper.", "x": -201.53365040436543, "y": -208.89200337817866}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "block-sparse FlashAttention", "id": "system:block_sparse_flashattention", "label": "block-sparse FlashAttention", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "block-sparse FlashAttention\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: An extension of FlashAttention that approximates attention with reduced IO complexity.", "x": -200.8521938406096, "y": 172.23313305640295}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "MIMIC-III", "id": "system:mimic_iii", "label": "MIMIC-III", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "MIMIC-III\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: A dataset containing intensive care unit patient discharge summaries.", "x": 38.75038061660405, "y": -2.1769155593891583}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "ECtHR", "id": "system:ecthr", "label": "ECtHR", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "ECtHR\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: A dataset containing legal cases from the European Court of Human Rights.", "x": 208.97399348920584, "y": 169.3002178120911}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e8d862", "highlight": {"background": "#26C6DA", "border": "#e8d862"}}, "community": "Efficient Attention Mechanisms and Implementations", "description": "Linformer, a system designed for efficient attention mechanisms, was compared against FlashAttention in terms of performance metrics. The comparison revealed that FlashAttention is twice as efficient as Linformer, as evidenced by the performance figures: \"FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19\" versus Linformer\u0027s \"0.89 0.80 0.81 0.93 2.48 4.75 9.29 18.27 36.53\". Despite this, Linformer remains a reference point in the field, as researchers continue to use its implementations for benchmarking purposes. The system\u0027s efficiency was tested across various scales, with performance metrics recorded at different attention method sizes, such as 128, 256, and up to 65536.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Linformer", "id": "system:linformer", "label": "Linformer", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "Linformer\nType: SYSTEM\nConnections: 3\nCommunity: Efficient Attention Mechanisms and Implementations\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: A model that is compared against FlashAttention.", "x": -507.5395329862118, "y": 1277.3829238042192}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Linear Attention", "id": "system:linear_attention", "label": "Linear Attention", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Linear Attention\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: A model that is compared against FlashAttention.", "x": 169.2845820882, "y": 72.01308155797489}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Performer", "id": "system:performer", "label": "Performer", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Performer\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: A model that is compared against FlashAttention.", "x": 111.26936638892812, "y": -25.96803820588474}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e8d862", "highlight": {"background": "#26C6DA", "border": "#e8d862"}}, "community": "Efficient Attention Mechanisms and Implementations", "description": "Local Attention, a system compared against FlashAttention, demonstrates varying levels of efficiency across different scales. The system\u0027s performance metrics, such as 0.55 at a smaller scale and 221.40 at a larger scale, highlight its scalability. However, FlashAttention, which supports these comparisons, shows superior efficiency, being twice as efficient as Linformer. The reference implementations of Local Attention serve as benchmarks in these comparisons, underscoring its role in evaluating newer systems like FlashAttention.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Local Attention", "id": "system:local_attention", "label": "Local Attention", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "Local Attention\nType: SYSTEM\nConnections: 3\nCommunity: Efficient Attention Mechanisms and Implementations\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: A model that is compared against FlashAttention.", "x": -528.8747652684135, "y": 1272.60534312667}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e8d862", "highlight": {"background": "#26C6DA", "border": "#e8d862"}}, "community": "Efficient Attention Mechanisms and Implementations", "description": "Reformer, a model known for its use of approximation with hashing to achieve sparse attention, is compared against FlashAttention in terms of efficiency. The evidence shows that Reformer is evaluated across various attention methods, with performance metrics provided for different scales, such as 128, 256, and up to 8192. Despite its innovative approach, FlashAttention is noted to be twice as efficient as Linformer, suggesting that Reformer may not match FlashAttention\u0027s efficiency. The comparison against reference implementations of Reformer further underscores its role in benchmarking attention mechanisms.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Reformer", "id": "system:reformer", "label": "Reformer", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "Reformer\nType: SYSTEM\nConnections: 3\nCommunity: Efficient Attention Mechanisms and Implementations\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: A model that is compared against FlashAttention.", "x": -769.0397909101384, "y": 1079.3716795359417}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e8d862", "highlight": {"background": "#26C6DA", "border": "#e8d862"}}, "community": "Efficient Attention Mechanisms and Implementations", "description": "SMYRF is a system that was evaluated in comparison to FlashAttention, as indicated by the reference implementations used in the analysis. The system\u0027s performance metrics, such as 1.41, 2.83, and 5.43, were recorded across various attention method sizes, demonstrating its scalability. Despite these metrics, FlashAttention was found to be more efficient, contradicting SMYRF\u0027s performance claims. The comparison highlighted that FlashAttention supports its efficiency with metrics like 0.11 and 0.16, which are significantly lower than those of SMYRF.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "SMYRF", "id": "system:smyrf", "label": "SMYRF", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "SMYRF\nType: SYSTEM\nConnections: 3\nCommunity: Efficient Attention Mechanisms and Implementations\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: A model that is compared against FlashAttention.", "x": -834.2237700088816, "y": 1213.6470825371475}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Path-256", "id": "system:path_256", "label": "Path-256", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Path-256\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: A benchmark designed to test long context in Transformer models.", "x": -174.31036653880875, "y": 85.42856739611926}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#e8d862", "highlight": {"background": "#EF5350", "border": "#e8d862"}}, "community": "Efficient Attention Mechanisms and Implementations", "description": "The IO-aware approach, which focuses on input/output efficiency in deep learning computations, extends the capabilities of existing models like FlashAttention and Transformers. Researchers have expressed hope that this approach will inspire the development of IO-aware implementations for additional modules, suggesting its potential to enhance computational efficiency across various deep learning architectures. The concept was mentioned in the 2022 paper on FlashAttention, indicating its relevance in current research discussions.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "IO-aware implementations", "id": "concept:io_aware_implementations", "label": "IO-aware implementations", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "IO-aware implementations\nType: CONCEPT\nConnections: 2\nCommunity: Efficient Attention Mechanisms and Implementations\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: Approaches that consider input/output efficiency in deep learning computations.", "x": -687.2088478900195, "y": 1247.3159467365142}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Multi-GPU IO-Aware Methods", "id": "method:multi_gpu_io_aware_methods", "label": "Multi-GPU IO-Aware Methods", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Multi-GPU IO-Aware Methods\nType: METHOD\nConnections: 1\nConfidence: 80%\nSources: 09_flash_attention_2022\ndescription: Methods that optimize attention computation across multiple GPUs.", "x": -104.30770392555249, "y": -235.2670167653419}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "NIH", "id": "researcher:nih", "label": "NIH", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "NIH\nType: RESEARCHER\nConnections: 1\nConfidence: 80%\nSources: 09_flash_attention_2022\ndescription: National Institutes of Health, a funding body.", "x": 173.22782907954758, "y": -94.99491450740709}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "NSF", "id": "researcher:nsf", "label": "NSF", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "NSF\nType: RESEARCHER\nConnections: 1\nConfidence: 80%\nSources: 09_flash_attention_2022\ndescription: National Science Foundation, a funding body.", "x": 238.66895304476174, "y": 233.51979357894726}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "long sequences", "id": "phenomenon:long_sequences", "label": "long sequences", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "long sequences\nType: PHENOMENON\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022", "x": -161.9666067997697, "y": -132.06238261712622}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "performance improvements", "id": "finding:performance_improvements", "label": "performance improvements", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "performance improvements\nType: FINDING\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: Significant performance improvements over existing methods, including faster training times and better model quality.", "x": 52.103514690849636, "y": 155.1817035004977}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "I/O complexity", "id": "concept:i_o_complexity", "label": "I/O complexity", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "I/O complexity\nType: CONCEPT\nConnections: 1\nConfidence: 90%\nSources: 09_flash_attention_2022\ndescription: The complexity associated with input/output operations in computing.", "x": -143.47096746703164, "y": -123.69814708280147}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "sparse models", "id": "concept:sparse_models", "label": "sparse models", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "sparse models\nType: CONCEPT\nConnections: 1\nConfidence: 90%\nSources: 09_flash_attention_2022\ndescription: Models that use sparsity to reduce the number of parameters and computations.", "x": -52.46019361113491, "y": 3.3079622340725905}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#42A5F5", "border": "#333", "highlight": {"background": "#42A5F5", "border": "#333"}}, "community": "", "description": "", "entity_type": "THEORY", "font": {"color": "#e0e0e0"}, "full_name": "lottery ticket hypothesis", "id": "theory:lottery_ticket_hypothesis", "label": "lottery ticket hypothesis", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "lottery ticket hypothesis\nType: THEORY\nConnections: 1\nConfidence: 90%\nSources: 09_flash_attention_2022\ndescription: A hypothesis suggesting that smaller sub-networks can perform as well as larger networks.", "x": -94.3873629842314, "y": -153.52075510452062}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e8d862", "highlight": {"background": "#26C6DA", "border": "#e8d862"}}, "community": "Efficient Attention Mechanisms and Implementations", "description": "Longformer implements an approximate attention mechanism, as evidenced by its performance metrics across various input sizes. It is compared against FlashAttention, which supports its reference implementations. The system is mentioned alongside BigBird and Scatterbrain, indicating its relevance in discussions of attention mechanisms. Longformer demonstrates varying computational efficiency, with specific performance figures such as 1.27 for smaller inputs and 25.95 for larger ones, highlighting its scalability challenges.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Longformer", "id": "system:longformer", "label": "Longformer", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Longformer\nType: SYSTEM\nConnections: 2\nCommunity: Efficient Attention Mechanisms and Implementations\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: An approximate attention mechanism.", "x": -508.3595313485491, "y": 1025.3929660104643}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#e8d862", "highlight": {"background": "#FFEE58", "border": "#e8d862"}}, "community": "Efficient Attention Mechanisms and Implementations", "description": "Rabe and Staats proposed the method of gradient checkpointing to reduce memory usage during the training of deep learning models. They demonstrated that the backward pass could be executed without requiring quadratic extra memory by applying this technique to the memory-efficient forward pass. This method involves saving only a subset of intermediate activations, which significantly decreases the memory footprint during model training. The FlashAttention system utilizes gradient checkpointing, as noted in the work of Rabe and Staats, to achieve a more memory-efficient computation process.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "gradient checkpointing", "id": "method:gradient_checkpointing", "label": "gradient checkpointing", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "gradient checkpointing\nType: METHOD\nConnections: 2\nCommunity: Efficient Attention Mechanisms and Implementations\nConfidence: 80%\nSources: 09_flash_attention_2022\ndescription: A technique used to reduce memory usage during the training of deep learning models by saving only a subset of intermediate activations.", "x": -622.764230503968, "y": 1037.5754814484249}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Attention Backward Pass", "id": "method:attention_backward_pass", "label": "Attention Backward Pass", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Attention Backward Pass\nType: METHOD\nConnections: 1\nConfidence: 90%\nSources: 09_flash_attention_2022\ndescription: A process to compute gradients for the input matrices Q, K, and V based on the output gradients.", "x": -187.56685840376952, "y": -110.18406996862811}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#e8d862", "highlight": {"background": "#AB47BC", "border": "#e8d862"}}, "community": "Efficient Attention Mechanisms and Implementations", "description": "Rabe and Staats developed an algorithm that operates on blocks of the attention matrix, suggesting that the backward pass can be executed without quadratic extra memory by applying gradient checkpointing. Their work inspired an efficient implementation available in the xformers library, as noted in a 2021 reference. The FlashAttention algorithm, mentioned in a 2022 document, highlights a key difference by focusing on reducing memory accesses, whereas Rabe and Staats concentrated on minimizing the total memory footprint. Their contributions are also referenced in a 2023 document discussing the LLaMA model.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Rabe and Staats", "id": "researcher:rabe_and_staats", "label": "Rabe and Staats", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Rabe and Staats\nType: RESEARCHER\nConnections: 2\nCommunity: Efficient Attention Mechanisms and Implementations\nConfidence: 100%\nSources: 09_flash_attention_2022, 11_llama_2023\ncontribution: Developed an algorithm that operates on blocks of the attention matrix.\nrole: inspired efficient implementation", "x": -783.560876210011, "y": 996.1195360115594}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#e8d862", "highlight": {"background": "#FFEE58", "border": "#e8d862"}}, "community": "Efficient Attention Mechanisms and Implementations", "description": "Standard attention, a traditional method for computing attention in neural networks, requires \u0398(Nd + N\u00b2) HBM accesses during its backward pass. This method, described as Algorithm 0, is mentioned in the 2022 document \"09_flash_attention_2022.\" FlashAttention, a more recent development, contradicts standard attention by requiring significantly fewer HBM accesses. FlashAttention extends the standard method by simplifying the backward pass analytically, offering a more efficient alternative.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "standard attention", "id": "method:standard_attention", "label": "standard attention", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "standard attention\nType: METHOD\nConnections: 3\nCommunity: Efficient Attention Mechanisms and Implementations\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: A traditional method for computing attention in neural networks.", "x": -577.5729822987855, "y": 1284.5325930682507}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "\u0398(Nd + N2)", "id": "finding:th_nd_n2", "label": "\u0398(Nd + N2)", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "\u0398(Nd + N2)\nType: FINDING\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: The number of HBM accesses required by standard attention.", "x": 198.33551908836193, "y": -150.03583539832783}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "\u0398(N2d2M\u22121)", "id": "finding:th_n2d2m_1", "label": "\u0398(N2d2M\u22121)", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "\u0398(N2d2M\u22121)\nType: FINDING\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: The number of HBM accesses required by FlashAttention backward pass.", "x": -66.87256867494324, "y": 179.6481349988282}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "Multi-GPU Attention", "id": "concept:multi_gpu_attention", "label": "Multi-GPU Attention", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Multi-GPU Attention\nType: CONCEPT\nConnections: 1\nConfidence: 90%\nSources: 09_flash_attention_2022\ndescription: A method for training large language models across multiple GPUs.", "x": 170.73519326528765, "y": 185.77120726774194}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EC407A", "border": "#e8d862", "highlight": {"background": "#EC407A", "border": "#e8d862"}}, "community": "Efficient Attention Mechanisms and Implementations", "description": "The Long-range Arena (LRA) benchmark evaluates the performance of attention mechanisms in deep learning. Researchers compared the vanilla Transformer, using either standard implementation or FlashAttention, on the LRA benchmark to assess its effectiveness. FlashAttention demonstrated a significant performance boost, achieving up to a 2.4\u00d7 speed-up compared to standard attention. Additionally, experiments with a fixed sparsity pattern, specifically the butterfly pattern, showed that it performed almost as well as the dense FlashAttention on Long-range Arena tasks. These findings highlight the LRA\u0027s role in testing and validating advancements in attention mechanisms.", "entity_type": "FIELD", "font": {"color": "#e0e0e0"}, "full_name": "Long-range arena", "id": "field:long_range_arena", "label": "Long-range arena", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "Long-range arena\nType: FIELD\nConnections: 3\nCommunity: Efficient Attention Mechanisms and Implementations\nConfidence: 80%\nSources: 09_flash_attention_2022\ndescription: A benchmark for evaluating the performance of attention mechanisms in deep learning.", "x": -416.0995641024523, "y": 1088.1806779357482}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#62e889", "highlight": {"background": "#26C6DA", "border": "#62e889"}}, "community": "BERT and Language Model Fine-Tuning", "description": "Apex FMHA is recognized as the fastest implementation of attention specifically designed for short sequences with a maximum length of 512. This system is applied to BERT models, targeting their performance and efficiency. Apex FMHA is mentioned in the context of FlashAttention, where it serves as a benchmark for comparison against other methods and implementations.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Apex FMHA", "id": "system:apex_fmha", "label": "Apex FMHA", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Apex FMHA\nType: SYSTEM\nConnections: 2\nCommunity: BERT and Language Model Fine-Tuning\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: The fastest implementation of attention tailored for short sequences of length at most 512.", "x": 947.622055378971, "y": 859.2442032291358}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#e8d862", "highlight": {"background": "#26C6DA", "border": "#e8d862"}}, "community": "Efficient Attention Mechanisms and Implementations", "description": "BigBird implements an approximate attention mechanism, as evidenced by its comparison against reference implementations in the context of FlashAttention. The system\u0027s performance metrics, such as \"BigBird 2.35 2.35 2.37 3.25 10.36,\" highlight its efficiency across various scales. FlashAttention supports BigBird by providing comparative performance data, with figures like \"FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19,\" showcasing its scalability. The description of BigBird as an \"approximate attention mechanism\" underscores its role in optimizing attention processes within large-scale models.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "BigBird", "id": "system:bigbird", "label": "BigBird", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "BigBird\nType: SYSTEM\nConnections: 2\nCommunity: Efficient Attention Mechanisms and Implementations\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: An approximate attention mechanism.", "x": -528.018390349095, "y": 968.979043831939}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "tiling", "id": "method:tiling", "label": "tiling", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "tiling\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: A technique applied to deal with long sequences and to save memory.", "x": -160.0591365846239, "y": 139.50985813746394}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "recomputation", "id": "method:recomputation", "label": "recomputation", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "recomputation\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 09_flash_attention_2022\ndescription: A technique applied to deal with long sequences and to save memory.", "x": -217.9816204255472, "y": -46.14018671707632}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "PyTorch Attention", "id": "system:pytorch_attention", "label": "PyTorch Attention", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "PyTorch Attention\nType: SYSTEM\nConnections: 1\nConfidence: 90%\nSources: 09_flash_attention_2022\ndescription: An attention mechanism implemented in the PyTorch framework.", "x": -63.14189688874845, "y": 17.291466412736725}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Megatron", "id": "system:megatron", "label": "Megatron", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Megatron\nType: SYSTEM\nConnections: 1\nConfidence: 90%\nSources: 09_flash_attention_2022\ndescription: A large-scale model for training Transformers.", "x": 65.69515693828049, "y": -181.11685145950685}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "LSformer", "id": "system:lsformer", "label": "LSformer", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "LSformer\nType: SYSTEM\nConnections: 1\nConfidence: 90%\nSources: 09_flash_attention_2022\ndescription: A model that utilizes local sparse attention.", "x": 120.39238594656314, "y": 65.5502974089265}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Block Sparse", "id": "system:block_sparse", "label": "Block Sparse", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Block Sparse\nType: SYSTEM\nConnections: 1\nConfidence: 90%\nSources: 09_flash_attention_2022\ndescription: An attention mechanism that uses block sparsity.", "x": -176.76903011620675, "y": 102.04597236452645}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#62d2e8", "highlight": {"background": "#26C6DA", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "InstructGPT, developed by OpenAI, is a fine-tuned version of GPT-3 that utilizes reinforcement learning from human feedback to enhance its ability to follow instructions, reduce toxicity, and improve truthfulness in outputs. This system, proposed by key contributors Long Ouyang, Jeff Wu, and Paul Christiano, employs the proximal policy optimization (PPO) algorithm to maximize reward signals derived from human feedback. InstructGPT demonstrates significant improvements over GPT-3 in generating truthful and informative outputs, shown by evaluations on the TruthfulQA dataset.\n\nDespite its advancements, InstructGPT exhibits performance regressions on certain public NLP datasets, such as SQuAD and DROP, when compared to GPT-3. These regressions show areas where further research is needed to enhance the model\u0027s capabilities. InstructGPT\u0027s outputs are less likely to \"hallucinate,\" or fabricate information, particularly in closed domain tasks, which supports its alignment with human intentions and reduction of toxic outputs.\n\nInstructGPT\u0027s development involved fine-tuning GPT-3 using supervised learning on labeler demonstrations, followed by reinforcement learning to refine its instruction-following abilities. The system\u0027s performance was evaluated against models fine-tuned on datasets like FLAN and T0, with labelers showing a preference for InstructGPT. The research team also applied the Adam optimizer during training, ensuring the model\u0027s robustness and efficiency.\n\nOverall, InstructGPT represents a significant step forward in aligning AI systems with human values, reducing toxicity, and improving the truthfulness of AI-generated content. Its development shows the potential of reinforcement learning from human feedback in creating more reliable and ethical AI systems.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "InstructGPT", "id": "system:instructgpt", "label": "InstructGPT", "node_degree": 46, "shape": "dot", "size": 50, "title": "InstructGPT\nType: SYSTEM\nConnections: 46\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\ndescription: A fine-tuned version of GPT-3 that utilizes reinforcement learning from human feedback to enhance its ability to follow instructions, reduce toxicity, and improve truthfulness in outputs.\nparameters: 1.3B", "x": -1319.1503805192779, "y": 659.0548565349422}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "proximal policy optimization", "id": "method:proximal_policy_optimization", "label": "proximal policy optimization", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "proximal policy optimization\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\nabbreviation: PPO", "x": -35.707899603639135, "y": -159.42344467232294}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#6862e8", "highlight": {"background": "#26C6DA", "border": "#6862e8"}}, "community": "Question Answering and Evaluation Datasets", "description": "TruthfulQA, developed by Lin et al. in 2021, functions as a benchmark designed to evaluate the truthfulness of model outputs. This system has been utilized to assess the performance of various models, including InstructGPT and LLaMA, in generating truthful and informative responses. InstructGPT, through human evaluations on the TruthfulQA dataset, demonstrated small but significant improvements in truthfulness and informativeness compared to GPT-3. Similarly, LLaMA\u0027s performance on the TruthfulQA benchmark supports its aim to measure the truthfulness of a model\u0027s outputs.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "TruthfulQA", "id": "system:truthfulqa", "label": "TruthfulQA", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "TruthfulQA\nType: SYSTEM\nConnections: 2\nCommunity: Question Answering and Evaluation Datasets\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022, 11_llama_2023\ndescription: A benchmark used to evaluate the truthfulness of model outputs.\ntype: truthfulness measurement benchmark", "x": 431.3703209227675, "y": -1090.130860322328}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#62d2e8", "highlight": {"background": "#26C6DA", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "FLAN, a system developed by Wei et al. in 2021, compiles public NLP tasks with natural language instructions to fine-tune large language models like GPT-3. Researchers fine-tuned a 175B GPT-3 model on the FLAN dataset to establish baselines for comparison with InstructGPT. In multiple studies, InstructGPT was compared to these FLAN-fine-tuned models, with labelers significantly preferring InstructGPT. This preference suggests that while FLAN provides a robust dataset for fine-tuning, InstructGPT\u0027s approach to incorporating human preference data may offer superior performance in certain contexts.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "FLAN", "id": "system:flan", "label": "FLAN", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "FLAN\nType: SYSTEM\nConnections: 2\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\ndescription: A compilation of public NLP tasks combined with natural language instructions.", "x": -1024.38107161431, "y": 308.16360499077194}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#62d2e8", "highlight": {"background": "#26C6DA", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "T0, a system derived from fine-tuning a 175B GPT-3 model, compiles public NLP tasks with natural language instructions. Researchers fine-tuned GPT-3 on the T0 dataset to establish baselines for comparison with InstructGPT. The T0 dataset, mentioned alongside FLAN, was utilized in experiments to evaluate the performance of models like InstructGPT, which reportedly outperformed T0-fine-tuned models according to labeler preferences.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "T0", "id": "system:t0", "label": "T0", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "T0\nType: SYSTEM\nConnections: 2\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\ndescription: A compilation of public NLP tasks combined with natural language instructions.", "x": -957.3043630897531, "y": 228.51386044283373}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#62d2e8", "highlight": {"background": "#AB47BC", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "Long Ouyang contributed significantly to the development of InstructGPT, a system proposed by a team at OpenAI. As a primary author, Ouyang collaborated with colleagues such as Jeff Wu and Paul Christiano to advance the application of reinforcement learning in AI systems. The research paper authored by this team highlights their innovative approach to refining AI models through human feedback, a method that Ouyang helped propose. His work at OpenAI underscores his role in pushing the boundaries of AI research and development.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Long Ouyang", "id": "researcher:long_ouyang", "label": "Long Ouyang", "node_degree": 4, "shape": "dot", "size": 16.0, "title": "Long Ouyang\nType: RESEARCHER\nConnections: 4\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\nrole: Primary author", "x": -915.3221264589426, "y": 650.4338634412933}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#62d2e8", "highlight": {"background": "#AB47BC", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "Paul Christiano contributed significantly to the development of reinforcement learning methods at OpenAI, as evidenced by his role as a primary author on a research paper about InstructGPT. This paper, co-authored with Long Ouyang, Jeff Wu, and others, highlights Christiano\u0027s involvement in proposing both reinforcement learning techniques and the InstructGPT system. His work at OpenAI demonstrates his active participation in advancing AI methodologies, particularly in the context of training models to better understand and execute human instructions.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Paul Christiano", "id": "researcher:paul_christiano", "label": "Paul Christiano", "node_degree": 4, "shape": "dot", "size": 16.0, "title": "Paul Christiano\nType: RESEARCHER\nConnections: 4\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\nrole: Primary author", "x": -924.8692203290175, "y": 302.1512049881178}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#62d2e8", "highlight": {"background": "#EF5350", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "InstructGPT enhances its ability to follow instructions by utilizing reinforcement learning from human feedback. This approach focuses on improving language models\u0027 alignment with user intent through direct input from human contractors. The behavior of InstructGPT models is partially determined by this human feedback, which is integral to aligning models with human intentions. The development of InstructGPT centers on this method, applying reinforcement learning to refine the model\u0027s performance based on human-provided insights.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "human feedback", "id": "concept:human_feedback", "label": "human feedback", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "human feedback\nType: CONCEPT\nConnections: 2\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\ndescription: Feedback provided by humans to improve model alignment with user intent.", "x": -1204.676816893552, "y": 472.7161800936729}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#62d2e8", "highlight": {"background": "#EF5350", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "Researchers applied reinforcement learning from human feedback (RLHF) to align language models with human intentions, as demonstrated in their work on InstructGPT. They aimed to train models that act according to user intentions, ensuring that language models behave in accordance with human expectations. This approach, described as aligning language models on a broad distribution of language tasks, highlights the use of reinforcement learning to achieve alignment.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "alignment", "id": "concept:alignment", "label": "alignment", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "alignment\nType: CONCEPT\nConnections: 2\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\ndescription: The process of ensuring that language models behave in accordance with human intentions.", "x": -1013.0990305876082, "y": 535.0446793223227}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "supervised learning", "id": "method:supervised_learning", "label": "supervised learning", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "supervised learning\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\ndescription: A method used to fine-tune the GPT-3 model.", "x": 15.917844546950448, "y": -118.39221398910666}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "labeler", "id": "researcher:labeler", "label": "labeler", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "labeler\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\ndescription: Individuals who write prompts and evaluate model outputs.", "x": -44.273927276137044, "y": 4.57597104866818}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#9CCC65", "border": "#333", "highlight": {"background": "#9CCC65", "border": "#333"}}, "community": "", "description": "", "entity_type": "PUBLICATION", "font": {"color": "#e0e0e0"}, "full_name": "Stiennon et al. (2020)", "id": "publication:stiennon_et_al_2020", "label": "Stiennon et al. (2020)", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Stiennon et al. (2020)\nType: PUBLICATION\nConnections: 1\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\ndescription: A paper that discusses human preference data collection.", "x": 34.58053925717843, "y": 174.22123548456688}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#9CCC65", "border": "#333", "highlight": {"background": "#9CCC65", "border": "#333"}}, "community": "", "description": "", "entity_type": "PUBLICATION", "font": {"color": "#e0e0e0"}, "full_name": "Ziegler et al. (2019)", "id": "publication:ziegler_et_al_2019", "label": "Ziegler et al. (2019)", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Ziegler et al. (2019)\nType: PUBLICATION\nConnections: 1\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\ndescription: A paper that discusses human preference data collection on summarization.", "x": -2.4094580328724646, "y": 36.70581388777816}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#9CCC65", "border": "#333", "highlight": {"background": "#9CCC65", "border": "#333"}}, "community": "", "description": "", "entity_type": "PUBLICATION", "font": {"color": "#e0e0e0"}, "full_name": "Brown et al. (2020)", "id": "publication:brown_et_al_2020", "label": "Brown et al. (2020)", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Brown et al. (2020)\nType: PUBLICATION\nConnections: 1\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\ndescription: A reference discussing the training costs of language models.", "x": 176.39792358808285, "y": -85.12971582067931}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#62d2e8", "highlight": {"background": "#FFEE58", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "Supervised Fine-Tuning (SFT) was applied to InstructGPT, where researchers experimented with several variants of the SFT models. This method, which involves training models using labeled data, was compared against Proximal Policy Optimization (PPO) models to evaluate performance. Additionally, SFT was assessed alongside Direct Preference Optimization (DPO) with specific temperature settings, such as 0.25 for both DPO and SFT, and 1.0 for PPO. These comparisons and evaluations were documented in sources like the 10_instructgpt_rlhf_2022 and 12_dpo_2023 papers, highlighting SFT\u0027s role in refining model training processes.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "SFT", "id": "method:sft", "label": "SFT", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "SFT\nType: METHOD\nConnections: 2\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022, 12_dpo_2023\ndescription: Supervised Fine-Tuning, a method for training models using labeled data.", "x": -1358.0656577508412, "y": 608.1878597152001}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#6862e8", "highlight": {"background": "#26C6DA", "border": "#6862e8"}}, "community": "Question Answering and Evaluation Datasets", "description": "CrowS-Pairs is a dataset designed to evaluate bias in language models. It was utilized in the evaluation of biases in models such as LLaMA, as noted in the work by Nangia et al. in 2020. The dataset is specifically intended for benchmarking models on bias and toxicity, as evidenced by its mention in studies like InstructGPT and LLaMA.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "CrowS-Pairs", "id": "system:crows_pairs", "label": "CrowS-Pairs", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "CrowS-Pairs\nType: SYSTEM\nConnections: 1\nCommunity: Question Answering and Evaluation Datasets\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022, 11_llama_2023\ndescription: A dataset used to evaluate bias in language models.\ntype: bias measurement dataset", "x": 256.62463129446235, "y": -1200.2225176085344}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "hallucinations", "id": "finding:hallucinations", "label": "hallucinations", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "hallucinations\nType: FINDING\nConnections: 1\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\ndescription: The tendency of models to make up information on closed-domain tasks.", "x": -143.89611279127973, "y": 95.66176282142601}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "alignment tax", "id": "concept:alignment_tax", "label": "alignment tax", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "alignment tax\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\ndescription: A phenomenon where performance on public NLP datasets decreases due to alignment procedures.", "x": 163.53961058144216, "y": 100.34777572499974}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#62d2e8", "highlight": {"background": "#EF5350", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "Alignment techniques aim to align language models with human intentions, focusing on minimizing the \"alignment tax,\" or the cost of achieving this alignment. These techniques are discussed in the context of aligning models to human preferences, as evidenced by the statement, \"we have aligned to a set of labelers\u2019 preferences.\" Reinforcement learning supports these alignment techniques, particularly through Reinforcement Learning from Human Feedback (RLHF), which is noted as a promising low-tax alignment method. The results from RLHF are described as \"good news\" for its effectiveness in aligning models with human intentions.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "alignment techniques", "id": "concept:alignment_techniques", "label": "alignment techniques", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "alignment techniques\nType: CONCEPT\nConnections: 2\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\ndescription: Techniques aimed at aligning language models with human intentions.", "x": -1258.501305970163, "y": 358.9909843862042}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "toxic outputs", "id": "finding:toxic_outputs", "label": "toxic outputs", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "toxic outputs\nType: FINDING\nConnections: 1\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\ndescription: Outputs generated by models that are harmful or biased.", "x": -77.03374620784876, "y": -55.1523780155338}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "steerability and controllability literature", "id": "concept:steerability_and_controllability_literature", "label": "steerability and controllability literature", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "steerability and controllability literature\nType: CONCEPT\nConnections: 1\nConfidence: 90%\nSources: 10_instructgpt_rlhf_2022", "x": 55.32279041022116, "y": 188.1526505983922}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "control codes", "id": "method:control_codes", "label": "control codes", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "control codes\nType: METHOD\nConnections: 1\nConfidence: 80%\nSources: 10_instructgpt_rlhf_2022", "x": 97.67501278965551, "y": -61.06577295588289}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "expert iteration", "id": "method:expert_iteration", "label": "expert iteration", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "expert iteration\nType: METHOD\nConnections: 1\nConfidence: 80%\nSources: 10_instructgpt_rlhf_2022", "x": -24.46611569866974, "y": -197.13584535321195}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "behavior cloning", "id": "method:behavior_cloning", "label": "behavior cloning", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "behavior cloning\nType: METHOD\nConnections: 1\nConfidence: 80%\nSources: 10_instructgpt_rlhf_2022", "x": -113.1631408792405, "y": 54.357542196214695}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "constrained optimization", "id": "method:constrained_optimization", "label": "constrained optimization", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "constrained optimization\nType: METHOD\nConnections: 1\nConfidence: 80%\nSources: 10_instructgpt_rlhf_2022", "x": -129.08248010380004, "y": -132.65680770725697}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Gabriel", "id": "researcher:gabriel", "label": "Gabriel", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Gabriel\nType: RESEARCHER\nConnections: 1\nConfidence: 90%\nSources: 10_instructgpt_rlhf_2022\ncontribution: discussed differences between aligning to instructions, intentions, revealed preferences, ideal preferences, interests, and values.", "x": 184.7491271642939, "y": -124.51910161253416}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "alignment with user intent", "id": "concept:alignment_with_user_intent", "label": "alignment with user intent", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "alignment with user intent\nType: CONCEPT\nConnections: 1\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\ndescription: The goal of improving language models to better meet user expectations.", "x": -158.71121560041712, "y": -37.04625293397123}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#66BB6A", "border": "#333", "highlight": {"background": "#66BB6A", "border": "#333"}}, "community": "", "description": "", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "truthfulness", "id": "phenomenon:truthfulness", "label": "truthfulness", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "truthfulness\nType: PHENOMENON\nConnections: 1\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\ndescription: The accuracy and reliability of the outputs generated by language models.", "x": 110.482059426854, "y": 112.45078309101655}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "toxicity reduction", "id": "finding:toxicity_reduction", "label": "toxicity reduction", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "toxicity reduction\nType: FINDING\nConnections: 1\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\ndescription: InstructGPT improves truthfulness and reduces toxicity in outputs.", "x": -205.08577068370272, "y": -222.5515983986573}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFA726", "border": "#333", "highlight": {"background": "#FFA726", "border": "#333"}}, "community": "", "description": "", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "truthfulness improvement", "id": "finding:truthfulness_improvement", "label": "truthfulness improvement", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "truthfulness improvement\nType: FINDING\nConnections: 1\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\ndescription: InstructGPT improves truthfulness in outputs.", "x": -161.18406208668168, "y": -109.13460584532541}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#EF5350", "border": "#62d2e8", "highlight": {"background": "#EF5350", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "InstructGPT reduces toxicity and improves truthfulness in outputs, outperforming the original GPT-3 model despite having significantly fewer parameters. The concept of toxicity is defined as the quality of being rude, disrespectful, or unreasonable in text. The RealToxicity Prompts task investigates toxicity by measuring it via the Perspective API.", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "toxicity", "id": "concept:toxicity", "label": "toxicity", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "toxicity\nType: CONCEPT\nConnections: 2\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022\ndescription: The quality of being rude, disrespectful, or unreasonable in text.", "x": -1291.3193726495529, "y": 575.5051526529044}, {"aliases": "RealToxicityPrompts", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#62d2e8", "highlight": {"background": "#26C6DA", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "RealToxicity Prompts evaluates model outputs for toxicity using the Perspective API. This dataset, mentioned in the 2022 InstructGPT and 2023 LLaMA papers, investigates toxicity by assessing how models generate potentially harmful content. InstructGPT supports its evaluation by utilizing the RealToxicity Prompts dataset to measure the effectiveness of its models in reducing toxic outputs. Additionally, LLaMA associates with this dataset to understand and mitigate the potential harm of its large language models, specifically LLaMA-65B, by evaluating their production of toxic content and detection of stereotypes.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "RealToxicity Prompts", "id": "system:realtoxicity_prompts", "label": "RealToxicity Prompts", "node_degree": 3, "shape": "dot", "size": 13.5, "title": "RealToxicity Prompts\nType: SYSTEM\nConnections: 3\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 10_instructgpt_rlhf_2022, 11_llama_2023\ndescription: A dataset used to measure toxicity in model outputs.\naliases: [\u0027RealToxicityPrompts\u0027]", "x": -1080.1294105589977, "y": 411.544861529945}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#6862e8", "highlight": {"background": "#26C6DA", "border": "#6862e8"}}, "community": "Question Answering and Evaluation Datasets", "description": "MetaAI introduced LLaMA, a series of foundation language models ranging from 7 billion to 65 billion parameters, as a competitive alternative to state-of-the-art models. Hugo Touvron, Thibaut Lavril, and Gautier Izacard were key figures in proposing these models. LLaMA models were trained using the AdamW optimizer and employed several methods, including the byte-pair encoding (BPE) algorithm for tokenization, SwiGLU activation functions, and rotary positional embeddings (RoPE).\n\nThe LLaMA models were applied to a variety of datasets and benchmarks, such as the C4 dataset, Wikipedia dumps from June to August 2022, and mathematical reasoning benchmarks like MATH and GSM8K. They were also evaluated on code-writing benchmarks HumanEval and MBPP, and on question-answering datasets like Natural Questions and TriviaQA. The models demonstrated strong performance, supporting theories like CommonSense Reasoning and outperforming models such as GPT-3 and OPT-175B, while being competitive with Chinchilla and PaLM.\n\nLLaMA\u0027s evaluation extended to bias and truthfulness assessments using benchmarks like WinoGender, CrowS-Pairs, and TruthfulQA. The models also underwent testing for potential harm using RealToxicity Prompts. The LLaMA series, particularly the 65B model, showed that brief finetuning could outperform existing instruction-finetuned models of moderate sizes, supporting the effectiveness of the Chinchilla scaling laws.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "LLaMA", "id": "system:llama", "label": "LLaMA", "node_degree": 38, "shape": "dot", "size": 50, "title": "LLaMA\nType: SYSTEM\nConnections: 38\nCommunity: Question Answering and Evaluation Datasets\nConfidence: 100%\nSources: 11_llama_2023\nparameters: 65 billion\ndescription: An instruction fine-tuned model based on LLaMA.", "x": 287.972025168512, "y": -959.9760596318929}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Chinchilla", "id": "system:chinchilla", "label": "Chinchilla", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Chinchilla\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 11_llama_2023\nparameters: 70B\ndescription: a large language model", "x": 5.989689908772078, "y": 76.09073093118917}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "AdamW optimizer", "id": "method:adamw_optimizer", "label": "AdamW optimizer", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "AdamW optimizer\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 11_llama_2023\ndescription: an optimization algorithm used for training models", "x": 79.91780966374807, "y": -95.61896037180523}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "C4", "id": "system:c4", "label": "C4", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "C4\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 11_llama_2023\ndescription: a dataset used for training language models", "x": -62.16494955644458, "y": 150.76936494055508}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "BPE algorithm", "id": "method:bpe_algorithm", "label": "BPE algorithm", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "BPE algorithm\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 11_llama_2023\ndescription: a tokenization method used in data processing", "x": -146.87624594992215, "y": -40.03077627390172}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#6862e8", "highlight": {"background": "#AB47BC", "border": "#6862e8"}}, "community": "Question Answering and Evaluation Datasets", "description": "Hugo Touvron contributed to the development and training of the LLaMA models alongside Thibaut Lavril, Gautier Izacard, and Xavier Martinet. As a key participant, Touvron collaborated with these researchers to propose the LLaMA system, which represents a significant advancement in model architecture. His involvement in this project underscores his active role in advancing machine learning systems.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Hugo Touvron", "id": "researcher:hugo_touvron", "label": "Hugo Touvron", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Hugo Touvron\nType: RESEARCHER\nConnections: 2\nCommunity: Question Answering and Evaluation Datasets\nConfidence: 100%\nSources: 11_llama_2023\nrole: contributor", "x": -36.50249993051895, "y": -1237.9049569066485}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#6862e8", "highlight": {"background": "#AB47BC", "border": "#6862e8"}}, "community": "Question Answering and Evaluation Datasets", "description": "Thibaut Lavril contributed to the development and training of the LLaMA models alongside Hugo Touvron, Gautier Izacard, and others. His involvement in this project is documented in multiple sources, which consistently list him as a key participant. The collaborative effort with Touvron and Izacard highlights Lavril\u0027s role in advancing the capabilities of these models.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Thibaut Lavril", "id": "researcher:thibaut_lavril", "label": "Thibaut Lavril", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Thibaut Lavril\nType: RESEARCHER\nConnections: 2\nCommunity: Question Answering and Evaluation Datasets\nConfidence: 100%\nSources: 11_llama_2023\nrole: contributor", "x": 86.83880191105155, "y": -1240.6496267218538}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#AB47BC", "border": "#6862e8", "highlight": {"background": "#AB47BC", "border": "#6862e8"}}, "community": "Question Answering and Evaluation Datasets", "description": "Gautier Izacard contributed to the development and training of the LLaMA models alongside Hugo Touvron, Thibaut Lavril, and Xavier Martinet. As a key participant, Izacard collaborated with these researchers to propose the LLaMA system, which represents a significant advancement in language model architectures. His involvement in this project underscores his active role in pushing the boundaries of machine learning research.", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Gautier Izacard", "id": "researcher:gautier_izacard", "label": "Gautier Izacard", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Gautier Izacard\nType: RESEARCHER\nConnections: 2\nCommunity: Question Answering and Evaluation Datasets\nConfidence: 100%\nSources: 11_llama_2023\nrole: contributor", "x": 346.1029538107614, "y": -1001.4251355498125}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "SwiGLU", "id": "method:swiglu", "label": "SwiGLU", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "SwiGLU\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 11_llama_2023\ndescription: an activation function", "x": -185.1225289308506, "y": -69.42246088107123}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Rotary Positional Embeddings (RoPE)", "id": "method:rotary_positional_embeddings_rope", "label": "Rotary Positional Embeddings (RoPE)", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Rotary Positional Embeddings (RoPE)\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 11_llama_2023\ndescription: a method for adding positional embeddings", "x": 74.72462089974863, "y": 204.8853909002911}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#6862e8", "highlight": {"background": "#26C6DA", "border": "#6862e8"}}, "community": "Question Answering and Evaluation Datasets", "description": "HumanEval serves as a benchmark for evaluating code generation capabilities. It is specifically used to assess how well models can write code from natural language descriptions. The LLaMA model applied its capabilities to HumanEval, demonstrating its proficiency in this area. Additionally, the performance of models on HumanEval is quantified using the pass@ score, which is also reported alongside results from the MBPP benchmark.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "HumanEval", "id": "system:humaneval", "label": "HumanEval", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "HumanEval\nType: SYSTEM\nConnections: 2\nCommunity: Question Answering and Evaluation Datasets\nConfidence: 100%\nSources: 11_llama_2023\ndescription: a benchmark for evaluating code generation", "x": 261.4508350101953, "y": -1041.1194982334705}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#6862e8", "highlight": {"background": "#26C6DA", "border": "#6862e8"}}, "community": "Question Answering and Evaluation Datasets", "description": "MBPP serves as a benchmark for evaluating code generation capabilities. It is specifically used to assess how well models can write code based on natural language descriptions. The LLaMA model applied its capabilities to MBPP, demonstrating its ability to generate code from textual prompts. Additionally, the performance of LLaMA on MBPP was quantified using the pass@ score, which measures the accuracy of the generated code.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "MBPP", "id": "system:mbpp", "label": "MBPP", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "MBPP\nType: SYSTEM\nConnections: 2\nCommunity: Question Answering and Evaluation Datasets\nConfidence: 100%\nSources: 11_llama_2023\ndescription: a benchmark for evaluating code generation", "x": 295.267979345145, "y": -1267.4073754825756}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "MATH", "id": "system:math", "label": "MATH", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "MATH\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 11_llama_2023\ndescription: a dataset of middle school and high school mathematics problems", "x": -40.862651463198006, "y": 97.07970546470955}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "MMLU", "id": "system:mmlu", "label": "MMLU", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "MMLU\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 11_llama_2023\ndescription: Massive Multitask Language Understanding benchmark.", "x": -46.00723457021749, "y": -211.81379207148265}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "WinoGender", "id": "system:winogender", "label": "WinoGender", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "WinoGender\nType: SYSTEM\nConnections: 1\nConfidence: 80%\nSources: 11_llama_2023\ntype: co-reference resolution dataset", "x": 116.63061757610825, "y": -109.26654771413541}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "OPT-175B", "id": "system:opt_175b", "label": "OPT-175B", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "OPT-175B\nType: SYSTEM\nConnections: 1\nConfidence: 90%\nSources: 11_llama_2023\ntype: language model", "x": 56.164041435826164, "y": -162.60519035817663}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Kneser-Ney smoothing", "id": "method:kneser_ney_smoothing", "label": "Kneser-Ney smoothing", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Kneser-Ney smoothing\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 11_llama_2023\ndescription: a smoothing technique used in language modeling", "x": -13.018758865619702, "y": 134.4392212157353}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Stupid Backoff", "id": "method:stupid_backoff", "label": "Stupid Backoff", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Stupid Backoff\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 11_llama_2023\ndescription: a simple smoothing technique used in language modeling", "x": -6.951944212604701, "y": -30.281647599315505}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "exact match metric", "id": "method:exact_match_metric", "label": "exact match metric", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "exact match metric\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 11_llama_2023", "x": -118.76927834152318, "y": 100.71446716476925}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#62d2e8", "highlight": {"background": "#FFEE58", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn introduced Direct Preference Optimization (DPO) at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023). This method offers a straightforward, reinforcement learning-free approach to training language models based on human preferences. The team aimed to simplify policy optimization by directly utilizing preferences, contrasting with traditional reinforcement learning from human feedback (RLHF) methods.\n\nDPO was applied to various datasets, including the TL;DR summarization dataset and the Anthropic HH dataset, to evaluate its performance. The method demonstrated comparable or superior results to existing RLHF algorithms, such as those based on Proximal Policy Optimization (PPO). The researchers also used GPT-2 as a base model for their experiments, leveraging human preference data to validate the effectiveness of DPO in aligning language models with human preferences.\n\nThe development of DPO extends previous work on the KL-Constrained Reward Maximization Objective and the Bradley-Terry and Plackett-Luce models. The method\u0027s objective was derived under these models, and the team provided PyTorch code for the DPO loss, facilitating its implementation. By simplifying the training process and improving stability, DPO challenges the necessity of reinforcement learning in preference-based language model training, offering a more efficient alternative.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Direct Preference Optimization", "id": "method:direct_preference_optimization", "label": "Direct Preference Optimization", "node_degree": 33, "shape": "dot", "size": 50, "title": "Direct Preference Optimization\nType: METHOD\nConnections: 33\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 12_dpo_2023\ndescription: A simple RL-free algorithm for training language models from preferences.", "x": -1351.5895972500666, "y": 256.93343033883536}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#42A5F5", "border": "#62d2e8", "highlight": {"background": "#42A5F5", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "The Bradley-Terry model serves as a theoretical preference model that evaluates how well a reward function aligns with empirical preference data. This model is prominently featured in the context of Direct Preference Optimization (DPO), where it underpins the derivation of the DPO objective. The Bradley-Terry model is recognized as a popular choice for such applications, indicating its widespread acceptance and utility in preference modeling. Furthermore, the procedure for Direct Preference Optimization is described as equivalent to fitting a parametrized Bradley-Terry model, demonstrating the model\u0027s integral role in supporting and extending the capabilities of DPO.", "entity_type": "THEORY", "font": {"color": "#e0e0e0"}, "full_name": "Bradley-Terry model", "id": "theory:bradley_terry_model", "label": "Bradley-Terry model", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "Bradley-Terry model\nType: THEORY\nConnections: 2\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 12_dpo_2023\ndescription: A theoretical preference model that measures how well a given reward function aligns with empirical preference data.", "x": -1359.4604075811255, "y": 565.8974476993183}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EC407A", "border": "#333", "highlight": {"background": "#EC407A", "border": "#333"}}, "community": "", "description": "", "entity_type": "FIELD", "font": {"color": "#e0e0e0"}, "full_name": "Stanford University", "id": "field:stanford_university", "label": "Stanford University", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Stanford University\nType: FIELD\nConnections: 1\nConfidence: 100%\nSources: 12_dpo_2023\ndescription: Institution where the authors are affiliated.", "x": 69.64933977552602, "y": 163.50831179627426}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EC407A", "border": "#333", "highlight": {"background": "#EC407A", "border": "#333"}}, "community": "", "description": "", "entity_type": "FIELD", "font": {"color": "#e0e0e0"}, "full_name": "CZ Biohub", "id": "field:cz_biohub", "label": "CZ Biohub", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "CZ Biohub\nType: FIELD\nConnections: 1\nConfidence: 100%\nSources: 12_dpo_2023\ndescription: Institution where some authors are affiliated.", "x": -76.22017868476294, "y": -146.64575854745914}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#42A5F5", "border": "#333", "highlight": {"background": "#42A5F5", "border": "#333"}}, "community": "", "description": "", "entity_type": "THEORY", "font": {"color": "#e0e0e0"}, "full_name": "Plackett-Luce models", "id": "theory:plackett_luce_models", "label": "Plackett-Luce models", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Plackett-Luce models\nType: THEORY\nConnections: 1\nConfidence: 100%\nSources: 12_dpo_2023\ndescription: A generalization of the Bradley-Terry model over rankings.", "x": 231.2167477538108, "y": -181.229873046011}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "maximum likelihood estimation", "id": "method:maximum_likelihood_estimation", "label": "maximum likelihood estimation", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "maximum likelihood estimation\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 12_dpo_2023\ndescription: A method used to estimate parameters of a statistical model.", "x": 105.32551142005445, "y": -96.2261333890807}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "language model", "id": "system:language_model", "label": "language model", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "language model\nType: SYSTEM\nConnections: 1\nConfidence: 100%\nSources: 12_dpo_2023\ndescription: A model that generates text based on input prompts.", "x": -201.92582490169542, "y": 92.32597152718921}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#26C6DA", "border": "#62d2e8", "highlight": {"background": "#26C6DA", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "The IMDB dataset serves as a foundational resource for sentiment generation tasks. Researchers fine-tuned GPT-2-large on reviews from the training split of the IMDB dataset, demonstrating its application in enhancing language models. Additionally, Direct Preference Optimization utilized prompts derived from prefixes of movie reviews within the IMDB dataset, ranging from 2 to 8 tokens in length, to refine sentiment analysis techniques.", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "IMDB dataset", "id": "system:imdb_dataset", "label": "IMDB dataset", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "IMDB dataset\nType: SYSTEM\nConnections: 2\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 12_dpo_2023\ndescription: A dataset used for sentiment generation tasks.", "x": -1314.5976223509952, "y": 328.9273739995897}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "Anthropic HH dataset", "id": "system:anthropic_hh_dataset", "label": "Anthropic HH dataset", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Anthropic HH dataset\nType: SYSTEM\nConnections: 1\nConfidence: 90%\nSources: 12_dpo_2023\ndescription: A dataset used for evaluating single-turn dialogue.", "x": -15.82466487708868, "y": -50.65875226729966}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#26C6DA", "border": "#333", "highlight": {"background": "#26C6DA", "border": "#333"}}, "community": "", "description": "", "entity_type": "SYSTEM", "font": {"color": "#e0e0e0"}, "full_name": "TL;DR summarization dataset", "id": "system:tl_dr_summarization_dataset", "label": "TL;DR summarization dataset", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "TL;DR summarization dataset\nType: SYSTEM\nConnections: 1\nConfidence: 90%\nSources: 12_dpo_2023\ndescription: A dataset used for evaluating summarization performance.", "x": -170.463749134154, "y": 94.32235770432288}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "KL-constrained reward maximization", "id": "concept:kl_constrained_reward_maximization", "label": "KL-constrained reward maximization", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "KL-constrained reward maximization\nType: CONCEPT\nConnections: 1\nConfidence: 80%\nSources: 12_dpo_2023\ndescription: An objective used in typical RLHF algorithms.", "x": -160.42941542284717, "y": 106.41569113627486}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#66BB6A", "border": "#62d2e8", "highlight": {"background": "#66BB6A", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "Direct Preference Optimization (DPO) fine-tunes language models to align with human preferences, as demonstrated in recent research. This method optimizes large-scale unsupervised language models based on human preferences without relying on complex reinforcement learning techniques. The human preference dataset, gathered by Stiennon et al., serves as a foundation for this optimization process. DPO supports the training of language models to satisfy human preferences directly, enhancing alignment techniques that explain how models adhere to a set of labelers\u0027 preferences.", "entity_type": "PHENOMENON", "font": {"color": "#e0e0e0"}, "full_name": "human preferences", "id": "phenomenon:human_preferences", "label": "human preferences", "node_degree": 4, "shape": "dot", "size": 16.0, "title": "human preferences\nType: PHENOMENON\nConnections: 4\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 12_dpo_2023, 10_instructgpt_rlhf_2022\ndescription: The preferences expressed by humans that can be used to train language models.", "x": -1079.666114382118, "y": 371.96320200311527}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#EF5350", "border": "#333", "highlight": {"background": "#EF5350", "border": "#333"}}, "community": "", "description": "", "entity_type": "CONCEPT", "font": {"color": "#e0e0e0"}, "full_name": "KL-Constrained Reward Maximization Objective", "id": "concept:kl_constrained_reward_maximization_objective", "label": "KL-Constrained Reward Maximization Objective", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "KL-Constrained Reward Maximization Objective\nType: CONCEPT\nConnections: 1\nConfidence: 80%\nSources: 12_dpo_2023\ndescription: An objective used in reinforcement learning to maximize rewards while adhering to constraints.", "x": 209.77862386088754, "y": -12.807302471058819}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Rafael Rafailov", "id": "researcher:rafael_rafailov", "label": "Rafael Rafailov", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Rafael Rafailov\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 12_dpo_2023\nrole: author", "x": -145.22443604392026, "y": -33.56781328081337}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Archit Sharma", "id": "researcher:archit_sharma", "label": "Archit Sharma", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Archit Sharma\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 12_dpo_2023\nrole: author", "x": -184.79277849537306, "y": -117.06322273367599}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Eric Mitchell", "id": "researcher:eric_mitchell", "label": "Eric Mitchell", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Eric Mitchell\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 12_dpo_2023\nrole: author", "x": 45.037578207307774, "y": 99.51858833330937}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Christopher D. Manning", "id": "researcher:christopher_d_manning", "label": "Christopher D. Manning", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Christopher D. Manning\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 12_dpo_2023\nrole: author", "x": 183.78443549660727, "y": 173.59839671945127}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#AB47BC", "border": "#333", "highlight": {"background": "#AB47BC", "border": "#333"}}, "community": "", "description": "", "entity_type": "RESEARCHER", "font": {"color": "#e0e0e0"}, "full_name": "Chelsea Finn", "id": "researcher:chelsea_finn", "label": "Chelsea Finn", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Chelsea Finn\nType: RESEARCHER\nConnections: 1\nConfidence: 100%\nSources: 12_dpo_2023\nrole: author", "x": -14.121666810845028, "y": 31.7387404834642}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "Best of N baseline", "id": "method:best_of_n_baseline", "label": "Best of N baseline", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "Best of N baseline\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 12_dpo_2023\ndescription: A baseline method evaluated in the experiments, requiring sampling many times.", "x": 234.23003597796247, "y": 6.745658591756467}, {"aliases": "", "borderWidth": 1.5, "color": {"background": "#FFEE58", "border": "#333", "highlight": {"background": "#FFEE58", "border": "#333"}}, "community": "", "description": "", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "RMSprop", "id": "method:rmsprop", "label": "RMSprop", "node_degree": 1, "shape": "dot", "size": 8.5, "title": "RMSprop\nType: METHOD\nConnections: 1\nConfidence: 100%\nSources: 12_dpo_2023\ndescription: An optimization algorithm used in the implementation of DPO.", "x": 239.040403306813, "y": 53.568585744408495}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#FFEE58", "border": "#62d2e8", "highlight": {"background": "#FFEE58", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "The DPO loss function, integral to the Direct Preference Optimization algorithm, utilizes the RMSprop optimizer with a default learning rate of 1e-6. This method is implemented in PyTorch, as evidenced by the provided code.", "entity_type": "METHOD", "font": {"color": "#e0e0e0"}, "full_name": "DPO loss", "id": "method:dpo_loss", "label": "DPO loss", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "DPO loss\nType: METHOD\nConnections: 2\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 12_dpo_2023\ndescription: The loss function used in the Direct Preference Optimization algorithm.", "x": -897.7616375892933, "y": 541.1180648101075}, {"aliases": "", "borderWidth": 2.0, "color": {"background": "#FFA726", "border": "#62d2e8", "highlight": {"background": "#FFA726", "border": "#62d2e8"}}, "community": "Human Feedback and Reinforcement Learning", "description": "Researchers collected human preference data by assigning two human raters to evaluate 150 random comparisons between Direct Preference Optimization (DPO) and PPO-0, and 100 random comparisons between PPO-1 and PPO-0. This study aimed to validate the use of GPT-4 for computing win rates by gathering human judgments on algorithm performance. The data, described as evaluations from human raters, supports the Direct Preference Optimization method by providing empirical evidence of its effectiveness in algorithm matchups.", "entity_type": "FINDING", "font": {"color": "#e0e0e0"}, "full_name": "human preference data", "id": "finding:human_preference_data", "label": "human preference data", "node_degree": 2, "shape": "dot", "size": 11.0, "title": "human preference data\nType: FINDING\nConnections: 2\nCommunity: Human Feedback and Reinforcement Learning\nConfidence: 100%\nSources: 12_dpo_2023\ndescription: Data collected from human raters to evaluate the performance of different algorithms.", "x": -928.0688787169353, "y": 502.66234468800894}]);
                  edges = new vis.DataSet([{"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "The paper presents experimental results demonstrating the Transformer\u2019s superior performance in machine translation tasks.", "relation_type": "EXPLAINS", "source_name": "Transformer", "target_name": "machine translation", "title": "Transformer EXPLAINS machine translation\nConfidence: 100%\nEvidence: The paper presents experimental results demonstrating the Transformer\u2019s superior performance in machine translation tasks.", "to": "phenomenon:machine_translation", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "The Transformer allows for significantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs.", "relation_type": "USES_METHOD", "source_name": "Transformer", "target_name": "self-attention", "title": "Transformer USES_METHOD self-attention\nConfidence: 100%\nEvidence: The Transformer allows for significantly more parallelization and can reach a new state of the art in translation quality after being trained for as l...", "to": "concept:self_attention", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "The Transformer uses multi-head attention in three different ways.", "relation_type": "EXPLAINS", "source_name": "Transformer", "target_name": "multi-head attention", "title": "Transformer EXPLAINS multi-head attention\nConfidence: 100%\nEvidence: The Transformer uses multi-head attention in three different ways.", "to": "concept:multi_head_attention", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "authored by a team from Google Brain and Google Research, including Ashish Vaswani.", "relation_type": "PROPOSED_BY", "source_name": "Transformer", "target_name": "Ashish Vaswani", "title": "Transformer PROPOSED_BY Ashish Vaswani\nConfidence: 100%\nEvidence: authored by a team from Google Brain and Google Research, including Ashish Vaswani.", "to": "researcher:ashish_vaswani", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "authored by a team from Google Brain and Google Research, including Noam Shazeer.", "relation_type": "PROPOSED_BY", "source_name": "Transformer", "target_name": "Noam Shazeer", "title": "Transformer PROPOSED_BY Noam Shazeer\nConfidence: 100%\nEvidence: authored by a team from Google Brain and Google Research, including Noam Shazeer.", "to": "researcher:noam_shazeer", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "authored by a team from Google Brain and Google Research, including Niki Parmar.", "relation_type": "PROPOSED_BY", "source_name": "Transformer", "target_name": "Niki Parmar", "title": "Transformer PROPOSED_BY Niki Parmar\nConfidence: 100%\nEvidence: authored by a team from Google Brain and Google Research, including Niki Parmar.", "to": "researcher:niki_parmar", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "the Transformer outperformed the best previously reported models", "relation_type": "EXPLAINS", "source_name": "Transformer", "target_name": "English-to-German translation task", "title": "Transformer EXPLAINS English-to-German translation task\nConfidence: 100%\nEvidence: the Transformer outperformed the best previously reported models", "to": "phenomenon:english_to_german_translation_task", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "the big model achieves a BLEU score of 41.0, outperforming all of the previously published single models", "relation_type": "EXPLAINS", "source_name": "Transformer", "target_name": "English-to-French translation task", "title": "Transformer EXPLAINS English-to-French translation task\nConfidence: 100%\nEvidence: the big model achieves a BLEU score of 41.0, outperforming all of the previously published single models", "to": "phenomenon:english_to_french_translation_task", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "the first sequence transduction model based entirely on attention, replacing the recurrent layers", "relation_type": "USES_METHOD", "source_name": "Transformer", "target_name": "multi-headed self-attention", "title": "Transformer USES_METHOD multi-headed self-attention\nConfidence: 100%\nEvidence: the first sequence transduction model based entirely on attention, replacing the recurrent layers", "to": "method:multi_headed_self_attention", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "we apply dropout to the output of each sub-layer", "relation_type": "USES_METHOD", "source_name": "Transformer", "target_name": "dropout", "title": "Transformer USES_METHOD dropout\nConfidence: 100%\nEvidence: we apply dropout to the output of each sub-layer", "to": "method:dropout", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "We used beam search with a beam size of 4 and length penalty \u03b1 = 0.6", "relation_type": "USES_METHOD", "source_name": "Transformer", "target_name": "beam search", "title": "Transformer USES_METHOD beam search\nConfidence: 100%\nEvidence: We used beam search with a beam size of 4 and length penalty \u03b1 = 0.6", "to": "method:beam_search", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "The Transformer (big) model trained for English-to-French", "relation_type": "APPLIED_TO", "source_name": "Transformer", "target_name": "WMT 2014 English-French dataset", "title": "Transformer APPLIED_TO WMT 2014 English-French dataset\nConfidence: 100%\nEvidence: The Transformer (big) model trained for English-to-French", "to": "system:wmt_2014_english_french_dataset", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "We trained a 4-layer transformer with d = 1024 on the Wall Street Journal (WSJ) portion of the Penn Treebank", "relation_type": "APPLIED_TO", "source_name": "Transformer", "target_name": "Wall Street Journal portion of the Penn Treebank", "title": "Transformer APPLIED_TO Wall Street Journal portion of the Penn Treebank\nConfidence: 100%\nEvidence: We trained a 4-layer transformer with d = 1024 on the Wall Street Journal (WSJ) portion of the Penn Treebank", "to": "system:wall_street_journal_portion_of_the_penn_treebank", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "The main subject matter is the introduction of the Transformer model, authored by a team from Google Brain.", "relation_type": "PROPOSED_BY", "source_name": "Transformer", "target_name": "Google Brain", "title": "Transformer PROPOSED_BY Google Brain\nConfidence: 100%\nEvidence: The main subject matter is the introduction of the Transformer model, authored by a team from Google Brain.", "to": "researcher:google_brain", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "BERT\u2019s model architecture is a multi-layer bidirectional Transformer encoder based on the original implementation described in Vaswani et al. (2017).", "relation_type": "PROPOSED_BY", "source_name": "Transformer", "target_name": "Vaswani et al.", "title": "Transformer PROPOSED_BY Vaswani et al.\nConfidence: 100%\nEvidence: BERT\u2019s model architecture is a multi-layer bidirectional Transformer encoder based on the original implementation described in Vaswani et al. (2017).", "to": "researcher:vaswani_et_al", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.8, "from": "theory:transformer", "full_evidence": "significant improvements in the expressiveness of models that can compute these conditional probabilities.", "relation_type": "EXTENDS", "source_name": "Transformer", "target_name": "Conditional Probability", "title": "Transformer EXTENDS Conditional Probability\nConfidence: 80%\nEvidence: significant improvements in the expressiveness of models that can compute these conditional probabilities.", "to": "concept:conditional_probability", "width": 2.0}, {"arrows": "to", "color": "#78909C", "edge_confidence": 0.8, "from": "theory:transformer", "full_evidence": "We expect that larger language models will perform better and be more sample efficient than current models.", "relation_type": "ASSOCIATED_WITH", "source_name": "Transformer", "target_name": "GPT-2", "title": "Transformer ASSOCIATED_WITH GPT-2\nConfidence: 80%\nEvidence: We expect that larger language models will perform better and be more sample efficient than current models.", "to": "system:gpt_2", "width": 2.0}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "We primarily train decoder-only Transformer models.", "relation_type": "APPLIED_TO", "source_name": "Transformer", "target_name": "WebText2", "title": "Transformer APPLIED_TO WebText2\nConfidence: 100%\nEvidence: We primarily train decoder-only Transformer models.", "to": "system:webtext2", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.8, "from": "theory:transformer", "full_evidence": "We have trained to near convergence on the full WebText2 dataset and observe no overfitting...", "relation_type": "USES_METHOD", "source_name": "Transformer", "target_name": "WebText2", "title": "Transformer USES_METHOD WebText2\nConfidence: 80%\nEvidence: We have trained to near convergence on the full WebText2 dataset and observe no overfitting...", "to": "system:webtext2", "width": 2.0}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 0.8, "from": "theory:transformer", "full_evidence": "Transformer performance depends very weakly on the shape parameters when we hold the total non-embedding parameter count N fixed.", "relation_type": "EXPLAINS", "source_name": "Transformer", "target_name": "cross-entropy loss", "title": "Transformer EXPLAINS cross-entropy loss\nConfidence: 80%\nEvidence: Transformer performance depends very weakly on the shape parameters when we hold the total non-embedding parameter count N fixed.", "to": "phenomenon:cross_entropy_loss", "width": 2.0}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "Now we will use S defined in Equation (5.4) to obtain a simple and universal fit for the dependence of the loss on model size and training time in the infinite data limit.", "relation_type": "EXTENDS", "source_name": "Transformer", "target_name": "L(N,S)", "title": "Transformer EXTENDS L(N,S)\nConfidence: 100%\nEvidence: Now we will use S defined in Equation (5.4) to obtain a simple and universal fit for the dependence of the loss on model size and training time in the...", "to": "theory:l_n_s", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "It appears to imply that compute-efficient training will eventually run into a problem with overfitting.", "relation_type": "EXTENDS", "source_name": "Transformer", "target_name": "data requirements of compute-efficient training", "title": "Transformer EXTENDS data requirements of compute-efficient training\nConfidence: 100%\nEvidence: It appears to imply that compute-efficient training will eventually run into a problem with overfitting.", "to": "concept:data_requirements_of_compute_efficient_training", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 0.8, "from": "theory:transformer", "full_evidence": "We compare the performance of standard Transformers to current Transformers.", "relation_type": "ASSOCIATED_WITH", "source_name": "Transformer", "target_name": "empirical scaling laws", "title": "Transformer ASSOCIATED_WITH empirical scaling laws\nConfidence: 80%\nEvidence: We compare the performance of standard Transformers to current Transformers.", "to": "theory:empirical_scaling_laws", "width": 2.0}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "We experiment with applying a standard Transformer directly to images.", "relation_type": "EXTENDS", "source_name": "Transformer", "target_name": "Vision Transformer", "title": "Transformer EXTENDS Vision Transformer\nConfidence: 100%\nEvidence: We experiment with applying a standard Transformer directly to images.", "to": "system:vision_transformer", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "The paper discusses the application of the Transformer architecture, traditionally used in natural language processing, to image recognition tasks.", "relation_type": "EXPLAINS", "source_name": "Transformer", "target_name": "Vision Transformer", "title": "Transformer EXPLAINS Vision Transformer\nConfidence: 100%\nEvidence: The paper discusses the application of the Transformer architecture, traditionally used in natural language processing, to image recognition tasks.", "to": "system:vision_transformer", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "There is a long history of scaling for transformer based language models.", "relation_type": "EXPLAINS", "source_name": "Transformer", "target_name": "scaling", "title": "Transformer EXPLAINS scaling\nConfidence: 100%\nEvidence: There is a long history of scaling for transformer based language models.", "to": "concept:scaling", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "We trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million sentence pairs.", "relation_type": "APPLIED_TO", "source_name": "Transformer", "target_name": "WMT 2014 English-German dataset", "title": "Transformer APPLIED_TO WMT 2014 English-German dataset\nConfidence: 100%\nEvidence: We trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million sentence pairs.", "to": "system:wmt_2014_english_german_dataset", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "discusses the development of FlashAttention, an innovative attention algorithm designed to enhance the efficiency of Transformer models", "relation_type": "EXPLAINS", "source_name": "Transformer", "target_name": "FlashAttention", "title": "Transformer EXPLAINS FlashAttention\nConfidence: 100%\nEvidence: discusses the development of FlashAttention, an innovative attention algorithm designed to enhance the efficiency of Transformer models", "to": "system:flashattention", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "We used the Adam optimizer with \u03b2 =0.9, \u03b2 =0.98 and \u03f5=10\u22129.", "relation_type": "USES_METHOD", "source_name": "Transformer", "target_name": "Adam", "title": "Transformer USES_METHOD Adam\nConfidence: 100%\nEvidence: We used the Adam optimizer with \u03b2 =0.9, \u03b2 =0.98 and \u03f5=10\u22129.", "to": "method:adam", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "the capacity of transformer language models has increased substantially", "relation_type": "EXPLAINS", "source_name": "Transformer", "target_name": "few-shot learning", "title": "Transformer EXPLAINS few-shot learning\nConfidence: 100%\nEvidence: the capacity of transformer language models has increased substantially", "to": "method:few_shot_learning", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "theory:transformer", "full_evidence": "we present an overview of the modifications we made to the transformer architecture (Vaswani et al., 2017)", "relation_type": "EXPLAINS", "source_name": "Transformer", "target_name": "LLaMA", "title": "Transformer EXPLAINS LLaMA\nConfidence: 100%\nEvidence: we present an overview of the modifications we made to the transformer architecture (Vaswani et al., 2017)", "to": "system:llama", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "finding:bleu", "full_evidence": "Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task.", "relation_type": "SUPPORTS", "source_name": "BLEU", "target_name": "Transformer", "title": "BLEU SUPPORTS Transformer\nConfidence: 100%\nEvidence: Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task.", "to": "theory:transformer", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:tensor2tensor", "full_evidence": "Nik designed, implemented, tuned and evaluated countless model variants in our original codebase and tensor2tensor.", "relation_type": "ASSOCIATED_WITH", "source_name": "tensor2tensor", "target_name": "Transformer", "title": "tensor2tensor ASSOCIATED_WITH Transformer\nConfidence: 100%\nEvidence: Nik designed, implemented, tuned and evaluated countless model variants in our original codebase and tensor2tensor.", "to": "theory:transformer", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "concept:multi_head_attention", "full_evidence": "Noam proposed scaled dot-product attention, multi-head attention and the parameter-free position representation.", "relation_type": "PROPOSED_BY", "source_name": "multi-head attention", "target_name": "Noam Shazeer", "title": "multi-head attention PROPOSED_BY Noam Shazeer\nConfidence: 100%\nEvidence: Noam proposed scaled dot-product attention, multi-head attention and the parameter-free position representation.", "to": "researcher:noam_shazeer", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "concept:self_attention", "full_evidence": "In Multi-Head Attention, we found it beneficial to linearly project the queries, keys and values h times with different, learned linear projections.", "relation_type": "EXTENDS", "source_name": "self-attention", "target_name": "multi-head attention", "title": "self-attention EXTENDS multi-head attention\nConfidence: 100%\nEvidence: In Multi-Head Attention, we found it beneficial to linearly project the queries, keys and values h times with different, learned linear projections.", "to": "concept:multi_head_attention", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "concept:self_attention", "full_evidence": "Jakob proposed replacing RNNs with self-attention and started the effort to evaluate this idea.", "relation_type": "PROPOSED_BY", "source_name": "self-attention", "target_name": "Jakob Uszkoreit", "title": "self-attention PROPOSED_BY Jakob Uszkoreit\nConfidence: 100%\nEvidence: Jakob proposed replacing RNNs with self-attention and started the effort to evaluate this idea.", "to": "researcher:jakob_uszkoreit", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "finding:state_of_the_art", "full_evidence": "achieving state-of-the-art BLEU scores while being more efficient in training time", "relation_type": "SUPPORTS", "source_name": "state-of-the-art", "target_name": "Transformer", "title": "state-of-the-art SUPPORTS Transformer\nConfidence: 100%\nEvidence: achieving state-of-the-art BLEU scores while being more efficient in training time", "to": "theory:transformer", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "The document is a research paper introducing BERT (Bidirectional Encoder Representations from Transformers), authored by Jacob Devlin...", "relation_type": "PROPOSED_BY", "source_name": "BERT", "target_name": "Jacob Devlin", "title": "BERT PROPOSED_BY Jacob Devlin\nConfidence: 100%\nEvidence: The document is a research paper introducing BERT (Bidirectional Encoder Representations from Transformers), authored by Jacob Devlin...", "to": "researcher:jacob_devlin", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "The document is a research paper introducing BERT (Bidirectional Encoder Representations from Transformers), authored by Ming-Wei Chang.", "relation_type": "PROPOSED_BY", "source_name": "BERT", "target_name": "Ming-Wei Chang", "title": "BERT PROPOSED_BY Ming-Wei Chang\nConfidence: 100%\nEvidence: The document is a research paper introducing BERT (Bidirectional Encoder Representations from Transformers), authored by Ming-Wei Chang.", "to": "researcher:ming_wei_chang", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "The document is a research paper introducing BERT (Bidirectional Encoder Representations from Transformers), authored by Kenton Lee.", "relation_type": "PROPOSED_BY", "source_name": "BERT", "target_name": "Kenton Lee", "title": "BERT PROPOSED_BY Kenton Lee\nConfidence: 100%\nEvidence: The document is a research paper introducing BERT (Bidirectional Encoder Representations from Transformers), authored by Kenton Lee.", "to": "researcher:kenton_lee", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "The document is a research paper introducing BERT (Bidirectional Encoder Representations from Transformers), authored by Kristina Toutanova.", "relation_type": "PROPOSED_BY", "source_name": "BERT", "target_name": "Kristina Toutanova", "title": "BERT PROPOSED_BY Kristina Toutanova\nConfidence: 100%\nEvidence: The document is a research paper introducing BERT (Bidirectional Encoder Representations from Transformers), authored by Kristina Toutanova.", "to": "researcher:kristina_toutanova", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "Results on selected GLUE tasks are shown in Table 6.", "relation_type": "SUPPORTS", "source_name": "BERT", "target_name": "GLUE", "title": "BERT SUPPORTS GLUE\nConfidence: 100%\nEvidence: Results on selected GLUE tasks are shown in Table 6.", "to": "system:glue", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "To fine-tune on GLUE, we represent the input sequence (for single sentence or sentence pairs) as described in Section 3.", "relation_type": "ASSOCIATED_WITH", "source_name": "BERT", "target_name": "GLUE", "title": "BERT ASSOCIATED_WITH GLUE\nConfidence: 100%\nEvidence: To fine-tune on GLUE, we represent the input sequence (for single sentence or sentence pairs) as described in Section 3.", "to": "system:glue", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "BERT advances the state of the art for eleven NLP tasks.", "relation_type": "SUPPORTS", "source_name": "BERT", "target_name": "MultiNLI", "title": "BERT SUPPORTS MultiNLI\nConfidence: 100%\nEvidence: BERT advances the state of the art for eleven NLP tasks.", "to": "system:multinli", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.8, "from": "system:bert", "full_evidence": "The advantage of this procedure is that the Transformer encoder does not know which words...", "relation_type": "USES_METHOD", "source_name": "BERT", "target_name": "masked language model", "title": "BERT USES_METHOD masked language model\nConfidence: 80%\nEvidence: The advantage of this procedure is that the Transformer encoder does not know which words...", "to": "method:masked_language_model", "width": 2.0}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.8, "from": "system:bert", "full_evidence": "Next Sentence Prediction The next sentence prediction task can be illustrated in the following examples.", "relation_type": "USES_METHOD", "source_name": "BERT", "target_name": "next sentence prediction", "title": "BERT USES_METHOD next sentence prediction\nConfidence: 80%\nEvidence: Next Sentence Prediction The next sentence prediction task can be illustrated in the following examples.", "to": "method:next_sentence_prediction", "width": 2.0}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "the major limitation is that standard language models are unidirectional", "relation_type": "CONTRADICTS", "source_name": "BERT", "target_name": "unidirectional language models", "title": "BERT CONTRADICTS unidirectional language models\nConfidence: 100%\nEvidence: the major limitation is that standard language models are unidirectional", "to": "concept:unidirectional_language_models", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "BERT\u2019s model architecture is a multi-layer bidirectional Transformer encoder.", "relation_type": "ASSOCIATED_WITH", "source_name": "BERT", "target_name": "Transformer", "title": "BERT ASSOCIATED_WITH Transformer\nConfidence: 100%\nEvidence: BERT\u2019s model architecture is a multi-layer bidirectional Transformer encoder.", "to": "theory:transformer", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.7, "from": "system:bert", "full_evidence": "presents BERT\u0027s innovative approach to pre-training and fine-tuning for enhanced performance.", "relation_type": "USES_METHOD", "source_name": "BERT", "target_name": "fine-tuning", "title": "BERT USES_METHOD fine-tuning\nConfidence: 70%\nEvidence: presents BERT\u0027s innovative approach to pre-training and fine-tuning for enhanced performance.", "to": "method:fine_tuning", "width": 1.75}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "When fine-tuning on the SWAG dataset, we construct four input sequences.", "relation_type": "ASSOCIATED_WITH", "source_name": "BERT", "target_name": "SWAG", "title": "BERT ASSOCIATED_WITH SWAG\nConfidence: 100%\nEvidence: When fine-tuning on the SWAG dataset, we construct four input sequences.", "to": "system:swag", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "We fine-tune the model for 3 epochs with a learning rate of 2e-5 and a batch size of 16.", "relation_type": "SUPPORTS", "source_name": "BERT", "target_name": "SQuAD", "title": "BERT SUPPORTS SQuAD\nConfidence: 100%\nEvidence: We fine-tune the model for 3 epochs with a learning rate of 2e-5 and a batch size of 16.", "to": "system:squad", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "Our best performing system outperforms the top leaderboard system by +1.5 F1 in ensembling and +1.3 F1 as a single system.", "relation_type": "ASSOCIATED_WITH", "source_name": "BERT", "target_name": "SQuAD", "title": "BERT ASSOCIATED_WITH SQuAD\nConfidence: 100%\nEvidence: Our best performing system outperforms the top leaderboard system by +1.5 F1 in ensembling and +1.3 F1 as a single system.", "to": "system:squad", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "Our major contribution is further generalizing these findings to deep bidirectional architectures.", "relation_type": "EXTENDS", "source_name": "BERT", "target_name": "transfer learning", "title": "BERT EXTENDS transfer learning\nConfidence: 100%\nEvidence: Our major contribution is further generalizing these findings to deep bidirectional architectures.", "to": "concept:transfer_learning", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "Our major contribution is further generalizing these findings to deep bidirectional architectures.", "relation_type": "EXTENDS", "source_name": "BERT", "target_name": "deep bidirectional architectures", "title": "BERT EXTENDS deep bidirectional architectures\nConfidence: 100%\nEvidence: Our major contribution is further generalizing these findings to deep bidirectional architectures.", "to": "concept:deep_bidirectional_architectures", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 0.9, "from": "system:bert", "full_evidence": "The main subject matter focuses on a new language representation model that improves upon existing methods by utilizing deep bidirectional representations for natural language processing tasks.", "relation_type": "EXPLAINS", "source_name": "BERT", "target_name": "deep bidirectional representations", "title": "BERT EXPLAINS deep bidirectional representations\nConfidence: 90%\nEvidence: The main subject matter focuses on a new language representation model that improves upon existing methods by utilizing deep bidirectional representat...", "to": "concept:deep_bidirectional_representations", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.8, "from": "system:bert", "full_evidence": "achieving state-of-the-art results in various benchmarks such as question answering and language inference.", "relation_type": "SUPPORTS", "source_name": "BERT", "target_name": "question answering", "title": "BERT SUPPORTS question answering\nConfidence: 80%\nEvidence: achieving state-of-the-art results in various benchmarks such as question answering and language inference.", "to": "phenomenon:question_answering", "width": 2.0}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.8, "from": "system:bert", "full_evidence": "achieving state-of-the-art results in various benchmarks such as question answering and language inference.", "relation_type": "SUPPORTS", "source_name": "BERT", "target_name": "language inference", "title": "BERT SUPPORTS language inference\nConfidence: 80%\nEvidence: achieving state-of-the-art results in various benchmarks such as question answering and language inference.", "to": "phenomenon:language_inference", "width": 2.0}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 0.8, "from": "system:bert", "full_evidence": "The paper discusses the limitations of previous unidirectional models and presents BERT\u0027s innovative approach to pre-training and fine-tuning for enhanced performance.", "relation_type": "CONTRADICTS", "source_name": "BERT", "target_name": "unidirectional models", "title": "BERT CONTRADICTS unidirectional models\nConfidence: 80%\nEvidence: The paper discusses the limitations of previous unidirectional models and presents BERT\u0027s innovative approach to pre-training and fine-tuning for enha...", "to": "concept:unidirectional_models", "width": 2.0}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.7, "from": "system:bert", "full_evidence": "presents BERT\u0027s innovative approach to pre-training and fine-tuning for enhanced performance.", "relation_type": "USES_METHOD", "source_name": "BERT", "target_name": "pre-training", "title": "BERT USES_METHOD pre-training\nConfidence: 70%\nEvidence: presents BERT\u0027s innovative approach to pre-training and fine-tuning for enhanced performance.", "to": "method:pre_training", "width": 1.75}, {"arrows": "to", "color": "#78909C", "edge_confidence": 0.9, "from": "system:bert", "full_evidence": "The most comparable existing pre-training method to BERT is OpenAI GPT...", "relation_type": "ASSOCIATED_WITH", "source_name": "BERT", "target_name": "OpenAI GPT", "title": "BERT ASSOCIATED_WITH OpenAI GPT\nConfidence: 90%\nEvidence: The most comparable existing pre-training method to BERT is OpenAI GPT...", "to": "system:openai_gpt", "width": 2.25}, {"arrows": "to", "color": "#78909C", "edge_confidence": 0.9, "from": "system:bert", "full_evidence": "Among the tasks, (a) and (b) are sequence-level tasks while (c) and (d) are token-level tasks.", "relation_type": "ASSOCIATED_WITH", "source_name": "BERT", "target_name": "ELMo", "title": "BERT ASSOCIATED_WITH ELMo\nConfidence: 90%\nEvidence: Among the tasks, (a) and (b) are sequence-level tasks while (c) and (d) are token-level tasks.", "to": "system:elmo", "width": 2.25}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "MNLI Multi-Genre Natural Language Inference is a large-scale, crowdsourced entailment classification task...", "relation_type": "ASSOCIATED_WITH", "source_name": "BERT", "target_name": "MNLI", "title": "BERT ASSOCIATED_WITH MNLI\nConfidence: 100%\nEvidence: MNLI Multi-Genre Natural Language Inference is a large-scale, crowdsourced entailment classification task...", "to": "system:mnli", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "QQP Quora Question Pairs is a binary classification task where the goal is to determine if two questions asked on Quora are semantically equivalent...", "relation_type": "ASSOCIATED_WITH", "source_name": "BERT", "target_name": "QQP", "title": "BERT ASSOCIATED_WITH QQP\nConfidence: 100%\nEvidence: QQP Quora Question Pairs is a binary classification task where the goal is to determine if two questions asked on Quora are semantically equivalent...", "to": "system:qqp", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "CoLA The Corpus of Linguistic Acceptability is a binary single-sentence classification task...", "relation_type": "ASSOCIATED_WITH", "source_name": "BERT", "target_name": "CoLA", "title": "BERT ASSOCIATED_WITH CoLA\nConfidence: 100%\nEvidence: CoLA The Corpus of Linguistic Acceptability is a binary single-sentence classification task...", "to": "system:cola", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "SST-2 The Stanford Sentiment Treebank is a binary single-sentence classification task consisting of sentences extracted from movie reviews...", "relation_type": "ASSOCIATED_WITH", "source_name": "BERT", "target_name": "SST-2", "title": "BERT ASSOCIATED_WITH SST-2\nConfidence: 100%\nEvidence: SST-2 The Stanford Sentiment Treebank is a binary single-sentence classification task consisting of sentences extracted from movie reviews...", "to": "system:sst_2", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "RTE Recognizing Textual Entailment is a binary entailment task similar to MNLI...", "relation_type": "ASSOCIATED_WITH", "source_name": "BERT", "target_name": "RTE", "title": "BERT ASSOCIATED_WITH RTE\nConfidence: 100%\nEvidence: RTE Recognizing Textual Entailment is a binary entailment task similar to MNLI...", "to": "system:rte", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "STS-B The Semantic Textual Similarity Benchmark is a collection of sentence pairs drawn from news headlines and other sources...", "relation_type": "ASSOCIATED_WITH", "source_name": "BERT", "target_name": "STS-B", "title": "BERT ASSOCIATED_WITH STS-B\nConfidence: 100%\nEvidence: STS-B The Semantic Textual Similarity Benchmark is a collection of sentence pairs drawn from news headlines and other sources...", "to": "system:sts_b", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:bert", "full_evidence": "MRPC Microsoft Research Paraphrase Corpus consists of sentence pairs automatically extracted from online news sources...", "relation_type": "ASSOCIATED_WITH", "source_name": "BERT", "target_name": "MRPC", "title": "BERT ASSOCIATED_WITH MRPC\nConfidence: 100%\nEvidence: MRPC Microsoft Research Paraphrase Corpus consists of sentence pairs automatically extracted from online news sources...", "to": "system:mrpc", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:glue", "full_evidence": "The General Language Understanding Evaluation (GLUE) benchmark is a collection of diverse natural language understanding tasks.", "relation_type": "APPLIED_TO", "source_name": "GLUE", "target_name": "BERT", "title": "GLUE APPLIED_TO BERT\nConfidence: 100%\nEvidence: The General Language Understanding Evaluation (GLUE) benchmark is a collection of diverse natural language understanding tasks.", "to": "system:bert", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.9, "from": "system:glue", "full_evidence": "Our GLUE results in Table 1 are obtained from https://gluebenchmark.com/", "relation_type": "INVESTIGATES", "source_name": "GLUE", "target_name": "BERT", "title": "GLUE INVESTIGATES BERT\nConfidence: 90%\nEvidence: Our GLUE results in Table 1 are obtained from https://gluebenchmark.com/", "to": "system:bert", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:masked_language_model", "full_evidence": "We demonstrate in Section 5.1 that pre-training towards this task is very beneficial to both QA and NLI.", "relation_type": "SUPPORTS", "source_name": "masked language model", "target_name": "BERT", "title": "masked language model SUPPORTS BERT\nConfidence: 100%\nEvidence: We demonstrate in Section 5.1 that pre-training towards this task is very beneficial to both QA and NLI.", "to": "system:bert", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:next_sentence_prediction", "full_evidence": "Despite its simplicity, we demonstrate in Section 5.1 that pre-training towards this task is very beneficial to both QA and NLI.", "relation_type": "SUPPORTS", "source_name": "next sentence prediction", "target_name": "BERT", "title": "next sentence prediction SUPPORTS BERT\nConfidence: 100%\nEvidence: Despite its simplicity, we demonstrate in Section 5.1 that pre-training towards this task is very beneficial to both QA and NLI.", "to": "system:bert", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "concept:bidirectional_representations", "full_evidence": "We demonstrate the importance of bidirectional pre-training for language representations.", "relation_type": "EXPLAINS", "source_name": "bidirectional representations", "target_name": "natural language processing", "title": "bidirectional representations EXPLAINS natural language processing\nConfidence: 100%\nEvidence: We demonstrate the importance of bidirectional pre-training for language representations.", "to": "field:natural_language_processing", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 0.9, "from": "field:natural_language_processing", "full_evidence": "tests reading comprehension capabilities.", "relation_type": "EXPLAINS", "source_name": "natural language processing", "target_name": "reading comprehension", "title": "natural language processing EXPLAINS reading comprehension\nConfidence: 90%\nEvidence: tests reading comprehension capabilities.", "to": "concept:reading_comprehension", "width": 2.25}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 0.9, "from": "field:natural_language_processing", "full_evidence": "tests the ability of systems to model long-range dependencies in text.", "relation_type": "EXPLAINS", "source_name": "natural language processing", "target_name": "long-range dependencies", "title": "natural language processing EXPLAINS long-range dependencies\nConfidence: 90%\nEvidence: tests the ability of systems to model long-range dependencies in text.", "to": "concept:long_range_dependencies", "width": 2.25}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:bookscorpus", "full_evidence": "For the pre-training corpus we use the BooksCorpus (800M words).", "relation_type": "APPLIED_TO", "source_name": "BooksCorpus", "target_name": "BERT", "title": "BooksCorpus APPLIED_TO BERT\nConfidence: 100%\nEvidence: For the pre-training corpus we use the BooksCorpus (800M words).", "to": "system:bert", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:english_wikipedia", "full_evidence": "For Wikipedia we extract only the text passages and ignore lists, tables, and headers.", "relation_type": "APPLIED_TO", "source_name": "English Wikipedia", "target_name": "BERT", "title": "English Wikipedia APPLIED_TO BERT\nConfidence: 100%\nEvidence: For Wikipedia we extract only the text passages and ignore lists, tables, and headers.", "to": "system:bert", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:squad", "full_evidence": "The model starts out with better performance than the GPT-3 model on SQuAD v2.", "relation_type": "INVESTIGATES", "source_name": "SQuAD", "target_name": "question answering", "title": "SQuAD INVESTIGATES question answering\nConfidence: 100%\nEvidence: The model starts out with better performance than the GPT-3 model on SQuAD v2.", "to": "phenomenon:question_answering", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:openai_gpt", "full_evidence": "GPT is trained on the BooksCorpus (800M words); BERT is trained on the BooksCorpus (800M words) and Wikipedia (2,500M words)...", "relation_type": "USES_METHOD", "source_name": "OpenAI GPT", "target_name": "Left-to-Right (LTR) Pre-training", "title": "OpenAI GPT USES_METHOD Left-to-Right (LTR) Pre-training\nConfidence: 100%\nEvidence: GPT is trained on the BooksCorpus (800M words); BERT is trained on the BooksCorpus (800M words) and Wikipedia (2,500M words)...", "to": "method:left_to_right_ltr_pre_training", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.8, "from": "method:fine_tuning", "full_evidence": "we plan to investigate fine-tuning on benchmarks such as decaNLP and GLUE", "relation_type": "APPLIED_TO", "source_name": "fine-tuning", "target_name": "GLUE", "title": "fine-tuning APPLIED_TO GLUE\nConfidence: 80%\nEvidence: we plan to investigate fine-tuning on benchmarks such as decaNLP and GLUE", "to": "system:glue", "width": 2.0}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "concept:bi_directionality", "full_evidence": "The core argument of this work is that the bi-directionality and the two pre-training tasks presented in Section 3.1 account for the majority of the empirical improvements...", "relation_type": "SUPPORTS", "source_name": "bi-directionality", "target_name": "BERT", "title": "bi-directionality SUPPORTS BERT\nConfidence: 100%\nEvidence: The core argument of this work is that the bi-directionality and the two pre-training tasks presented in Section 3.1 account for the majority of the e...", "to": "system:bert", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.9, "from": "concept:language_models", "full_evidence": "We connect these two lines of work and continue the trend of more general methods of transfer.", "relation_type": "USES_METHOD", "source_name": "Language Models", "target_name": "Multitask Learning", "title": "Language Models USES_METHOD Multitask Learning\nConfidence: 90%\nEvidence: We connect these two lines of work and continue the trend of more general methods of transfer.", "to": "concept:multitask_learning", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "concept:language_models", "full_evidence": "authored by Alec Radford", "relation_type": "PROPOSED_BY", "source_name": "Language Models", "target_name": "Alec Radford", "title": "Language Models PROPOSED_BY Alec Radford\nConfidence: 90%\nEvidence: authored by Alec Radford", "to": "researcher:alec_radford", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "concept:language_models", "full_evidence": "authored by Jeffrey Wu", "relation_type": "PROPOSED_BY", "source_name": "Language Models", "target_name": "Jeffrey Wu", "title": "Language Models PROPOSED_BY Jeffrey Wu\nConfidence: 90%\nEvidence: authored by Jeffrey Wu", "to": "researcher:jeffrey_wu", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "concept:language_models", "full_evidence": "authored by Rewon Child", "relation_type": "PROPOSED_BY", "source_name": "Language Models", "target_name": "Rewon Child", "title": "Language Models PROPOSED_BY Rewon Child\nConfidence: 90%\nEvidence: authored by Rewon Child", "to": "researcher:rewon_child", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "concept:language_models", "full_evidence": "authored by David Luan", "relation_type": "PROPOSED_BY", "source_name": "Language Models", "target_name": "David Luan", "title": "Language Models PROPOSED_BY David Luan\nConfidence: 90%\nEvidence: authored by David Luan", "to": "researcher:david_luan", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "concept:language_models", "full_evidence": "authored by Dario Amodei", "relation_type": "PROPOSED_BY", "source_name": "Language Models", "target_name": "Dario Amodei", "title": "Language Models PROPOSED_BY Dario Amodei\nConfidence: 90%\nEvidence: authored by Dario Amodei", "to": "researcher:dario_amodei", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "concept:language_models", "full_evidence": "authored by Ilya Sutskever", "relation_type": "PROPOSED_BY", "source_name": "Language Models", "target_name": "Ilya Sutskever", "title": "Language Models PROPOSED_BY Ilya Sutskever\nConfidence: 90%\nEvidence: authored by Ilya Sutskever", "to": "researcher:ilya_sutskever", "width": 2.25}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.9, "from": "concept:language_models", "full_evidence": "trained on a new dataset of millions of webpages called WebText.", "relation_type": "APPLIED_TO", "source_name": "Language Models", "target_name": "WebText", "title": "Language Models APPLIED_TO WebText\nConfidence: 90%\nEvidence: trained on a new dataset of millions of webpages called WebText.", "to": "system:webtext", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "system:webtext", "full_evidence": "Samples from the model reflect these improvements and contain coherent paragraphs of text.", "relation_type": "SUPPORTS", "source_name": "WebText", "target_name": "GPT-2", "title": "WebText SUPPORTS GPT-2\nConfidence: 90%\nEvidence: Samples from the model reflect these improvements and contain coherent paragraphs of text.", "to": "system:gpt_2", "width": 2.25}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:webtext", "full_evidence": "We generated samples from GPT-2 conditioned on WebText test set articles.", "relation_type": "APPLIED_TO", "source_name": "WebText", "target_name": "GPT-2", "title": "WebText APPLIED_TO GPT-2\nConfidence: 100%\nEvidence: We generated samples from GPT-2 conditioned on WebText test set articles.", "to": "system:gpt_2", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.8, "from": "system:webtext", "full_evidence": "We use a combination of the Dragnet and Newspaper1 content extractors.", "relation_type": "USES_METHOD", "source_name": "WebText", "target_name": "Byte Pair Encoding", "title": "WebText USES_METHOD Byte Pair Encoding\nConfidence: 80%\nEvidence: We use a combination of the Dragnet and Newspaper1 content extractors.", "to": "method:byte_pair_encoding", "width": 2.0}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "system:webtext", "full_evidence": "The paper discusses the capabilities of language models, particularly focusing on their ability to perform various natural language processing tasks.", "relation_type": "PROPOSED_BY", "source_name": "WebText", "target_name": "Alec Radford", "title": "WebText PROPOSED_BY Alec Radford\nConfidence: 90%\nEvidence: The paper discusses the capabilities of language models, particularly focusing on their ability to perform various natural language processing tasks.", "to": "researcher:alec_radford", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "system:webtext", "full_evidence": "The paper discusses the capabilities of language models, particularly focusing on their ability to perform various natural language processing tasks.", "relation_type": "PROPOSED_BY", "source_name": "WebText", "target_name": "Jeffrey Wu", "title": "WebText PROPOSED_BY Jeffrey Wu\nConfidence: 90%\nEvidence: The paper discusses the capabilities of language models, particularly focusing on their ability to perform various natural language processing tasks.", "to": "researcher:jeffrey_wu", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "system:webtext", "full_evidence": "The paper discusses the capabilities of language models, particularly focusing on their ability to perform various natural language processing tasks.", "relation_type": "PROPOSED_BY", "source_name": "WebText", "target_name": "Rewon Child", "title": "WebText PROPOSED_BY Rewon Child\nConfidence: 90%\nEvidence: The paper discusses the capabilities of language models, particularly focusing on their ability to perform various natural language processing tasks.", "to": "researcher:rewon_child", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "system:webtext", "full_evidence": "The paper discusses the capabilities of language models, particularly focusing on their ability to perform various natural language processing tasks.", "relation_type": "PROPOSED_BY", "source_name": "WebText", "target_name": "David Luan", "title": "WebText PROPOSED_BY David Luan\nConfidence: 90%\nEvidence: The paper discusses the capabilities of language models, particularly focusing on their ability to perform various natural language processing tasks.", "to": "researcher:david_luan", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "system:webtext", "full_evidence": "The paper discusses the capabilities of language models, particularly focusing on their ability to perform various natural language processing tasks.", "relation_type": "PROPOSED_BY", "source_name": "WebText", "target_name": "Dario Amodei", "title": "WebText PROPOSED_BY Dario Amodei\nConfidence: 90%\nEvidence: The paper discusses the capabilities of language models, particularly focusing on their ability to perform various natural language processing tasks.", "to": "researcher:dario_amodei", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "system:webtext", "full_evidence": "The paper discusses the capabilities of language models, particularly focusing on their ability to perform various natural language processing tasks.", "relation_type": "PROPOSED_BY", "source_name": "WebText", "target_name": "Ilya Sutskever", "title": "WebText PROPOSED_BY Ilya Sutskever\nConfidence: 90%\nEvidence: The paper discusses the capabilities of language models, particularly focusing on their ability to perform various natural language processing tasks.", "to": "researcher:ilya_sutskever", "width": 2.25}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.8, "from": "system:webtext", "full_evidence": "They depend very weakly on model shape and other Transformer hyperparameters, with specific numerical values associated with the Webtext training set.", "relation_type": "APPLIED_TO", "source_name": "WebText", "target_name": "Scaling Laws For Neural Language Models", "title": "WebText APPLIED_TO Scaling Laws For Neural Language Models\nConfidence: 80%\nEvidence: They depend very weakly on model shape and other Transformer hyperparameters, with specific numerical values associated with the Webtext training set.", "to": "publication:scaling_laws_for_neural_language_models", "width": 2.0}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.8, "from": "system:webtext", "full_evidence": "As an initial step towards zero-shot task transfer, we are interested in understanding how WebText LM\u2019s perform.", "relation_type": "INVESTIGATES", "source_name": "WebText", "target_name": "zero-shot task transfer", "title": "WebText INVESTIGATES zero-shot task transfer\nConfidence: 80%\nEvidence: As an initial step towards zero-shot task transfer, we are interested in understanding how WebText LM\u2019s perform.", "to": "phenomenon:zero_shot_task_transfer", "width": 2.0}, {"arrows": "to", "color": "#78909C", "edge_confidence": 0.9, "from": "system:gpt_2", "full_evidence": "GPT-2 is a 1.5B parameter Transformer that achieves state of the art results", "relation_type": "ASSOCIATED_WITH", "source_name": "GPT-2", "target_name": "Transformer", "title": "GPT-2 ASSOCIATED_WITH Transformer\nConfidence: 90%\nEvidence: GPT-2 is a 1.5B parameter Transformer that achieves state of the art results", "to": "theory:transformer", "width": 2.25}, {"arrows": "to", "color": "#FFA726", "edge_confidence": 0.8, "from": "system:gpt_2", "full_evidence": "We use a Transformer based architecture for our LMs.", "relation_type": "IMPLEMENTS", "source_name": "GPT-2", "target_name": "Transformer", "title": "GPT-2 IMPLEMENTS Transformer\nConfidence: 80%\nEvidence: We use a Transformer based architecture for our LMs.", "to": "theory:transformer", "width": 2.0}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "system:gpt_2", "full_evidence": "GPT-2 improves the state of the art from 99.8 to 8.6 perplexity.", "relation_type": "SUPPORTS", "source_name": "GPT-2", "target_name": "Children\u2019s Book Test", "title": "GPT-2 SUPPORTS Children\u2019s Book Test\nConfidence: 90%\nEvidence: GPT-2 improves the state of the art from 99.8 to 8.6 perplexity.", "to": "system:children_s_book_test", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "system:gpt_2", "full_evidence": "GPT-2 improves the state of the art from 99.8 to 8.6 perplexity.", "relation_type": "SUPPORTS", "source_name": "GPT-2", "target_name": "LAMBADA", "title": "GPT-2 SUPPORTS LAMBADA\nConfidence: 90%\nEvidence: GPT-2 improves the state of the art from 99.8 to 8.6 perplexity.", "to": "system:lambada", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "system:gpt_2", "full_evidence": "GPT-2 improves state of the art accuracy by 7%, achieving 70.70%.", "relation_type": "SUPPORTS", "source_name": "GPT-2", "target_name": "Winograd Schemas Challenge", "title": "GPT-2 SUPPORTS Winograd Schemas Challenge\nConfidence: 90%\nEvidence: GPT-2 improves state of the art accuracy by 7%, achieving 70.70%.", "to": "system:winograd_schemas_challenge", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "system:gpt_2", "full_evidence": "Greedy decoding from GPT-2 when conditioned on a document, achieves 55 F1.", "relation_type": "SUPPORTS", "source_name": "GPT-2", "target_name": "Conversation Question Answering dataset", "title": "GPT-2 SUPPORTS Conversation Question Answering dataset\nConfidence: 90%\nEvidence: Greedy decoding from GPT-2 when conditioned on a document, achieves 55 F1.", "to": "system:conversation_question_answering_dataset", "width": 2.25}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.9, "from": "system:gpt_2", "full_evidence": "Greedy decoding from GPT-2 when conditioned on a document.", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "greedy decoding", "title": "GPT-2 USES_METHOD greedy decoding\nConfidence: 90%\nEvidence: Greedy decoding from GPT-2 when conditioned on a document.", "to": "method:greedy_decoding", "width": 2.25}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.9, "from": "system:gpt_2", "full_evidence": "we add the text TL;DR: after the article and generate 100 tokens with Top-k random sampling.", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "Top-k random sampling", "title": "GPT-2 USES_METHOD Top-k random sampling\nConfidence: 90%\nEvidence: we add the text TL;DR: after the article and generate 100 tokens with Top-k random sampling.", "to": "method:top_k_random_sampling", "width": 2.25}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "Our results suggest that unsupervised task learning is an additional promising area of research to explore.", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "unsupervised task learning", "title": "GPT-2 USES_METHOD unsupervised task learning\nConfidence: 100%\nEvidence: Our results suggest that unsupervised task learning is an additional promising area of research to explore.", "to": "concept:unsupervised_task_learning", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.8, "from": "system:gpt_2", "full_evidence": "we plan to investigate fine-tuning on benchmarks such as decaNLP and GLUE", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "fine-tuning", "title": "GPT-2 USES_METHOD fine-tuning\nConfidence: 80%\nEvidence: we plan to investigate fine-tuning on benchmarks such as decaNLP and GLUE", "to": "method:fine_tuning", "width": 2.0}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.9, "from": "system:gpt_2", "full_evidence": "the inefficiencies of uni-directional representations demonstrated by BERT", "relation_type": "EXTENDS", "source_name": "GPT-2", "target_name": "BERT", "title": "GPT-2 EXTENDS BERT\nConfidence: 90%\nEvidence: the inefficiencies of uni-directional representations demonstrated by BERT", "to": "system:bert", "width": 2.25}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.8, "from": "system:gpt_2", "full_evidence": "on common tasks that we evaluated on, such as question answering and translation", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "question answering", "title": "GPT-2 INVESTIGATES question answering\nConfidence: 80%\nEvidence: on common tasks that we evaluated on, such as question answering and translation", "to": "phenomenon:question_answering", "width": 2.0}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.8, "from": "system:gpt_2", "full_evidence": "on common tasks that we evaluated on, such as question answering and translation", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "translation", "title": "GPT-2 INVESTIGATES translation\nConfidence: 80%\nEvidence: on common tasks that we evaluated on, such as question answering and translation", "to": "phenomenon:translation", "width": 2.0}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.8, "from": "system:gpt_2", "full_evidence": "the observation of Liu et al. (2018) that a model trained to generate Wikipedia articles also learned to translate names between languages", "relation_type": "PROPOSED_BY", "source_name": "GPT-2", "target_name": "Liu et al.", "title": "GPT-2 PROPOSED_BY Liu et al.\nConfidence: 80%\nEvidence: the observation of Liu et al. (2018) that a model trained to generate Wikipedia articles also learned to translate names between languages", "to": "researcher:liu_et_al", "width": 2.0}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.8, "from": "system:gpt_2", "full_evidence": "current machine learning systems are limited by their reliance on task-specific training", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "task-specific training", "title": "GPT-2 USES_METHOD task-specific training\nConfidence: 80%\nEvidence: current machine learning systems are limited by their reliance on task-specific training", "to": "concept:task_specific_training", "width": 2.0}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "The paper discusses the capabilities of language models, particularly focusing on their ability to perform various natural language processing tasks.", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "natural language processing", "title": "GPT-2 USES_METHOD natural language processing\nConfidence: 100%\nEvidence: The paper discusses the capabilities of language models, particularly focusing on their ability to perform various natural language processing tasks.", "to": "field:natural_language_processing", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "Anothertaskwellsuitedforfew-shotlearningiscorrectingEnglishgrammar.", "relation_type": "SUPPORTS", "source_name": "GPT-2", "target_name": "few-shot learning", "title": "GPT-2 SUPPORTS few-shot learning\nConfidence: 100%\nEvidence: Anothertaskwellsuitedforfew-shotlearningiscorrectingEnglishgrammar.", "to": "method:few_shot_learning", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.9, "from": "system:gpt_2", "full_evidence": "strong performance on many NLP tasks and benchmarks in the zero-shot, one-shot, and few-shot settings", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "few-shot learning", "title": "GPT-2 USES_METHOD few-shot learning\nConfidence: 90%\nEvidence: strong performance on many NLP tasks and benchmarks in the zero-shot, one-shot, and few-shot settings", "to": "method:few_shot_learning", "width": 2.25}, {"arrows": "to", "color": "#78909C", "edge_confidence": 0.9, "from": "system:gpt_2", "full_evidence": "we focus on zero-shot, one-shot and few-shot, with the aim of comparing them", "relation_type": "ASSOCIATED_WITH", "source_name": "GPT-2", "target_name": "few-shot learning", "title": "GPT-2 ASSOCIATED_WITH few-shot learning\nConfidence: 90%\nEvidence: we focus on zero-shot, one-shot and few-shot, with the aim of comparing them", "to": "method:few_shot_learning", "width": 2.25}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "The main subject matter discusses how scaling up language models enhances their few-shot learning capabilities.", "relation_type": "EXPLAINS", "source_name": "GPT-2", "target_name": "few-shot learning", "title": "GPT-2 EXPLAINS few-shot learning\nConfidence: 100%\nEvidence: The main subject matter discusses how scaling up language models enhances their few-shot learning capabilities.", "to": "method:few_shot_learning", "width": 2.5}, {"arrows": "to", "color": "#FFA726", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "The main subject matter discusses how scaling up language models enhances their few-shot learning capabilities", "relation_type": "IMPLEMENTS", "source_name": "GPT-2", "target_name": "few-shot learning", "title": "GPT-2 IMPLEMENTS few-shot learning\nConfidence: 100%\nEvidence: The main subject matter discusses how scaling up language models enhances their few-shot learning capabilities", "to": "method:few_shot_learning", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "the model is conditioned on a natural language instruction and/or a few demonstrations of the task", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "in-context learning", "title": "GPT-2 USES_METHOD in-context learning\nConfidence: 100%\nEvidence: the model is conditioned on a natural language instruction and/or a few demonstrations of the task", "to": "method:in_context_learning", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "The document is a research paper authored by a team from OpenAI, including key contributors such as Tom B. Brown.", "relation_type": "PROPOSED_BY", "source_name": "GPT-2", "target_name": "Tom B. Brown", "title": "GPT-2 PROPOSED_BY Tom B. Brown\nConfidence: 100%\nEvidence: The document is a research paper authored by a team from OpenAI, including key contributors such as Tom B. Brown.", "to": "researcher:tom_b_brown", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "The document is a research paper authored by a team from OpenAI, including key contributors such as Benjamin Mann.", "relation_type": "PROPOSED_BY", "source_name": "GPT-2", "target_name": "Benjamin Mann", "title": "GPT-2 PROPOSED_BY Benjamin Mann\nConfidence: 100%\nEvidence: The document is a research paper authored by a team from OpenAI, including key contributors such as Benjamin Mann.", "to": "researcher:benjamin_mann", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "The document is a research paper authored by a team from OpenAI, including key contributors such as Ilya Sutskever.", "relation_type": "PROPOSED_BY", "source_name": "GPT-2", "target_name": "Ilya Sutskever", "title": "GPT-2 PROPOSED_BY Ilya Sutskever\nConfidence: 100%\nEvidence: The document is a research paper authored by a team from OpenAI, including key contributors such as Ilya Sutskever.", "to": "researcher:ilya_sutskever", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "(b) \u0027one-shot learning\u0027, where we allow only one demonstration", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "one-shot learning", "title": "GPT-2 USES_METHOD one-shot learning\nConfidence: 100%\nEvidence: (b) \u0027one-shot learning\u0027, where we allow only one demonstration", "to": "concept:one_shot_learning", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "system:gpt_2", "full_evidence": "one-shot performance is still quite strong", "relation_type": "SUPPORTS", "source_name": "GPT-2", "target_name": "one-shot learning", "title": "GPT-2 SUPPORTS one-shot learning\nConfidence: 90%\nEvidence: one-shot performance is still quite strong", "to": "concept:one_shot_learning", "width": 2.25}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.9, "from": "system:gpt_2", "full_evidence": "strong performance on many NLP tasks and benchmarks in the zero-shot, one-shot, and few-shot settings", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "zero-shot learning", "title": "GPT-2 USES_METHOD zero-shot learning\nConfidence: 90%\nEvidence: strong performance on many NLP tasks and benchmarks in the zero-shot, one-shot, and few-shot settings", "to": "concept:zero_shot_learning", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "system:gpt_2", "full_evidence": "even zero-shot performance of the full GPT-3 significantly outperforms few-shot learning for all smaller models", "relation_type": "SUPPORTS", "source_name": "GPT-2", "target_name": "zero-shot learning", "title": "GPT-2 SUPPORTS zero-shot learning\nConfidence: 90%\nEvidence: even zero-shot performance of the full GPT-3 significantly outperforms few-shot learning for all smaller models", "to": "concept:zero_shot_learning", "width": 2.25}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "GPT-3 achieves 81.5 F1 on CoQA in the zero-shot setting", "relation_type": "APPLIED_TO", "source_name": "GPT-2", "target_name": "CoQA", "title": "GPT-2 APPLIED_TO CoQA\nConfidence: 100%\nEvidence: GPT-3 achieves 81.5 F1 on CoQA in the zero-shot setting", "to": "system:coqa", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "GPT-3 achieves 64.3% accuracy on TriviaQA in the zero-shot setting", "relation_type": "APPLIED_TO", "source_name": "GPT-2", "target_name": "TriviaQA", "title": "GPT-2 APPLIED_TO TriviaQA\nConfidence: 100%\nEvidence: GPT-3 achieves 64.3% accuracy on TriviaQA in the zero-shot setting", "to": "system:triviaqa", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "This includes natural language inference tasks like the ANLI dataset", "relation_type": "APPLIED_TO", "source_name": "GPT-2", "target_name": "ANLI", "title": "GPT-2 APPLIED_TO ANLI\nConfidence: 100%\nEvidence: This includes natural language inference tasks like the ANLI dataset", "to": "dataset:anli", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "This includes reading comprehension datasets like RACE", "relation_type": "APPLIED_TO", "source_name": "GPT-2", "target_name": "RACE", "title": "GPT-2 APPLIED_TO RACE\nConfidence: 100%\nEvidence: This includes reading comprehension datasets like RACE", "to": "dataset:race", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "This includes reading comprehension datasets like QuAC", "relation_type": "APPLIED_TO", "source_name": "GPT-2", "target_name": "QuAC", "title": "GPT-2 APPLIED_TO QuAC\nConfidence: 100%\nEvidence: This includes reading comprehension datasets like QuAC", "to": "system:quac", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "Our initial analysis flagged \u003e90% of task examples from QuAC, SQuAD2, and DROP as potentially contaminated.", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "QuAC", "title": "GPT-2 INVESTIGATES QuAC\nConfidence: 100%\nEvidence: Our initial analysis flagged \u003e90% of task examples from QuAC, SQuAD2, and DROP as potentially contaminated.", "to": "system:quac", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.9, "from": "system:gpt_2", "full_evidence": "Datasets for language models have rapidly expanded, culminating in the Common Crawl dataset", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "Common Crawl", "title": "GPT-2 USES_METHOD Common Crawl\nConfidence: 90%\nEvidence: Datasets for language models have rapidly expanded, culminating in the Common Crawl dataset", "to": "system:common_crawl", "width": 2.25}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "the dataset and model size are about two orders of magnitude larger than those used for GPT-2, and include a large amount of Common Crawl.", "relation_type": "APPLIED_TO", "source_name": "GPT-2", "target_name": "Common Crawl", "title": "GPT-2 APPLIED_TO Common Crawl\nConfidence: 100%\nEvidence: the dataset and model size are about two orders of magnitude larger than those used for GPT-2, and include a large amount of Common Crawl.", "to": "system:common_crawl", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.8, "from": "system:gpt_2", "full_evidence": "WebText2 19 billion", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "WebText", "title": "GPT-2 USES_METHOD WebText\nConfidence: 80%\nEvidence: WebText2 19 billion", "to": "system:webtext", "width": 2.0}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.8, "from": "system:gpt_2", "full_evidence": "Books1 12 billion", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "Books1", "title": "GPT-2 USES_METHOD Books1\nConfidence: 80%\nEvidence: Books1 12 billion", "to": "system:books1", "width": 2.0}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.8, "from": "system:gpt_2", "full_evidence": "Books2 55 billion", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "Books2", "title": "GPT-2 USES_METHOD Books2\nConfidence: 80%\nEvidence: Books2 55 billion", "to": "system:books2", "width": 2.0}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.8, "from": "system:gpt_2", "full_evidence": "Wikipedia 3 billion", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "Wikipedia", "title": "GPT-2 USES_METHOD Wikipedia\nConfidence: 80%\nEvidence: Wikipedia 3 billion", "to": "system:wikipedia", "width": 2.0}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "We test GPT-3\u2019s performance on both Winograd and Winogrande", "relation_type": "APPLIED_TO", "source_name": "GPT-2", "target_name": "Winograd Schema Challenge", "title": "GPT-2 APPLIED_TO Winograd Schema Challenge\nConfidence: 100%\nEvidence: We test GPT-3\u2019s performance on both Winograd and Winogrande", "to": "phenomenon:winograd_schema_challenge", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "GPT-3 achieves 81.0% accuracy zero-shot, 80.5% accuracy one-shot, and 82.8% accuracy few-shot", "relation_type": "APPLIED_TO", "source_name": "GPT-2", "target_name": "PIQA", "title": "GPT-2 APPLIED_TO PIQA\nConfidence: 100%\nEvidence: GPT-3 achieves 81.0% accuracy zero-shot, 80.5% accuracy one-shot, and 82.8% accuracy few-shot", "to": "system:piqa", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "Our analysis flagged six groups of benchmarks for further investigation: Word Scrambling, Reading Comprehension (QuAC, SQuAD2, DROP), PIQA...", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "PIQA", "title": "GPT-2 INVESTIGATES PIQA\nConfidence: 100%\nEvidence: Our analysis flagged six groups of benchmarks for further investigation: Word Scrambling, Reading Comprehension (QuAC, SQuAD2, DROP), PIQA...", "to": "system:piqa", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "GPT-3 achieves 51.4% accuracy in the zero-shot setting, 53.2% in the one-shot setting, and 51.5% in the few-shot setting", "relation_type": "APPLIED_TO", "source_name": "GPT-2", "target_name": "ARC", "title": "GPT-2 APPLIED_TO ARC\nConfidence: 100%\nEvidence: GPT-3 achieves 51.4% accuracy in the zero-shot setting, 53.2% in the one-shot setting, and 51.5% in the few-shot setting", "to": "system:arc", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "GPT-3 improves significantly from zero to few shot settings", "relation_type": "APPLIED_TO", "source_name": "GPT-2", "target_name": "OpenBookQA", "title": "GPT-2 APPLIED_TO OpenBookQA\nConfidence: 100%\nEvidence: GPT-3 improves significantly from zero to few shot settings", "to": "system:openbookqa", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "we also evaluate GPT-3 on a standardized collection of datasets, the SuperGLUE benchmark", "relation_type": "APPLIED_TO", "source_name": "GPT-2", "target_name": "SuperGLUE", "title": "GPT-2 APPLIED_TO SuperGLUE\nConfidence: 100%\nEvidence: we also evaluate GPT-3 on a standardized collection of datasets, the SuperGLUE benchmark", "to": "system:superglue", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "Our analysis flagged six groups of benchmarks for further investigation: Word Scrambling, Reading Comprehension (QuAC, SQuAD2, DROP)...", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "Word Scrambling", "title": "GPT-2 INVESTIGATES Word Scrambling\nConfidence: 100%\nEvidence: Our analysis flagged six groups of benchmarks for further investigation: Word Scrambling, Reading Comprehension (QuAC, SQuAD2, DROP)...", "to": "phenomenon:word_scrambling", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "Our initial analysis flagged \u003e90% of task examples from QuAC, SQuAD2, and DROP as potentially contaminated.", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "DROP", "title": "GPT-2 INVESTIGATES DROP\nConfidence: 100%\nEvidence: Our initial analysis flagged \u003e90% of task examples from QuAC, SQuAD2, and DROP as potentially contaminated.", "to": "system:drop", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "We found 25% of the examples in the WMT16 German-English test set were marked as potentially contaminated.", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "German-English translation", "title": "GPT-2 INVESTIGATES German-English translation\nConfidence: 100%\nEvidence: We found 25% of the examples in the WMT16 German-English test set were marked as potentially contaminated.", "to": "phenomenon:german_english_translation", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "Our analysis flagged six groups of benchmarks for further investigation: Word Scrambling, Reading Comprehension (QuAC, SQuAD2, DROP), PIQA, Winograd...", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "Winograd", "title": "GPT-2 INVESTIGATES Winograd\nConfidence: 100%\nEvidence: Our analysis flagged six groups of benchmarks for further investigation: Word Scrambling, Reading Comprehension (QuAC, SQuAD2, DROP), PIQA, Winograd.....", "to": "system:winograd", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.9, "from": "system:gpt_2", "full_evidence": "One possible future direction to address this is distillation of large models down to a manageable size for specific tasks.", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "distillation", "title": "GPT-2 USES_METHOD distillation\nConfidence: 90%\nEvidence: One possible future direction to address this is distillation of large models down to a manageable size for specific tasks.", "to": "method:distillation", "width": 2.25}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "We have conducted an analysis of biases in the model in order to better understand GPT-3\u2019s limitations when it comes to fairness, bias, and representation.", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "bias", "title": "GPT-2 INVESTIGATES bias\nConfidence: 100%\nEvidence: We have conducted an analysis of biases in the model in order to better understand GPT-3\u2019s limitations when it comes to fairness, bias, and representa...", "to": "concept:bias", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "In our investigation of gender bias in GPT-3, we focused on associations between gender and occupation.", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "gender bias", "title": "GPT-2 INVESTIGATES gender bias\nConfidence: 100%\nEvidence: In our investigation of gender bias in GPT-3, we focused on associations between gender and occupation.", "to": "concept:gender_bias", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "applied scaling laws to help predict and guide model and data scaling decisions", "relation_type": "SUPPORTS", "source_name": "GPT-2", "target_name": "scaling laws", "title": "GPT-2 SUPPORTS scaling laws\nConfidence: 100%\nEvidence: applied scaling laws to help predict and guide model and data scaling decisions", "to": "concept:scaling_laws", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "To train all versions of GPT-3, we use Adam", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "Adam", "title": "GPT-2 USES_METHOD Adam\nConfidence: 100%\nEvidence: To train all versions of GPT-3, we use Adam", "to": "method:adam", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "The classifier is trained using logistic regression classifier", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "logistic regression", "title": "GPT-2 USES_METHOD logistic regression\nConfidence: 100%\nEvidence: The classifier is trained using logistic regression classifier", "to": "method:logistic_regression", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "All models use weight decay of 0.1 to provide a small amount of regularization", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "weight decay", "title": "GPT-2 USES_METHOD weight decay\nConfidence: 100%\nEvidence: All models use weight decay of 0.1 to provide a small amount of regularization", "to": "method:weight_decay", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "several language modeling benchmarks plus the Children\u2019s Book Test showed almost complete overlap", "relation_type": "SUPPORTS", "source_name": "GPT-2", "target_name": "language modeling benchmarks", "title": "GPT-2 SUPPORTS language modeling benchmarks\nConfidence: 100%\nEvidence: several language modeling benchmarks plus the Children\u2019s Book Test showed almost complete overlap", "to": "concept:language_modeling_benchmarks", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "we train using AdamW (Loshchilov \u0026 Hutter, 2017)...", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "AdamW", "title": "GPT-2 USES_METHOD AdamW\nConfidence: 100%\nEvidence: we train using AdamW (Loshchilov \u0026 Hutter, 2017)...", "to": "method:adamw", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "we conduct experiments using the publicly available GPT-3 API", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "Chain-of-Thought Prompting", "title": "GPT-2 USES_METHOD Chain-of-Thought Prompting\nConfidence: 100%\nEvidence: we conduct experiments using the publicly available GPT-3 API", "to": "method:chain_of_thought_prompting", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "wefine-tuneGPT-2-largeuntilconvergenceonreviewsfromthetrainsplitoftheIMDBdataset.", "relation_type": "APPLIED_TO", "source_name": "GPT-2", "target_name": "IMDB dataset", "title": "GPT-2 APPLIED_TO IMDB dataset\nConfidence: 100%\nEvidence: wefine-tuneGPT-2-largeuntilconvergenceonreviewsfromthetrainsplitoftheIMDBdataset.", "to": "system:imdb_dataset", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "We find that the win rates computed by GPT-4 are impacted by the prompt.", "relation_type": "ASSOCIATED_WITH", "source_name": "GPT-2", "target_name": "human preferences", "title": "GPT-2 ASSOCIATED_WITH human preferences\nConfidence: 100%\nEvidence: We find that the win rates computed by GPT-4 are impacted by the prompt.", "to": "phenomenon:human_preferences", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "The order in which summaries are presented in randomized when evaluating with GPT-4...", "relation_type": "USES_METHOD", "source_name": "GPT-2", "target_name": "Direct Preference Optimization", "title": "GPT-2 USES_METHOD Direct Preference Optimization\nConfidence: 100%\nEvidence: The order in which summaries are presented in randomized when evaluating with GPT-4...", "to": "method:direct_preference_optimization", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.9, "from": "system:gpt_2", "full_evidence": "We observe some memorizing behavior in GPT-2 on longer strings that are repeated many times in the dataset.", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "text memorization", "title": "GPT-2 INVESTIGATES text memorization\nConfidence: 90%\nEvidence: We observe some memorizing behavior in GPT-2 on longer strings that are repeated many times in the dataset.", "to": "phenomenon:text_memorization", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "The paper discusses the capabilities of language models, particularly focusing on their ability to perform various natural language processing tasks in a zero-shot setting without explicit supervision.", "relation_type": "PROPOSED_BY", "source_name": "GPT-2", "target_name": "Language Models are Unsupervised Multitask Learners", "title": "GPT-2 PROPOSED_BY Language Models are Unsupervised Multitask Learners\nConfidence: 100%\nEvidence: The paper discusses the capabilities of language models, particularly focusing on their ability to perform various natural language processing tasks i...", "to": "publication:language_models_are_unsupervised_multitask_learners", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "substantial progress on many challenging NLP tasks such as textual entailment", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "textual entailment", "title": "GPT-2 INVESTIGATES textual entailment\nConfidence: 100%\nEvidence: substantial progress on many challenging NLP tasks such as textual entailment", "to": "phenomenon:textual_entailment", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "we also undertake a systematic study of \u0027data contamination\u0027 \u2013 a growing problem when training high capacity models", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "data contamination", "title": "GPT-2 INVESTIGATES data contamination\nConfidence: 100%\nEvidence: we also undertake a systematic study of \u0027data contamination\u0027 \u2013 a growing problem when training high capacity models", "to": "phenomenon:data_contamination", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.8, "from": "system:gpt_2", "full_evidence": "to test GPT-3\u2019s ability to perform simple arithmetic operations without task-specific training", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "Arithmetic", "title": "GPT-2 INVESTIGATES Arithmetic\nConfidence: 80%\nEvidence: to test GPT-3\u2019s ability to perform simple arithmetic operations without task-specific training", "to": "phenomenon:arithmetic", "width": 2.0}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "To test GPT-3\u2019s ability to learn novel symbolic manipulations from a few examples, we designed a small battery of 5 \u0027character manipulation\u0027 tasks.", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "character manipulation tasks", "title": "GPT-2 INVESTIGATES character manipulation tasks\nConfidence: 100%\nEvidence: To test GPT-3\u2019s ability to learn novel symbolic manipulations from a few examples, we designed a small battery of 5 \u0027character manipulation\u0027 tasks.", "to": "phenomenon:character_manipulation_tasks", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "To test GPT-3 on another task that is somewhat unusual relative to the typical distribution of text, we collected a set of 374 \u0027SAT analogy\u0027 problems.", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "SAT analogy problems", "title": "GPT-2 INVESTIGATES SAT analogy problems\nConfidence: 100%\nEvidence: To test GPT-3 on another task that is somewhat unusual relative to the typical distribution of text, we collected a set of 374 \u0027SAT analogy\u0027 problems.", "to": "phenomenon:sat_analogy_problems", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "Previous work on generative language models qualitatively tested their ability to generate synthetic \u0027news articles\u0027.", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "news article generation", "title": "GPT-2 INVESTIGATES news article generation\nConfidence: 100%\nEvidence: Previous work on generative language models qualitatively tested their ability to generate synthetic \u0027news articles\u0027.", "to": "phenomenon:news_article_generation", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.9, "from": "system:gpt_2", "full_evidence": "We qualitatively test GPT-3\u2019s ability to do the former.", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "learning and using novel words", "title": "GPT-2 INVESTIGATES learning and using novel words\nConfidence: 90%\nEvidence: We qualitatively test GPT-3\u2019s ability to do the former.", "to": "phenomenon:learning_and_using_novel_words", "width": 2.25}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "achieves only 4% on Natural Questions", "relation_type": "APPLIED_TO", "source_name": "GPT-2", "target_name": "Natural Questions", "title": "GPT-2 APPLIED_TO Natural Questions\nConfidence: 100%\nEvidence: achieves only 4% on Natural Questions", "to": "system:natural_questions", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "Our initial analysis flagged \u003e90% of task examples from QuAC, SQuAD2, and DROP as potentially contaminated.", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "SQuAD", "title": "GPT-2 INVESTIGATES SQuAD\nConfidence: 100%\nEvidence: Our initial analysis flagged \u003e90% of task examples from QuAC, SQuAD2, and DROP as potentially contaminated.", "to": "system:squad", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:gpt_2", "full_evidence": "substantial progress on many challenging NLP tasks such as reading comprehension", "relation_type": "INVESTIGATES", "source_name": "GPT-2", "target_name": "reading comprehension", "title": "GPT-2 INVESTIGATES reading comprehension\nConfidence: 100%\nEvidence: substantial progress on many challenging NLP tasks such as reading comprehension", "to": "concept:reading_comprehension", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "concept:multitask_learning", "full_evidence": "Multitask learning (Caruana, 1997) is a promising framework for improving general performance.", "relation_type": "PROPOSED_BY", "source_name": "Multitask Learning", "target_name": "Alec Radford", "title": "Multitask Learning PROPOSED_BY Alec Radford\nConfidence: 90%\nEvidence: Multitask learning (Caruana, 1997) is a promising framework for improving general performance.", "to": "researcher:alec_radford", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "method:rnn", "full_evidence": "improved the RNN based fine-tuning approaches of (Dai \u0026 Le, 2015).", "relation_type": "PROPOSED_BY", "source_name": "RNN", "target_name": "Dai \u0026 Le", "title": "RNN PROPOSED_BY Dai \u0026 Le\nConfidence: 90%\nEvidence: improved the RNN based fine-tuning approaches of (Dai \u0026 Le, 2015).", "to": "researcher:dai_le", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.8, "from": "method:rnn", "full_evidence": "similar to the work of Jozefowicz et al. (2016) which begins to learn to perform tasks directly.", "relation_type": "PROPOSED_BY", "source_name": "RNN", "target_name": "Jozefowicz et al.", "title": "RNN PROPOSED_BY Jozefowicz et al.\nConfidence: 80%\nEvidence: similar to the work of Jozefowicz et al. (2016) which begins to learn to perform tasks directly.", "to": "researcher:jozefowicz_et_al", "width": 2.0}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.8, "from": "finding:zero_shot_performance", "full_evidence": "zero-shot performance establishes a baseline of the potential performance of GPT-2", "relation_type": "SUPPORTS", "source_name": "zero-shot performance", "target_name": "GPT-2", "title": "zero-shot performance SUPPORTS GPT-2\nConfidence: 80%\nEvidence: zero-shot performance establishes a baseline of the potential performance of GPT-2", "to": "system:gpt_2", "width": 2.0}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "concept:pre_training_techniques", "full_evidence": "these findings potentially help explain the widespread success of pre-training techniques for down-stream NLP tasks.", "relation_type": "SUPPORTS", "source_name": "pre-training techniques", "target_name": "zero-shot performance", "title": "pre-training techniques SUPPORTS zero-shot performance\nConfidence: 100%\nEvidence: these findings potentially help explain the widespread success of pre-training techniques for down-stream NLP tasks.", "to": "finding:zero_shot_performance", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.8, "from": "concept:overlap_rates", "full_evidence": "The results of this analysis suggest that GPT-2 repeats text from the training set less often than the baseline rate of held-out articles.", "relation_type": "SUPPORTS", "source_name": "overlap rates", "target_name": "text memorization", "title": "overlap rates SUPPORTS text memorization\nConfidence: 80%\nEvidence: The results of this analysis suggest that GPT-2 repeats text from the training set less often than the baseline rate of held-out articles.", "to": "phenomenon:text_memorization", "width": 2.0}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "publication:language_models_are_unsupervised_multitask_learners", "full_evidence": "The document is a research paper titled \u0027Language Models are Unsupervised Multitask Learners,\u0027 authored by Alec Radford.", "relation_type": "PROPOSED_BY", "source_name": "Language Models are Unsupervised Multitask Learners", "target_name": "Alec Radford", "title": "Language Models are Unsupervised Multitask Learners PROPOSED_BY Alec Radford\nConfidence: 90%\nEvidence: The document is a research paper titled \u0027Language Models are Unsupervised Multitask Learners,\u0027 authored by Alec Radford.", "to": "researcher:alec_radford", "width": 2.25}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 0.8, "from": "concept:general_systems", "full_evidence": "propose a shift towards more general systems", "relation_type": "EXPLAINS", "source_name": "general systems", "target_name": "Language Models", "title": "general systems EXPLAINS Language Models\nConfidence: 80%\nEvidence: propose a shift towards more general systems", "to": "concept:language_models", "width": 2.0}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "concept:general_systems", "full_evidence": "The authors argue that current machine learning systems are limited by their reliance on task-specific training and propose a shift towards more general systems.", "relation_type": "EXTENDS", "source_name": "general systems", "target_name": "task-specific training", "title": "general systems EXTENDS task-specific training\nConfidence: 100%\nEvidence: The authors argue that current machine learning systems are limited by their reliance on task-specific training and propose a shift towards more gener...", "to": "concept:task_specific_training", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 0.7, "from": "concept:general_systems", "full_evidence": "the potential for these models to generalize across tasks using a large dataset called WebText.", "relation_type": "EXPLAINS", "source_name": "general systems", "target_name": "zero-shot setting", "title": "general systems EXPLAINS zero-shot setting\nConfidence: 70%\nEvidence: the potential for these models to generalize across tasks using a large dataset called WebText.", "to": "concept:zero_shot_setting", "width": 1.75}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:meta_learning", "full_evidence": "One potential route towards addressing these issues is meta-learning", "relation_type": "PROPOSED_BY", "source_name": "meta-learning", "target_name": "Tom B. Brown", "title": "meta-learning PROPOSED_BY Tom B. Brown\nConfidence: 100%\nEvidence: One potential route towards addressing these issues is meta-learning", "to": "researcher:tom_b_brown", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:in_context_learning", "full_evidence": "Recent work attempts to do this via what we call \u0027in-context learning\u0027", "relation_type": "PROPOSED_BY", "source_name": "in-context learning", "target_name": "Tom B. Brown", "title": "in-context learning PROPOSED_BY Tom B. Brown\nConfidence: 100%\nEvidence: Recent work attempts to do this via what we call \u0027in-context learning\u0027", "to": "researcher:tom_b_brown", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.8, "from": "method:few_shot_learning", "full_evidence": "One-Shot(1S) is the same as few-shot except that only one demonstration is allowed", "relation_type": "EXTENDS", "source_name": "few-shot learning", "target_name": "one-shot learning", "title": "few-shot learning EXTENDS one-shot learning\nConfidence: 80%\nEvidence: One-Shot(1S) is the same as few-shot except that only one demonstration is allowed", "to": "concept:one_shot_learning", "width": 2.0}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:few_shot_learning", "full_evidence": "LAMBADA is also a demonstration of the flexibility of few-shot learning.", "relation_type": "SUPPORTS", "source_name": "few-shot learning", "target_name": "LAMBADA", "title": "few-shot learning SUPPORTS LAMBADA\nConfidence: 100%\nEvidence: LAMBADA is also a demonstration of the flexibility of few-shot learning.", "to": "system:lambada", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "method:few_shot_learning", "full_evidence": "GPT-3\u0027s few-shot result further improves performance another 3.2% beyond this.", "relation_type": "SUPPORTS", "source_name": "few-shot learning", "target_name": "GPT-2", "title": "few-shot learning SUPPORTS GPT-2\nConfidence: 90%\nEvidence: GPT-3\u0027s few-shot result further improves performance another 3.2% beyond this.", "to": "system:gpt_2", "width": 2.25}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.9, "from": "method:few_shot_learning", "full_evidence": "ambiguity about whether few-shot learning actually learns new tasks \u0027from scratch\u0027", "relation_type": "INVESTIGATES", "source_name": "few-shot learning", "target_name": "GPT-2", "title": "few-shot learning INVESTIGATES GPT-2\nConfidence: 90%\nEvidence: ambiguity about whether few-shot learning actually learns new tasks \u0027from scratch\u0027", "to": "system:gpt_2", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:few_shot_learning", "full_evidence": "Alec Radford originally demonstrated few-shot learning occurs in language models", "relation_type": "PROPOSED_BY", "source_name": "few-shot learning", "target_name": "Alec Radford", "title": "few-shot learning PROPOSED_BY Alec Radford\nConfidence: 100%\nEvidence: Alec Radford originally demonstrated few-shot learning occurs in language models", "to": "researcher:alec_radford", "width": 2.5}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 0.7, "from": "method:few_shot_learning", "full_evidence": "As shown in Table 8, fine-tuning improves the model performance drastically compared to few-shot learning on datasets large and small.", "relation_type": "CONTRADICTS", "source_name": "few-shot learning", "target_name": "fine-tuning", "title": "few-shot learning CONTRADICTS fine-tuning\nConfidence: 70%\nEvidence: As shown in Table 8, fine-tuning improves the model performance drastically compared to few-shot learning on datasets large and small.", "to": "method:fine_tuning", "width": 1.75}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.8, "from": "concept:one_shot_learning", "full_evidence": "Zero-Shot(0S) is the same as one-shot except that no demonstrations are allowed", "relation_type": "EXTENDS", "source_name": "one-shot learning", "target_name": "zero-shot learning", "title": "one-shot learning EXTENDS zero-shot learning\nConfidence: 80%\nEvidence: Zero-Shot(0S) is the same as one-shot except that no demonstrations are allowed", "to": "concept:zero_shot_learning", "width": 2.0}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "concept:one_shot_learning", "full_evidence": "GPT-3 One-Shot 28.3.", "relation_type": "SUPPORTS", "source_name": "one-shot learning", "target_name": "GPT-2", "title": "one-shot learning SUPPORTS GPT-2\nConfidence: 90%\nEvidence: GPT-3 One-Shot 28.3.", "to": "system:gpt_2", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "concept:zero_shot_learning", "full_evidence": "Zero-shot GPT-3, which only receives a natural language description of the task.", "relation_type": "SUPPORTS", "source_name": "zero-shot learning", "target_name": "GPT-2", "title": "zero-shot learning SUPPORTS GPT-2\nConfidence: 90%\nEvidence: Zero-shot GPT-3, which only receives a natural language description of the task.", "to": "system:gpt_2", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.7, "from": "theory:sparse_transformer", "full_evidence": "similar to the Sparse Transformer", "relation_type": "PROPOSED_BY", "source_name": "Sparse Transformer", "target_name": "Scaling Laws For Neural Language Models", "title": "Sparse Transformer PROPOSED_BY Scaling Laws For Neural Language Models\nConfidence: 70%\nEvidence: similar to the Sparse Transformer", "to": "publication:scaling_laws_for_neural_language_models", "width": 1.75}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "publication:scaling_laws_for_neural_language_models", "full_evidence": "The key participants include Jared Kaplan and Sam McCandlish, who led the research.", "relation_type": "PROPOSED_BY", "source_name": "Scaling Laws For Neural Language Models", "target_name": "Jared Kaplan", "title": "Scaling Laws For Neural Language Models PROPOSED_BY Jared Kaplan\nConfidence: 100%\nEvidence: The key participants include Jared Kaplan and Sam McCandlish, who led the research.", "to": "researcher:jared_kaplan", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "publication:scaling_laws_for_neural_language_models", "full_evidence": "The key participants include Jared Kaplan and Sam McCandlish, who led the research.", "relation_type": "PROPOSED_BY", "source_name": "Scaling Laws For Neural Language Models", "target_name": "Sam McCandlish", "title": "Scaling Laws For Neural Language Models PROPOSED_BY Sam McCandlish\nConfidence: 100%\nEvidence: The key participants include Jared Kaplan and Sam McCandlish, who led the research.", "to": "researcher:sam_mccandlish", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "publication:scaling_laws_for_neural_language_models", "full_evidence": "focusing on the Transformer architecture.", "relation_type": "USES_METHOD", "source_name": "Scaling Laws For Neural Language Models", "target_name": "Transformer", "title": "Scaling Laws For Neural Language Models USES_METHOD Transformer\nConfidence: 100%\nEvidence: focusing on the Transformer architecture.", "to": "theory:transformer", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "publication:scaling_laws_for_neural_language_models", "full_evidence": "The document is a research paper titled \u0027Scaling Laws for Neural Language Models,\u0027 authored by Jared Kaplan, Sam McCandlish, and several other contributors.", "relation_type": "PROPOSED_BY", "source_name": "Scaling Laws For Neural Language Models", "target_name": "Tom Henighan", "title": "Scaling Laws For Neural Language Models PROPOSED_BY Tom Henighan\nConfidence: 100%\nEvidence: The document is a research paper titled \u0027Scaling Laws for Neural Language Models,\u0027 authored by Jared Kaplan, Sam McCandlish, and several other contrib...", "to": "researcher:tom_henighan", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "publication:scaling_laws_for_neural_language_models", "full_evidence": "The document is a research paper titled \u0027Scaling Laws for Neural Language Models,\u0027 authored by Jared Kaplan, Sam McCandlish, and several other contributors.", "relation_type": "PROPOSED_BY", "source_name": "Scaling Laws For Neural Language Models", "target_name": "Tom B. Brown", "title": "Scaling Laws For Neural Language Models PROPOSED_BY Tom B. Brown\nConfidence: 100%\nEvidence: The document is a research paper titled \u0027Scaling Laws for Neural Language Models,\u0027 authored by Jared Kaplan, Sam McCandlish, and several other contrib...", "to": "researcher:tom_b_brown", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "publication:scaling_laws_for_neural_language_models", "full_evidence": "The main subject matter focuses on empirical scaling laws that describe how language model performance, specifically in terms of cross-entropy loss, scales with model size, dataset size, and compute resources.", "relation_type": "EXPLAINS", "source_name": "Scaling Laws For Neural Language Models", "target_name": "cross-entropy loss", "title": "Scaling Laws For Neural Language Models EXPLAINS cross-entropy loss\nConfidence: 100%\nEvidence: The main subject matter focuses on empirical scaling laws that describe how language model performance, specifically in terms of cross-entropy loss, s...", "to": "phenomenon:cross_entropy_loss", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 0.9, "from": "concept:power_law", "full_evidence": "It provides some suggestion for the potential benefits from training on larger contexts.", "relation_type": "EXPLAINS", "source_name": "power-law", "target_name": "sample efficiency", "title": "power-law EXPLAINS sample efficiency\nConfidence: 90%\nEvidence: It provides some suggestion for the potential benefits from training on larger contexts.", "to": "concept:sample_efficiency", "width": 2.25}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "concept:power_law", "full_evidence": "The power-law behavior observed continues for an additional two orders of magnitude with only small deviations from the predicted curve.", "relation_type": "EXPLAINS", "source_name": "power-law", "target_name": "cross-entropy loss", "title": "power-law EXPLAINS cross-entropy loss\nConfidence: 100%\nEvidence: The power-law behavior observed continues for an additional two orders of magnitude with only small deviations from the predicted curve.", "to": "phenomenon:cross_entropy_loss", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "method:ppo", "full_evidence": "We apply our default training method for PPO with pretraining mix.", "relation_type": "APPLIED_TO", "source_name": "PPO", "target_name": "InstructGPT", "title": "PPO APPLIED_TO InstructGPT\nConfidence: 100%\nEvidence: We apply our default training method for PPO with pretraining mix.", "to": "system:instructgpt", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 0.8, "from": "method:ppo", "full_evidence": "The KL-constrained reward maximization objective used in typical RLHF algorithms...", "relation_type": "ASSOCIATED_WITH", "source_name": "PPO", "target_name": "KL-constrained reward maximization", "title": "PPO ASSOCIATED_WITH KL-constrained reward maximization\nConfidence: 80%\nEvidence: The KL-constrained reward maximization objective used in typical RLHF algorithms...", "to": "concept:kl_constrained_reward_maximization", "width": 2.0}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "method:ppo", "full_evidence": "we consider PPO using a reward function learned from the preference data...", "relation_type": "USES_METHOD", "source_name": "PPO", "target_name": "reinforcement learning", "title": "PPO USES_METHOD reinforcement learning\nConfidence: 100%\nEvidence: we consider PPO using a reward function learned from the preference data...", "to": "method:reinforcement_learning", "width": 2.5}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "system:drop", "full_evidence": "One instance where this technique seems to fail to give good signal is DROP, a reading comprehension task in which 94% of the examples are dirty", "relation_type": "CONTRADICTS", "source_name": "DROP", "target_name": "clean-only examples", "title": "DROP CONTRADICTS clean-only examples\nConfidence: 100%\nEvidence: One instance where this technique seems to fail to give good signal is DROP, a reading comprehension task in which 94% of the examples are dirty", "to": "concept:clean_only_examples", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:drop", "full_evidence": "The model starts out with better performance than the GPT-3 model on DROP.", "relation_type": "INVESTIGATES", "source_name": "DROP", "target_name": "question answering", "title": "DROP INVESTIGATES question answering\nConfidence: 100%\nEvidence: The model starts out with better performance than the GPT-3 model on DROP.", "to": "phenomenon:question_answering", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.8, "from": "concept:natural_language_inference_nli", "full_evidence": "Natural Language Inference (NLI) concerns the ability to understand the relationship between two sentences", "relation_type": "INVESTIGATES", "source_name": "Natural Language Inference (NLI)", "target_name": "GPT-2", "title": "Natural Language Inference (NLI) INVESTIGATES GPT-2\nConfidence: 80%\nEvidence: Natural Language Inference (NLI) concerns the ability to understand the relationship between two sentences", "to": "system:gpt_2", "width": 2.0}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.8, "from": "system:adversarial_natural_language_inference_anli", "full_evidence": "we also evaluate on the recently introduced Adversarial Natural Language Inference (ANLI) dataset", "relation_type": "INVESTIGATES", "source_name": "Adversarial Natural Language Inference (ANLI)", "target_name": "GPT-2", "title": "Adversarial Natural Language Inference (ANLI) INVESTIGATES GPT-2\nConfidence: 80%\nEvidence: we also evaluate on the recently introduced Adversarial Natural Language Inference (ANLI) dataset", "to": "system:gpt_2", "width": 2.0}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "finding:human_ability_to_detect_model_generated_text", "full_evidence": "Human abilities to detect model generated text appear to decrease as model size increases.", "relation_type": "SUPPORTS", "source_name": "human ability to detect model-generated text", "target_name": "GPT-2", "title": "human ability to detect model-generated text SUPPORTS GPT-2\nConfidence: 100%\nEvidence: Human abilities to detect model generated text appear to decrease as model size increases.", "to": "system:gpt_2", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "concept:human_accuracy", "full_evidence": "Mean human accuracy at detecting that the intentionally bad articles were model generated was \u223c86%.", "relation_type": "SUPPORTS", "source_name": "human accuracy", "target_name": "GPT-2", "title": "human accuracy SUPPORTS GPT-2\nConfidence: 90%\nEvidence: Mean human accuracy at detecting that the intentionally bad articles were model generated was \u223c86%.", "to": "system:gpt_2", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "system:grover", "full_evidence": "Related work on language model detection by Ippolito et al. indicates that automatic discriminators like GROVER may have greater success.", "relation_type": "PROPOSED_BY", "source_name": "GROVER", "target_name": "Ippolito et al.", "title": "GROVER PROPOSED_BY Ippolito et al.\nConfidence: 90%\nEvidence: Related work on language model detection by Ippolito et al. indicates that automatic discriminators like GROVER may have greater success.", "to": "researcher:ippolito_et_al", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "system:gltr", "full_evidence": "Related work on language model detection by Ippolito et al. indicates that automatic discriminators like GLTR may have greater success.", "relation_type": "PROPOSED_BY", "source_name": "GLTR", "target_name": "Ippolito et al.", "title": "GLTR PROPOSED_BY Ippolito et al.\nConfidence: 90%\nEvidence: Related work on language model detection by Ippolito et al. indicates that automatic discriminators like GLTR may have greater success.", "to": "researcher:ippolito_et_al", "width": 2.25}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 0.9, "from": "system:gpt_3_175b", "full_evidence": "Mean human accuracy at detecting the longer articles that were produced by GPT-3 175B was still barely above chance at \u223c52%.", "relation_type": "CONTRADICTS", "source_name": "GPT-3 175B", "target_name": "human accuracy", "title": "GPT-3 175B CONTRADICTS human accuracy\nConfidence: 90%\nEvidence: Mean human accuracy at detecting the longer articles that were produced by GPT-3 175B was still barely above chance at \u223c52%.", "to": "concept:human_accuracy", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.8, "from": "concept:statistical_bias", "full_evidence": "leading us to suspect that the shift is likely statistical bias rather than memorization", "relation_type": "SUPPORTS", "source_name": "statistical bias", "target_name": "PIQA", "title": "statistical bias SUPPORTS PIQA\nConfidence: 80%\nEvidence: leading us to suspect that the shift is likely statistical bias rather than memorization", "to": "system:piqa", "width": 2.0}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 0.8, "from": "phenomenon:text_synthesis", "full_evidence": "notable weaknesses in text synthesis", "relation_type": "CONTRADICTS", "source_name": "text synthesis", "target_name": "GPT-2", "title": "text synthesis CONTRADICTS GPT-2\nConfidence: 80%\nEvidence: notable weaknesses in text synthesis", "to": "system:gpt_2", "width": 2.0}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "method:reinforcement_learning", "full_evidence": "InstructGPT utilizes reinforcement learning from human feedback.", "relation_type": "EXPLAINS", "source_name": "reinforcement learning", "target_name": "human feedback", "title": "reinforcement learning EXPLAINS human feedback\nConfidence: 100%\nEvidence: InstructGPT utilizes reinforcement learning from human feedback.", "to": "concept:human_feedback", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "method:reinforcement_learning", "full_evidence": "InstructGPT that utilizes reinforcement learning from human feedback to enhance its ability to follow instructions.", "relation_type": "APPLIED_TO", "source_name": "reinforcement learning", "target_name": "human feedback", "title": "reinforcement learning APPLIED_TO human feedback\nConfidence: 100%\nEvidence: InstructGPT that utilizes reinforcement learning from human feedback to enhance its ability to follow instructions.", "to": "concept:human_feedback", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:reinforcement_learning", "full_evidence": "authored by a team from OpenAI, including key contributors like Long Ouyang", "relation_type": "PROPOSED_BY", "source_name": "reinforcement learning", "target_name": "Long Ouyang", "title": "reinforcement learning PROPOSED_BY Long Ouyang\nConfidence: 100%\nEvidence: authored by a team from OpenAI, including key contributors like Long Ouyang", "to": "researcher:long_ouyang", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:reinforcement_learning", "full_evidence": "authored by a team from OpenAI, including key contributors like Jeff Wu", "relation_type": "PROPOSED_BY", "source_name": "reinforcement learning", "target_name": "Jeff Wu", "title": "reinforcement learning PROPOSED_BY Jeff Wu\nConfidence: 100%\nEvidence: authored by a team from OpenAI, including key contributors like Jeff Wu", "to": "researcher:jeff_wu", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:reinforcement_learning", "full_evidence": "authored by a team from OpenAI, including key contributors like Paul Christiano", "relation_type": "PROPOSED_BY", "source_name": "reinforcement learning", "target_name": "Paul Christiano", "title": "reinforcement learning PROPOSED_BY Paul Christiano\nConfidence: 100%\nEvidence: authored by a team from OpenAI, including key contributors like Paul Christiano", "to": "researcher:paul_christiano", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "method:reinforcement_learning", "full_evidence": "we show an avenue for aligning language models with user intent on a wider range of tasks by fine-tuning with human feedback", "relation_type": "EXPLAINS", "source_name": "reinforcement learning", "target_name": "InstructGPT", "title": "reinforcement learning EXPLAINS InstructGPT\nConfidence: 100%\nEvidence: we show an avenue for aligning language models with user intent on a wider range of tasks by fine-tuning with human feedback", "to": "system:instructgpt", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "method:reinforcement_learning", "full_evidence": "to align models with human intentions, particularly reinforcement learning from human feedback.", "relation_type": "EXPLAINS", "source_name": "reinforcement learning", "target_name": "alignment", "title": "reinforcement learning EXPLAINS alignment\nConfidence: 100%\nEvidence: to align models with human intentions, particularly reinforcement learning from human feedback.", "to": "concept:alignment", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:reinforcement_learning", "full_evidence": "our results are good news for RLHF as a low-tax alignment technique", "relation_type": "SUPPORTS", "source_name": "reinforcement learning", "target_name": "alignment techniques", "title": "reinforcement learning SUPPORTS alignment techniques\nConfidence: 100%\nEvidence: our results are good news for RLHF as a low-tax alignment technique", "to": "concept:alignment_techniques", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 0.9, "from": "method:reinforcement_learning", "full_evidence": "Getting models to do what we want is directly related to the steerability and controllability literature...", "relation_type": "EXPLAINS", "source_name": "reinforcement learning", "target_name": "steerability and controllability literature", "title": "reinforcement learning EXPLAINS steerability and controllability literature\nConfidence: 90%\nEvidence: Getting models to do what we want is directly related to the steerability and controllability literature...", "to": "concept:steerability_and_controllability_literature", "width": 2.25}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.8, "from": "method:reinforcement_learning", "full_evidence": "A promising future path is combining RLHF with other methods of steerability, for example using control codes...", "relation_type": "EXTENDS", "source_name": "reinforcement learning", "target_name": "control codes", "title": "reinforcement learning EXTENDS control codes\nConfidence: 80%\nEvidence: A promising future path is combining RLHF with other methods of steerability, for example using control codes...", "to": "method:control_codes", "width": 2.0}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.8, "from": "method:reinforcement_learning", "full_evidence": "one could explore expert iteration...", "relation_type": "EXTENDS", "source_name": "reinforcement learning", "target_name": "expert iteration", "title": "reinforcement learning EXTENDS expert iteration\nConfidence: 80%\nEvidence: one could explore expert iteration...", "to": "method:expert_iteration", "width": 2.0}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.8, "from": "method:reinforcement_learning", "full_evidence": "or simpler behavior cloning methods that use a subset of the comparison data.", "relation_type": "EXTENDS", "source_name": "reinforcement learning", "target_name": "behavior cloning", "title": "reinforcement learning EXTENDS behavior cloning\nConfidence: 80%\nEvidence: or simpler behavior cloning methods that use a subset of the comparison data.", "to": "method:behavior_cloning", "width": 2.0}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.8, "from": "method:reinforcement_learning", "full_evidence": "One could also try constrained optimization approaches...", "relation_type": "EXTENDS", "source_name": "reinforcement learning", "target_name": "constrained optimization", "title": "reinforcement learning EXTENDS constrained optimization\nConfidence: 80%\nEvidence: One could also try constrained optimization approaches...", "to": "method:constrained_optimization", "width": 2.0}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "method:reinforcement_learning", "full_evidence": "DPO is simpler, more stable, and effective in aligning language models with human preferences compared to existing RLHF approaches.", "relation_type": "CONTRADICTS", "source_name": "reinforcement learning", "target_name": "Direct Preference Optimization", "title": "reinforcement learning CONTRADICTS Direct Preference Optimization\nConfidence: 100%\nEvidence: DPO is simpler, more stable, and effective in aligning language models with human preferences compared to existing RLHF approaches.", "to": "method:direct_preference_optimization", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.9, "from": "concept:bias", "full_evidence": "We found that the language models learnt some of these biases such as a tendency to associate female pronouns with participant positions more than male pronouns.", "relation_type": "INVESTIGATES", "source_name": "bias", "target_name": "GPT-2", "title": "bias INVESTIGATES GPT-2\nConfidence: 90%\nEvidence: We found that the language models learnt some of these biases such as a tendency to associate female pronouns with participant positions more than mal...", "to": "system:gpt_2", "width": 2.25}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.9, "from": "concept:gender_bias", "full_evidence": "We view the work in this section as subjective signposting - we chose gender, race, and religion as a starting point...", "relation_type": "INVESTIGATES", "source_name": "gender bias", "target_name": "GPT-2", "title": "gender bias INVESTIGATES GPT-2\nConfidence: 90%\nEvidence: We view the work in this section as subjective signposting - we chose gender, race, and religion as a starting point...", "to": "system:gpt_2", "width": 2.25}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.8, "from": "system:winogender_dataset", "full_evidence": "We also carried out pronoun resolution on the Winogender dataset [RNLVD18] using two methods which further corroborated the model\u2019s tendency to associate most occupations with males.", "relation_type": "APPLIED_TO", "source_name": "Winogender dataset", "target_name": "GPT-2", "title": "Winogender dataset APPLIED_TO GPT-2\nConfidence: 80%\nEvidence: We also carried out pronoun resolution on the Winogender dataset [RNLVD18] using two methods which further corroborated the model\u2019s tendency to associ...", "to": "system:gpt_2", "width": 2.0}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.8, "from": "system:sentiwordnet", "full_evidence": "We measured sentiment using SentiWordNet[BES10] for the words which co-occurred disproportionately with each race.", "relation_type": "USES_METHOD", "source_name": "SentiWordNet", "target_name": "GPT-2", "title": "SentiWordNet USES_METHOD GPT-2\nConfidence: 80%\nEvidence: We measured sentiment using SentiWordNet[BES10] for the words which co-occurred disproportionately with each race.", "to": "system:gpt_2", "width": 2.0}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.9, "from": "concept:racial_bias", "full_evidence": "To investigate racial bias in GPT-3, we seeded the model with prompts such as - \u0027The {race} man was very\u0027, \u0027The {race} woman was very\u0027...", "relation_type": "INVESTIGATES", "source_name": "racial bias", "target_name": "GPT-2", "title": "racial bias INVESTIGATES GPT-2\nConfidence: 90%\nEvidence: To investigate racial bias in GPT-3, we seeded the model with prompts such as - \u0027The {race} man was very\u0027, \u0027The {race} woman was very\u0027...", "to": "system:gpt_2", "width": 2.25}, {"arrows": "to", "color": "#78909C", "edge_confidence": 0.8, "from": "concept:bias_mitigation", "full_evidence": "to develop informative labels such as Model Cards for Model Reporting", "relation_type": "ASSOCIATED_WITH", "source_name": "bias mitigation", "target_name": "Model Cards for Model Reporting", "title": "bias mitigation ASSOCIATED_WITH Model Cards for Model Reporting\nConfidence: 80%\nEvidence: to develop informative labels such as Model Cards for Model Reporting", "to": "concept:model_cards_for_model_reporting", "width": 2.0}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.8, "from": "concept:scaling_laws", "full_evidence": "revealing predictable power-law relationships and implications for optimal training strategies.", "relation_type": "SUPPORTS", "source_name": "scaling laws", "target_name": "optimal training strategies", "title": "scaling laws SUPPORTS optimal training strategies\nConfidence: 80%\nEvidence: revealing predictable power-law relationships and implications for optimal training strategies.", "to": "concept:optimal_training_strategies", "width": 2.0}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "concept:scaling_laws", "full_evidence": "The document is a research paper titled \u0027Scaling Laws for Neural Language Models,\u0027 authored by Jared Kaplan...", "relation_type": "PROPOSED_BY", "source_name": "scaling laws", "target_name": "Jared Kaplan", "title": "scaling laws PROPOSED_BY Jared Kaplan\nConfidence: 90%\nEvidence: The document is a research paper titled \u0027Scaling Laws for Neural Language Models,\u0027 authored by Jared Kaplan...", "to": "researcher:jared_kaplan", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "concept:scaling_laws", "full_evidence": "The document is a research paper titled \u0027Scaling Laws for Neural Language Models,\u0027 authored by Sam McCandlish...", "relation_type": "PROPOSED_BY", "source_name": "scaling laws", "target_name": "Sam McCandlish", "title": "scaling laws PROPOSED_BY Sam McCandlish\nConfidence: 90%\nEvidence: The document is a research paper titled \u0027Scaling Laws for Neural Language Models,\u0027 authored by Sam McCandlish...", "to": "researcher:sam_mccandlish", "width": 2.25}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "method:adam", "full_evidence": "We used the Adam optimizer with \u03b2 =0.9, \u03b2 =0.98 and \u03f5=10\u22129", "relation_type": "ASSOCIATED_WITH", "source_name": "Adam", "target_name": "Transformer", "title": "Adam ASSOCIATED_WITH Transformer\nConfidence: 100%\nEvidence: We used the Adam optimizer with \u03b2 =0.9, \u03b2 =0.98 and \u03f5=10\u22129", "to": "theory:transformer", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "method:two_sample_t_test", "full_evidence": "This was implemented in Python using the scipy.stats.ttest_ind function.", "relation_type": "USES_METHOD", "source_name": "two-sample t-test", "target_name": "Python", "title": "two-sample t-test USES_METHOD Python\nConfidence: 100%\nEvidence: This was implemented in Python using the scipy.stats.ttest_ind function.", "to": "method:python", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.9, "from": "method:two_sample_t_test", "full_evidence": "We use a two-sample Student\u2019s T-Test to test for significant difference between the means of the participant accuracies.", "relation_type": "USES_METHOD", "source_name": "two-sample t-test", "target_name": "control model", "title": "two-sample t-test USES_METHOD control model\nConfidence: 90%\nEvidence: We use a two-sample Student\u2019s T-Test to test for significant difference between the means of the participant accuracies.", "to": "system:control_model", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "finding:average_participant_accuracy", "full_evidence": "Lower accuracy scores despite increased time investment from participants supports the finding that larger models generate harder-to-distinguish news articles.", "relation_type": "SUPPORTS", "source_name": "average participant accuracy", "target_name": "human detection", "title": "average participant accuracy SUPPORTS human detection\nConfidence: 100%\nEvidence: Lower accuracy scores despite increased time investment from participants supports the finding that larger models generate harder-to-distinguish news ...", "to": "phenomenon:human_detection", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 0.9, "from": "method:scaling_up_language_models", "full_evidence": "The main subject matter discusses how scaling up language models enhances their few-shot learning capabilities.", "relation_type": "EXPLAINS", "source_name": "scaling up language models", "target_name": "few-shot learning", "title": "scaling up language models EXPLAINS few-shot learning\nConfidence: 90%\nEvidence: The main subject matter discusses how scaling up language models enhances their few-shot learning capabilities.", "to": "method:few_shot_learning", "width": 2.25}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "concept:power_law_relationships", "full_evidence": "The power laws specify the degree of performance improvement expected as we scale up.", "relation_type": "EXPLAINS", "source_name": "power-law relationships", "target_name": "cross-entropy loss", "title": "power-law relationships EXPLAINS cross-entropy loss\nConfidence: 100%\nEvidence: The power laws specify the degree of performance improvement expected as we scale up.", "to": "phenomenon:cross_entropy_loss", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "concept:power_law_relationships", "full_evidence": "the amount of data used by compute-efficient training grows slowly with the compute budget.", "relation_type": "SUPPORTS", "source_name": "power-law relationships", "target_name": "compute-efficient training", "title": "power-law relationships SUPPORTS compute-efficient training\nConfidence: 100%\nEvidence: the amount of data used by compute-efficient training grows slowly with the compute budget.", "to": "method:compute_efficient_training", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:webtext2", "full_evidence": "Due to memory constraints, our largest models (more than 1B parameters) were trained with Adafactor.", "relation_type": "USES_METHOD", "source_name": "WebText2", "target_name": "Adafactor", "title": "WebText2 USES_METHOD Adafactor\nConfidence: 100%\nEvidence: Due to memory constraints, our largest models (more than 1B parameters) were trained with Adafactor.", "to": "method:adafactor", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:webtext2", "full_evidence": "We see no sign of overfitting when training with the full 22B token WebText2 dataset.", "relation_type": "APPLIED_TO", "source_name": "WebText2", "target_name": "overfitting", "title": "WebText2 APPLIED_TO overfitting\nConfidence: 100%\nEvidence: We see no sign of overfitting when training with the full 22B token WebText2 dataset.", "to": "phenomenon:overfitting", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:webtext2", "full_evidence": "Unless otherwise noted, we train models with the Adam optimizer.", "relation_type": "USES_METHOD", "source_name": "WebText2", "target_name": "Adam", "title": "WebText2 USES_METHOD Adam\nConfidence: 100%\nEvidence: Unless otherwise noted, we train models with the Adam optimizer.", "to": "method:adam", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:universal_transformers", "full_evidence": "We also train LSTM models and Universal Transformers for comparison.", "relation_type": "APPLIED_TO", "source_name": "Universal Transformers", "target_name": "WebText2", "title": "Universal Transformers APPLIED_TO WebText2\nConfidence: 100%\nEvidence: We also train LSTM models and Universal Transformers for comparison.", "to": "system:webtext2", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "concept:learning_curves", "full_evidence": "the learning curves can be accurately fit by.", "relation_type": "EXPLAINS", "source_name": "learning curves", "target_name": "cross-entropy loss", "title": "learning curves EXPLAINS cross-entropy loss\nConfidence: 100%\nEvidence: the learning curves can be accurately fit by.", "to": "phenomenon:cross_entropy_loss", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "theory:lstm", "full_evidence": "Tom Henighan contributed the LSTM experiments.", "relation_type": "APPLIED_TO", "source_name": "LSTM", "target_name": "Scaling Laws For Neural Language Models", "title": "LSTM APPLIED_TO Scaling Laws For Neural Language Models\nConfidence: 100%\nEvidence: Tom Henighan contributed the LSTM experiments.", "to": "publication:scaling_laws_for_neural_language_models", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "theory:lstm", "full_evidence": "We also train LSTM models and Universal Transformers for comparison.", "relation_type": "APPLIED_TO", "source_name": "LSTM", "target_name": "WebText2", "title": "LSTM APPLIED_TO WebText2\nConfidence: 100%\nEvidence: We also train LSTM models and Universal Transformers for comparison.", "to": "system:webtext2", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "method:equation_1_5", "full_evidence": "The early-stopped test loss L(N,D) depends predictably on the dataset size D and model size N according to Equation (1.5).", "relation_type": "EXPLAINS", "source_name": "Equation (1.5)", "target_name": "cross-entropy loss", "title": "Equation (1.5) EXPLAINS cross-entropy loss\nConfidence: 100%\nEvidence: The early-stopped test loss L(N,D) depends predictably on the dataset size D and model size N according to Equation (1.5).", "to": "phenomenon:cross_entropy_loss", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "method:equation_1_5", "full_evidence": "We will see that our equation for L(N,D) fits the data well, which is the most important justification for our L(N,D) ansatz.", "relation_type": "USES_METHOD", "source_name": "Equation (1.5)", "target_name": "L(N,D)", "title": "Equation (1.5) USES_METHOD L(N,D)\nConfidence: 100%\nEvidence: We will see that our equation for L(N,D) fits the data well, which is the most important justification for our L(N,D) ansatz.", "to": "concept:l_n_d", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:equation_4_3", "full_evidence": "The extent of overfitting depends predominantly on the ratio N\u03b1D/D, as predicted in equation (4.3).", "relation_type": "SUPPORTS", "source_name": "Equation (4.3)", "target_name": "overfitting", "title": "Equation (4.3) SUPPORTS overfitting\nConfidence: 100%\nEvidence: The extent of overfitting depends predominantly on the ratio N\u03b1D/D, as predicted in equation (4.3).", "to": "phenomenon:overfitting", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 0.8, "from": "concept:critical_batch_size", "full_evidence": "We measure the critical batch size using the data displayed in figure 18.", "relation_type": "ASSOCIATED_WITH", "source_name": "critical batch size", "target_name": "compute-efficient training", "title": "critical batch size ASSOCIATED_WITH compute-efficient training\nConfidence: 80%\nEvidence: We measure the critical batch size using the data displayed in figure 18.", "to": "method:compute_efficient_training", "width": 2.0}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "theory:l_n_s", "full_evidence": "When we hold either total compute or number of training steps fixed, performance follows L(N,S) from Equation (5.6).", "relation_type": "EXPLAINS", "source_name": "L(N,S)", "target_name": "cross-entropy loss", "title": "L(N,S) EXPLAINS cross-entropy loss\nConfidence: 100%\nEvidence: When we hold either total compute or number of training steps fixed, performance follows L(N,S) from Equation (5.6).", "to": "phenomenon:cross_entropy_loss", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "finding:lower_bound_on_early_stopping_step", "full_evidence": "The results for L(N,S) can be used to derive a lower-bound (and rough estimate) of the step at which early stopping should occur when training is data limited.", "relation_type": "SUPPORTS", "source_name": "lower-bound on early stopping step", "target_name": "L(N,S)", "title": "lower-bound on early stopping step SUPPORTS L(N,S)\nConfidence: 100%\nEvidence: The results for L(N,S) can be used to derive a lower-bound (and rough estimate) of the step at which early stopping should occur when training is data...", "to": "theory:l_n_s", "width": 2.5}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "concept:l_d_c", "full_evidence": "this will eventually intersect with our prediction for L(C) from Figure 13.", "relation_type": "CONTRADICTS", "source_name": "L(D(C))", "target_name": "L(C)", "title": "L(D(C)) CONTRADICTS L(C)\nConfidence: 100%\nEvidence: this will eventually intersect with our prediction for L(C) from Figure 13.", "to": "concept:l_c", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "concept:power_law_scaling", "full_evidence": "we have extracted all of the reliable information available in natural language data.", "relation_type": "APPLIED_TO", "source_name": "power-law scaling", "target_name": "natural language data", "title": "power-law scaling APPLIED_TO natural language data\nConfidence: 100%\nEvidence: we have extracted all of the reliable information available in natural language data.", "to": "concept:natural_language_data", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.8, "from": "method:compute_efficient_training", "full_evidence": "The power-law fit to the learning curve implies a simple prescription for compute-efficient training.", "relation_type": "USES_METHOD", "source_name": "compute-efficient training", "target_name": "power-law", "title": "compute-efficient training USES_METHOD power-law\nConfidence: 80%\nEvidence: The power-law fit to the learning curve implies a simple prescription for compute-efficient training.", "to": "concept:power_law", "width": 2.0}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 0.8, "from": "theory:empirical_scaling_laws", "full_evidence": "The main subject matter focuses on empirical scaling laws that describe how language model performance, specifically in terms of cross-entropy loss, scales with model size, dataset size, and compute resources.", "relation_type": "EXPLAINS", "source_name": "empirical scaling laws", "target_name": "cross-entropy loss", "title": "empirical scaling laws EXPLAINS cross-entropy loss\nConfidence: 80%\nEvidence: The main subject matter focuses on empirical scaling laws that describe how language model performance, specifically in terms of cross-entropy loss, s...", "to": "phenomenon:cross_entropy_loss", "width": 2.0}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.8, "from": "system:recurrent_transformers", "full_evidence": "Recurrent Transformers perform slightly better when comparing models with equal parameter count.", "relation_type": "SUPPORTS", "source_name": "recurrent Transformers", "target_name": "Transformer", "title": "recurrent Transformers SUPPORTS Transformer\nConfidence: 80%\nEvidence: Recurrent Transformers perform slightly better when comparing models with equal parameter count.", "to": "theory:transformer", "width": 2.0}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.8, "from": "concept:sample_efficiency", "full_evidence": "We measure the critical batch size using the data displayed in figure 18.", "relation_type": "INVESTIGATES", "source_name": "sample efficiency", "target_name": "batch size", "title": "sample efficiency INVESTIGATES batch size\nConfidence: 80%\nEvidence: We measure the critical batch size using the data displayed in figure 18.", "to": "concept:batch_size", "width": 2.0}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:vision_transformer", "full_evidence": "authored by a team from Google Research\u0027s Brain Team, including key contributors Alexey Dosovitskiy", "relation_type": "PROPOSED_BY", "source_name": "Vision Transformer", "target_name": "Alexey Dosovitskiy", "title": "Vision Transformer PROPOSED_BY Alexey Dosovitskiy\nConfidence: 100%\nEvidence: authored by a team from Google Research\u0027s Brain Team, including key contributors Alexey Dosovitskiy", "to": "researcher:alexey_dosovitskiy", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:vision_transformer", "full_evidence": "authored by a team from Google Research\u0027s Brain Team, including key contributors Lucas Beyer", "relation_type": "PROPOSED_BY", "source_name": "Vision Transformer", "target_name": "Lucas Beyer", "title": "Vision Transformer PROPOSED_BY Lucas Beyer\nConfidence: 100%\nEvidence: authored by a team from Google Research\u0027s Brain Team, including key contributors Lucas Beyer", "to": "researcher:lucas_beyer", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:vision_transformer", "full_evidence": "authored by a team from Google Research\u0027s Brain Team, including key contributors Neil Houlsby", "relation_type": "PROPOSED_BY", "source_name": "Vision Transformer", "target_name": "Neil Houlsby", "title": "Vision Transformer PROPOSED_BY Neil Houlsby\nConfidence: 100%\nEvidence: authored by a team from Google Research\u0027s Brain Team, including key contributors Neil Houlsby", "to": "researcher:neil_houlsby", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:vision_transformer", "full_evidence": "ViT pre-trained on the smaller public ImageNet-21k dataset performs well too.", "relation_type": "SUPPORTS", "source_name": "Vision Transformer", "target_name": "ImageNet", "title": "Vision Transformer SUPPORTS ImageNet\nConfidence: 100%\nEvidence: ViT pre-trained on the smaller public ImageNet-21k dataset performs well too.", "to": "system:imagenet", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:vision_transformer", "full_evidence": "CIFAR-100 94.55\u00b10.04 93.90\u00b10.05 93.25\u00b10.05 93.51\u00b10.08 \u2212", "relation_type": "SUPPORTS", "source_name": "Vision Transformer", "target_name": "CIFAR-100", "title": "Vision Transformer SUPPORTS CIFAR-100\nConfidence: 100%\nEvidence: CIFAR-100 94.55\u00b10.04 93.90\u00b10.05 93.25\u00b10.05 93.51\u00b10.08 \u2212", "to": "system:cifar_100", "width": 2.5}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "system:vision_transformer", "full_evidence": "We show that this reliance on CNNs is not necessary.", "relation_type": "CONTRADICTS", "source_name": "Vision Transformer", "target_name": "CNN", "title": "Vision Transformer CONTRADICTS CNN\nConfidence: 100%\nEvidence: We show that this reliance on CNNs is not necessary.", "to": "concept:cnn", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:vision_transformer", "full_evidence": "The Vision Transformer performs well when pre-trained on a large JFT-300M dataset.", "relation_type": "SUPPORTS", "source_name": "Vision Transformer", "target_name": "JFT-300M", "title": "Vision Transformer SUPPORTS JFT-300M\nConfidence: 100%\nEvidence: The Vision Transformer performs well when pre-trained on a large JFT-300M dataset.", "to": "system:jft_300m", "width": 2.5}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "system:vision_transformer", "full_evidence": "Vision Transformers generally outperform ResNets with the same computational budget.", "relation_type": "CONTRADICTS", "source_name": "Vision Transformer", "target_name": "ResNet", "title": "Vision Transformer CONTRADICTS ResNet\nConfidence: 100%\nEvidence: Vision Transformers generally outperform ResNets with the same computational budget.", "to": "theory:resnet", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:vision_transformer", "full_evidence": "ViT-H/14 outperforms BiT-R152x4, and other methods, on the Natural and Structured tasks.", "relation_type": "SUPPORTS", "source_name": "Vision Transformer", "target_name": "BiT", "title": "Vision Transformer SUPPORTS BiT\nConfidence: 100%\nEvidence: ViT-H/14 outperforms BiT-R152x4, and other methods, on the Natural and Structured tasks.", "to": "system:bit", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:vision_transformer", "full_evidence": "CIFAR-10 99.50\u00b10.06 99.42\u00b10.03 99.15\u00b10.03 99.37\u00b10.06 \u2212", "relation_type": "SUPPORTS", "source_name": "Vision Transformer", "target_name": "CIFAR-10", "title": "Vision Transformer SUPPORTS CIFAR-10\nConfidence: 100%\nEvidence: CIFAR-10 99.50\u00b10.06 99.42\u00b10.03 99.15\u00b10.03 99.37\u00b10.06 \u2212", "to": "system:cifar_10", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:vision_transformer", "full_evidence": "Oxford-IIIT Pets 97.56\u00b10.03 97.32\u00b10.11 94.67\u00b10.15 96.62\u00b10.23 \u2212", "relation_type": "SUPPORTS", "source_name": "Vision Transformer", "target_name": "Oxford-IIIT Pets", "title": "Vision Transformer SUPPORTS Oxford-IIIT Pets\nConfidence: 100%\nEvidence: Oxford-IIIT Pets 97.56\u00b10.03 97.32\u00b10.11 94.67\u00b10.15 96.62\u00b10.23 \u2212", "to": "system:oxford_iiit_pets", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:vision_transformer", "full_evidence": "Oxford Flowers-102 99.68\u00b10.02 99.74\u00b10.00 99.61\u00b10.02 99.63\u00b10.03 \u2212", "relation_type": "SUPPORTS", "source_name": "Vision Transformer", "target_name": "Oxford Flowers-102", "title": "Vision Transformer SUPPORTS Oxford Flowers-102\nConfidence: 100%\nEvidence: Oxford Flowers-102 99.68\u00b10.02 99.74\u00b10.00 99.61\u00b10.02 99.63\u00b10.03 \u2212", "to": "system:oxford_flowers_102", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:vision_transformer", "full_evidence": "VTAB (19 tasks) 77.63\u00b10.23 76.28\u00b10.46 72.72\u00b10.21 76.29\u00b11.70 \u2212", "relation_type": "SUPPORTS", "source_name": "Vision Transformer", "target_name": "VTAB", "title": "Vision Transformer SUPPORTS VTAB\nConfidence: 100%\nEvidence: VTAB (19 tasks) 77.63\u00b10.23 76.28\u00b10.46 72.72\u00b10.21 76.29\u00b11.70 \u2212", "to": "system:vtab", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:vision_transformer", "full_evidence": "Thus, Vision Transformer matches or exceeds the state of the art on many image classification datasets, whilst being relatively cheap to pre-train.", "relation_type": "USES_METHOD", "source_name": "Vision Transformer", "target_name": "self-supervised pre-training", "title": "Vision Transformer USES_METHOD self-supervised pre-training\nConfidence: 100%\nEvidence: Thus, Vision Transformer matches or exceeds the state of the art on many image classification datasets, whilst being relatively cheap to pre-train.", "to": "method:self_supervised_pre_training", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:vision_transformer", "full_evidence": "We employ the masked patch prediction objective for preliminary self-supervision experiments.", "relation_type": "USES_METHOD", "source_name": "Vision Transformer", "target_name": "self-supervised learning", "title": "Vision Transformer USES_METHOD self-supervised learning\nConfidence: 100%\nEvidence: We employ the masked patch prediction objective for preliminary self-supervision experiments.", "to": "method:self_supervised_learning", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:vision_transformer", "full_evidence": "We employ the masked patch prediction objective for preliminary self-supervision experiments.", "relation_type": "USES_METHOD", "source_name": "Vision Transformer", "target_name": "masked patch prediction", "title": "Vision Transformer USES_METHOD masked patch prediction\nConfidence: 100%\nEvidence: We employ the masked patch prediction objective for preliminary self-supervision experiments.", "to": "method:masked_patch_prediction", "width": 2.5}, {"arrows": "to", "color": "#FFA726", "edge_confidence": 0.9, "from": "system:vision_transformer", "full_evidence": "the application of the Transformer architecture, traditionally used in natural language processing, to image recognition tasks", "relation_type": "IMPLEMENTS", "source_name": "Vision Transformer", "target_name": "Transformer", "title": "Vision Transformer IMPLEMENTS Transformer\nConfidence: 90%\nEvidence: the application of the Transformer architecture, traditionally used in natural language processing, to image recognition tasks", "to": "theory:transformer", "width": 2.25}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:vision_transformer", "full_evidence": "we have modified ViT to process inputs in the 2-dimensional shape, instead of a 1-dimensional sequence of patches, and incorporate Axial Transformer blocks", "relation_type": "USES_METHOD", "source_name": "Vision Transformer", "target_name": "Axial Attention", "title": "Vision Transformer USES_METHOD Axial Attention\nConfidence: 100%\nEvidence: we have modified ViT to process inputs in the 2-dimensional shape, instead of a 1-dimensional sequence of patches, and incorporate Axial Transformer b...", "to": "method:axial_attention", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:self_supervised_pre_training", "full_evidence": "our smaller ViT-B/16 model achieves 79.9% accuracy on ImageNet, a significant improvement of 2% to training from scratch.", "relation_type": "SUPPORTS", "source_name": "self-supervised pre-training", "target_name": "ImageNet", "title": "self-supervised pre-training SUPPORTS ImageNet\nConfidence: 100%\nEvidence: our smaller ViT-B/16 model achieves 79.9% accuracy on ImageNet, a significant improvement of 2% to training from scratch.", "to": "system:imagenet", "width": 2.5}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "method:self_supervised_pre_training", "full_evidence": "there is still large gap between self-supervised and large-scale supervised pre-training.", "relation_type": "CONTRADICTS", "source_name": "self-supervised pre-training", "target_name": "large-scale supervised pre-training", "title": "self-supervised pre-training CONTRADICTS large-scale supervised pre-training\nConfidence: 100%\nEvidence: there is still large gap between self-supervised and large-scale supervised pre-training.", "to": "method:large_scale_supervised_pre_training", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.9, "from": "theory:resnet", "full_evidence": "ResNets are typically trained with SGD", "relation_type": "USES_METHOD", "source_name": "ResNet", "target_name": "SGD", "title": "ResNet USES_METHOD SGD\nConfidence: 90%\nEvidence: ResNets are typically trained with SGD", "to": "method:sgd", "width": 2.25}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.9, "from": "theory:resnet", "full_evidence": "our use of Adam as optimizer is quite unconventional", "relation_type": "USES_METHOD", "source_name": "ResNet", "target_name": "Adam", "title": "ResNet USES_METHOD Adam\nConfidence: 90%\nEvidence: our use of Adam as optimizer is quite unconventional", "to": "method:adam", "width": 2.25}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:vit_l_16", "full_evidence": "when pretrained on JFT dataset", "relation_type": "APPLIED_TO", "source_name": "ViT-L/16", "target_name": "JFT dataset", "title": "ViT-L/16 APPLIED_TO JFT dataset\nConfidence: 100%\nEvidence: when pretrained on JFT dataset", "to": "system:jft_dataset", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:vit_l_16", "full_evidence": "Table 9 shows the scores attained on each of the VTAB-1k tasks.", "relation_type": "APPLIED_TO", "source_name": "ViT-L/16", "target_name": "VTAB-1k", "title": "ViT-L/16 APPLIED_TO VTAB-1k\nConfidence: 100%\nEvidence: Table 9 shows the scores attained on each of the VTAB-1k tasks.", "to": "system:vtab_1k", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:axial_resnet", "full_evidence": "performance of Axial-ViT-B/32 and Axial-ViT-B/16 on ImageNet 5-shot linear", "relation_type": "APPLIED_TO", "source_name": "Axial ResNet", "target_name": "ImageNet", "title": "Axial ResNet APPLIED_TO ImageNet\nConfidence: 100%\nEvidence: performance of Axial-ViT-B/32 and Axial-ViT-B/16 on ImageNet 5-shot linear", "to": "system:imagenet", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "method:low_rank_adaptation", "full_evidence": "The document is a research paper from Microsoft Corporation, authored by Edward Hu.", "relation_type": "PROPOSED_BY", "source_name": "Low-Rank Adaptation", "target_name": "Edward Hu", "title": "Low-Rank Adaptation PROPOSED_BY Edward Hu\nConfidence: 90%\nEvidence: The document is a research paper from Microsoft Corporation, authored by Edward Hu.", "to": "researcher:edward_hu", "width": 2.25}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "We focus on language modeling as our motivating use case.", "relation_type": "EXPLAINS", "source_name": "Low-Rank Adaptation", "target_name": "conditional language modeling", "title": "Low-Rank Adaptation EXPLAINS conditional language modeling\nConfidence: 100%\nEvidence: We focus on language modeling as our motivating use case.", "to": "phenomenon:conditional_language_modeling", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA.", "relation_type": "SUPPORTS", "source_name": "Low-Rank Adaptation", "target_name": "rank-deficiency in language model adaptation", "title": "Low-Rank Adaptation SUPPORTS rank-deficiency in language model adaptation\nConfidence: 100%\nEvidence: We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA.", "to": "finding:rank_deficiency_in_language_model_adaptation", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "When optimizing with Adam, tuning \u03b1 is roughly the same as tuning the learning rate.", "relation_type": "USES_METHOD", "source_name": "Low-Rank Adaptation", "target_name": "Adam", "title": "Low-Rank Adaptation USES_METHOD Adam\nConfidence: 100%\nEvidence: When optimizing with Adam, tuning \u03b1 is roughly the same as tuning the learning rate.", "to": "method:adam", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "We release a package that facilitates the integration of LoRA with PyTorch models.", "relation_type": "ASSOCIATED_WITH", "source_name": "Low-Rank Adaptation", "target_name": "PyTorch", "title": "Low-Rank Adaptation ASSOCIATED_WITH PyTorch\nConfidence: 100%\nEvidence: We release a package that facilitates the integration of LoRA with PyTorch models.", "to": "system:pytorch", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "Since the inception of transfer learning, dozens of works have sought to make model adaptation more parameter-and compute-efficient.", "relation_type": "EXTENDS", "source_name": "Low-Rank Adaptation", "target_name": "transfer learning", "title": "Low-Rank Adaptation EXTENDS transfer learning\nConfidence: 100%\nEvidence: Since the inception of transfer learning, dozens of works have sought to make model adaptation more parameter-and compute-efficient.", "to": "concept:transfer_learning", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "LoRA can be a competitive alternative to full fine-tuning on NLU", "relation_type": "EXPLAINS", "source_name": "Low-Rank Adaptation", "target_name": "GPT-2", "title": "Low-Rank Adaptation EXPLAINS GPT-2\nConfidence: 100%\nEvidence: LoRA can be a competitive alternative to full fine-tuning on NLU", "to": "system:gpt_2", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "We repeat our experiment on the effect of r in GPT-2.", "relation_type": "APPLIED_TO", "source_name": "Low-Rank Adaptation", "target_name": "GPT-2", "title": "Low-Rank Adaptation APPLIED_TO GPT-2\nConfidence: 100%\nEvidence: We repeat our experiment on the effect of r in GPT-2.", "to": "system:gpt_2", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 0.9, "from": "method:low_rank_adaptation", "full_evidence": "Low-Rank Adaptation (LoRA) for efficiently adapting large pre-trained language models like GPT-3 to specific tasks.", "relation_type": "ASSOCIATED_WITH", "source_name": "Low-Rank Adaptation", "target_name": "GPT-2", "title": "Low-Rank Adaptation ASSOCIATED_WITH GPT-2\nConfidence: 90%\nEvidence: Low-Rank Adaptation (LoRA) for efficiently adapting large pre-trained language models like GPT-3 to specific tasks.", "to": "system:gpt_2", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "method:low_rank_adaptation", "full_evidence": "LoRA as a solution that significantly reduces the number of trainable parameters while maintaining or improving model performance.", "relation_type": "SUPPORTS", "source_name": "Low-Rank Adaptation", "target_name": "GPT-2", "title": "Low-Rank Adaptation SUPPORTS GPT-2\nConfidence: 90%\nEvidence: LoRA as a solution that significantly reduces the number of trainable parameters while maintaining or improving model performance.", "to": "system:gpt_2", "width": 2.25}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "evaluate the downstream task performance of LoRA on RoBERTa (Liu et al., 2019).", "relation_type": "APPLIED_TO", "source_name": "Low-Rank Adaptation", "target_name": "RoBERTa", "title": "Low-Rank Adaptation APPLIED_TO RoBERTa\nConfidence: 100%\nEvidence: evaluate the downstream task performance of LoRA on RoBERTa (Liu et al., 2019).", "to": "system:roberta", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "evaluate the performance of different efficient adaptation approaches on tasks from the GLUE benchmark", "relation_type": "EXPLAINS", "source_name": "Low-Rank Adaptation", "target_name": "RoBERTa", "title": "Low-Rank Adaptation EXPLAINS RoBERTa\nConfidence: 100%\nEvidence: evaluate the performance of different efficient adaptation approaches on tasks from the GLUE benchmark", "to": "system:roberta", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "evaluate the downstream task performance of LoRA on DeBERTa (He et al., 2021).", "relation_type": "APPLIED_TO", "source_name": "Low-Rank Adaptation", "target_name": "DeBERTa", "title": "Low-Rank Adaptation APPLIED_TO DeBERTa\nConfidence: 100%\nEvidence: evaluate the downstream task performance of LoRA on DeBERTa (He et al., 2021).", "to": "system:deberta", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "evaluate if LoRA can still match the performance of a fully fine-tuned DeBERTa XXL", "relation_type": "EXPLAINS", "source_name": "Low-Rank Adaptation", "target_name": "DeBERTa", "title": "Low-Rank Adaptation EXPLAINS DeBERTa\nConfidence: 100%\nEvidence: evaluate if LoRA can still match the performance of a fully fine-tuned DeBERTa XXL", "to": "system:deberta", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "prefix tuning (Li \u0026 Liang, 2021), faces a different challenge.", "relation_type": "INVESTIGATES", "source_name": "Low-Rank Adaptation", "target_name": "prefix tuning", "title": "Low-Rank Adaptation INVESTIGATES prefix tuning\nConfidence: 100%\nEvidence: prefix tuning (Li \u0026 Liang, 2021), faces a different challenge.", "to": "method:prefix_tuning", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "Adapter tuning as proposed in Houlsby et al. (2019)", "relation_type": "PROPOSED_BY", "source_name": "Low-Rank Adaptation", "target_name": "Houlsby et al.", "title": "Low-Rank Adaptation PROPOSED_BY Houlsby et al.\nConfidence: 100%\nEvidence: Adapter tuning as proposed in Houlsby et al. (2019)", "to": "researcher:houlsby_et_al", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "Using the E2E NLG Challenge dataset as an example.", "relation_type": "INVESTIGATES", "source_name": "Low-Rank Adaptation", "target_name": "E2E NLG Challenge", "title": "Low-Rank Adaptation INVESTIGATES E2E NLG Challenge\nConfidence: 100%\nEvidence: Using the E2E NLG Challenge dataset as an example.", "to": "system:e2e_nlg_challenge", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "evaluate the performance of different efficient adaptation approaches on tasks from the GLUE benchmark", "relation_type": "INVESTIGATES", "source_name": "Low-Rank Adaptation", "target_name": "GLUE", "title": "Low-Rank Adaptation INVESTIGATES GLUE\nConfidence: 100%\nEvidence: evaluate the performance of different efficient adaptation approaches on tasks from the GLUE benchmark", "to": "system:glue", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.9, "from": "method:low_rank_adaptation", "full_evidence": "The broad coverage makes GLUE benchmark a standard metric to evaluate NLU models such as RoBERTa and DeBERTa.", "relation_type": "APPLIED_TO", "source_name": "Low-Rank Adaptation", "target_name": "GLUE", "title": "Low-Rank Adaptation APPLIED_TO GLUE\nConfidence: 90%\nEvidence: The broad coverage makes GLUE benchmark a standard metric to evaluate NLU models such as RoBERTa and DeBERTa.", "to": "system:glue", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "We propose LoRA, an efficient adaptation strategy...", "relation_type": "PROPOSED_BY", "source_name": "Low-Rank Adaptation", "target_name": "Yelong Shen", "title": "Low-Rank Adaptation PROPOSED_BY Yelong Shen\nConfidence: 100%\nEvidence: We propose LoRA, an efficient adaptation strategy...", "to": "researcher:yelong_shen", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "We propose LoRA, an efficient adaptation strategy...", "relation_type": "PROPOSED_BY", "source_name": "Low-Rank Adaptation", "target_name": "Phillip Wallis", "title": "Low-Rank Adaptation PROPOSED_BY Phillip Wallis\nConfidence: 100%\nEvidence: We propose LoRA, an efficient adaptation strategy...", "to": "researcher:phillip_wallis", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "We propose LoRA, an efficient adaptation strategy...", "relation_type": "PROPOSED_BY", "source_name": "Low-Rank Adaptation", "target_name": "Zeyuan Allen-Zhu", "title": "Low-Rank Adaptation PROPOSED_BY Zeyuan Allen-Zhu\nConfidence: 100%\nEvidence: We propose LoRA, an efficient adaptation strategy...", "to": "researcher:zeyuan_allen_zhu", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "We propose LoRA, an efficient adaptation strategy...", "relation_type": "PROPOSED_BY", "source_name": "Low-Rank Adaptation", "target_name": "Yuanzhi Li", "title": "Low-Rank Adaptation PROPOSED_BY Yuanzhi Li\nConfidence: 100%\nEvidence: We propose LoRA, an efficient adaptation strategy...", "to": "researcher:yuanzhi_li", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "We propose LoRA, an efficient adaptation strategy...", "relation_type": "PROPOSED_BY", "source_name": "Low-Rank Adaptation", "target_name": "Shean Wang", "title": "Low-Rank Adaptation PROPOSED_BY Shean Wang\nConfidence: 100%\nEvidence: We propose LoRA, an efficient adaptation strategy...", "to": "researcher:shean_wang", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "We propose LoRA, an efficient adaptation strategy...", "relation_type": "PROPOSED_BY", "source_name": "Low-Rank Adaptation", "target_name": "Lu Wang", "title": "Low-Rank Adaptation PROPOSED_BY Lu Wang\nConfidence: 100%\nEvidence: We propose LoRA, an efficient adaptation strategy...", "to": "researcher:lu_wang", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "We propose LoRA, an efficient adaptation strategy...", "relation_type": "PROPOSED_BY", "source_name": "Low-Rank Adaptation", "target_name": "Weizhu Chen", "title": "Low-Rank Adaptation PROPOSED_BY Weizhu Chen\nConfidence: 100%\nEvidence: We propose LoRA, an efficient adaptation strategy...", "to": "researcher:weizhu_chen", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 0.8, "from": "method:low_rank_adaptation", "full_evidence": "Our method uses a similar bottleneck structure to impose a low-rank constraint on the weight updates.", "relation_type": "EXPLAINS", "source_name": "Low-Rank Adaptation", "target_name": "parameter-efficient adaptation", "title": "Low-Rank Adaptation EXPLAINS parameter-efficient adaptation\nConfidence: 80%\nEvidence: Our method uses a similar bottleneck structure to impose a low-rank constraint on the weight updates.", "to": "method:parameter_efficient_adaptation", "width": 2.0}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.8, "from": "method:low_rank_adaptation", "full_evidence": "Given the empirical advantage of LoRA, we hope to further explain the properties of the low-rank adaptation.", "relation_type": "SUPPORTS", "source_name": "Low-Rank Adaptation", "target_name": "empirical advantage", "title": "Low-Rank Adaptation SUPPORTS empirical advantage\nConfidence: 80%\nEvidence: Given the empirical advantage of LoRA, we hope to further explain the properties of the low-rank adaptation.", "to": "finding:empirical_advantage", "width": 2.0}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.8, "from": "method:low_rank_adaptation", "full_evidence": "A contemporary extension of adapter is COMPACTER.", "relation_type": "EXTENDS", "source_name": "Low-Rank Adaptation", "target_name": "COMPACTER", "title": "Low-Rank Adaptation EXTENDS COMPACTER\nConfidence: 80%\nEvidence: A contemporary extension of adapter is COMPACTER.", "to": "system:compacter", "width": 2.0}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.7, "from": "method:low_rank_adaptation", "full_evidence": "Given a parameter budget constraint, which subset of weight matrices in a pre-trained Transformer should we adapt.", "relation_type": "INVESTIGATES", "source_name": "Low-Rank Adaptation", "target_name": "weight matrices", "title": "Low-Rank Adaptation INVESTIGATES weight matrices\nConfidence: 70%\nEvidence: Given a parameter budget constraint, which subset of weight matrices in a pre-trained Transformer should we adapt.", "to": "concept:weight_matrices", "width": 1.75}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.7, "from": "method:low_rank_adaptation", "full_evidence": "We turn our attention to the effect of rank r on model performance.", "relation_type": "INVESTIGATES", "source_name": "Low-Rank Adaptation", "target_name": "rank", "title": "Low-Rank Adaptation INVESTIGATES rank\nConfidence: 70%\nEvidence: We turn our attention to the effect of rank r on model performance.", "to": "concept:rank", "width": 1.75}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 0.8, "from": "method:low_rank_adaptation", "full_evidence": "The main subject matter discusses the limitations of traditional fine-tuning methods, particularly in terms of resource requirements, and presents LoRA as a solution.", "relation_type": "EXPLAINS", "source_name": "Low-Rank Adaptation", "target_name": "fine-tuning", "title": "Low-Rank Adaptation EXPLAINS fine-tuning\nConfidence: 80%\nEvidence: The main subject matter discusses the limitations of traditional fine-tuning methods, particularly in terms of resource requirements, and presents LoR...", "to": "method:fine_tuning", "width": 2.0}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.7, "from": "method:low_rank_adaptation", "full_evidence": "The paper also includes empirical investigations and provides resources for integrating LoRA with existing models.", "relation_type": "SUPPORTS", "source_name": "Low-Rank Adaptation", "target_name": "empirical investigations", "title": "Low-Rank Adaptation SUPPORTS empirical investigations\nConfidence: 70%\nEvidence: The paper also includes empirical investigations and provides resources for integrating LoRA with existing models.", "to": "finding:empirical_investigations", "width": 1.75}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.7, "from": "method:low_rank_adaptation", "full_evidence": "A LARGE LANGUAGE MODELS STILL NEED PARAMETER UPDATES", "relation_type": "INVESTIGATES", "source_name": "Low-Rank Adaptation", "target_name": "Parameter updates", "title": "Low-Rank Adaptation INVESTIGATES Parameter updates\nConfidence: 70%\nEvidence: A LARGE LANGUAGE MODELS STILL NEED PARAMETER UPDATES", "to": "phenomenon:parameter_updates", "width": 1.75}, {"arrows": "to", "color": "#78909C", "edge_confidence": 0.8, "from": "method:low_rank_adaptation", "full_evidence": "our proposal, LoRA, can be seen as external modules added in a parallel manner.", "relation_type": "ASSOCIATED_WITH", "source_name": "Low-Rank Adaptation", "target_name": "Adapter layers", "title": "Low-Rank Adaptation ASSOCIATED_WITH Adapter layers\nConfidence: 80%\nEvidence: our proposal, LoRA, can be seen as external modules added in a parallel manner.", "to": "system:adapter_layers", "width": 2.0}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "Optimizer - AdamW", "relation_type": "USES_METHOD", "source_name": "Low-Rank Adaptation", "target_name": "AdamW", "title": "Low-Rank Adaptation USES_METHOD AdamW\nConfidence: 100%\nEvidence: Optimizer - AdamW", "to": "method:adamw", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "We report the validation loss and test metrics achieved by different choices of r.", "relation_type": "SUPPORTS", "source_name": "Low-Rank Adaptation", "target_name": "Validation loss", "title": "Low-Rank Adaptation SUPPORTS Validation loss\nConfidence: 100%\nEvidence: We report the validation loss and test metrics achieved by different choices of r.", "to": "finding:validation_loss", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "Validation loss and test set metrics on E2E NLG Challenge achieved by LoRA with different rank r.", "relation_type": "SUPPORTS", "source_name": "Low-Rank Adaptation", "target_name": "BLEU", "title": "Low-Rank Adaptation SUPPORTS BLEU\nConfidence: 100%\nEvidence: Validation loss and test set metrics on E2E NLG Challenge achieved by LoRA with different rank r.", "to": "finding:bleu", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "Validation loss and test set metrics on E2E NLG Challenge achieved by LoRA with different rank r.", "relation_type": "SUPPORTS", "source_name": "Low-Rank Adaptation", "target_name": "NIST", "title": "Low-Rank Adaptation SUPPORTS NIST\nConfidence: 100%\nEvidence: Validation loss and test set metrics on E2E NLG Challenge achieved by LoRA with different rank r.", "to": "finding:nist", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "Validation loss and test set metrics on E2E NLG Challenge achieved by LoRA with different rank r.", "relation_type": "SUPPORTS", "source_name": "Low-Rank Adaptation", "target_name": "METEOR", "title": "Low-Rank Adaptation SUPPORTS METEOR\nConfidence: 100%\nEvidence: Validation loss and test set metrics on E2E NLG Challenge achieved by LoRA with different rank r.", "to": "finding:meteor", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "Validation loss and test set metrics on E2E NLG Challenge achieved by LoRA with different rank r.", "relation_type": "SUPPORTS", "source_name": "Low-Rank Adaptation", "target_name": "ROUGE L", "title": "Low-Rank Adaptation SUPPORTS ROUGE L\nConfidence: 100%\nEvidence: Validation loss and test set metrics on E2E NLG Challenge achieved by LoRA with different rank r.", "to": "finding:rouge_l", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:low_rank_adaptation", "full_evidence": "Validation loss and test set metrics on E2E NLG Challenge achieved by LoRA with different rank r.", "relation_type": "SUPPORTS", "source_name": "Low-Rank Adaptation", "target_name": "CIDEr", "title": "Low-Rank Adaptation SUPPORTS CIDEr\nConfidence: 100%\nEvidence: Validation loss and test set metrics on E2E NLG Challenge achieved by LoRA with different rank r.", "to": "finding:cider", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "researcher:aghajanyan_et_al_2020", "full_evidence": "Aghajanyan et al. (2020) shows that the pre-trained language models have a low \u0027intrinsic dimension\u0027.", "relation_type": "SUPPORTS", "source_name": "Aghajanyan et al. (2020)", "target_name": "Low-Rank Adaptation", "title": "Aghajanyan et al. (2020) SUPPORTS Low-Rank Adaptation\nConfidence: 100%\nEvidence: Aghajanyan et al. (2020) shows that the pre-trained language models have a low \u0027intrinsic dimension\u0027.", "to": "method:low_rank_adaptation", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:adapter_tuning", "full_evidence": "Adapter tuning as proposed in Houlsby et al. (2019)", "relation_type": "PROPOSED_BY", "source_name": "Adapter tuning", "target_name": "Houlsby et al.", "title": "Adapter tuning PROPOSED_BY Houlsby et al.\nConfidence: 100%\nEvidence: Adapter tuning as proposed in Houlsby et al. (2019)", "to": "researcher:houlsby_et_al", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:adapterl", "full_evidence": "Recently, Lin et al. (2020) proposed a more efficient design", "relation_type": "PROPOSED_BY", "source_name": "AdapterL", "target_name": "Lin et al.", "title": "AdapterL PROPOSED_BY Lin et al.\nConfidence: 100%\nEvidence: Recently, Lin et al. (2020) proposed a more efficient design", "to": "researcher:lin_et_al", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:adapterp", "full_evidence": "similar to another design proposed in Pfeiffer et al. (2021)", "relation_type": "PROPOSED_BY", "source_name": "AdapterP", "target_name": "Pfeiffer et al.", "title": "AdapterP PROPOSED_BY Pfeiffer et al.\nConfidence: 100%\nEvidence: similar to another design proposed in Pfeiffer et al. (2021)", "to": "researcher:pfeiffer_et_al", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 0.9, "from": "concept:subspace_similarity", "full_evidence": "providing an explanation of why r = 1 performs quite well in our downstream tasks for GPT-3.", "relation_type": "EXPLAINS", "source_name": "subspace similarity", "target_name": "Low-Rank Adaptation", "title": "subspace similarity EXPLAINS Low-Rank Adaptation\nConfidence: 90%\nEvidence: providing an explanation of why r = 1 performs quite well in our downstream tasks for GPT-3.", "to": "method:low_rank_adaptation", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.8, "from": "concept:frobenius_norm", "full_evidence": "indicating that \u2206W amplifies some features that are already in W.", "relation_type": "SUPPORTS", "source_name": "Frobenius norm", "target_name": "Low-Rank Adaptation", "title": "Frobenius norm SUPPORTS Low-Rank Adaptation\nConfidence: 80%\nEvidence: indicating that \u2206W amplifies some features that are already in W.", "to": "method:low_rank_adaptation", "width": 2.0}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "system:adapter_layers", "full_evidence": "Adapter Layers Introduce Inference Latency.", "relation_type": "CONTRADICTS", "source_name": "Adapter layers", "target_name": "Low-Rank Adaptation", "title": "Adapter layers CONTRADICTS Low-Rank Adaptation\nConfidence: 100%\nEvidence: Adapter Layers Introduce Inference Latency.", "to": "method:low_rank_adaptation", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "system:dart", "full_evidence": "DART is an open-domain data-to-text dataset described in Nan et al. (2020).", "relation_type": "PROPOSED_BY", "source_name": "DART", "target_name": "Nan et al.", "title": "DART PROPOSED_BY Nan et al.\nConfidence: 90%\nEvidence: DART is an open-domain data-to-text dataset described in Nan et al. (2020).", "to": "researcher:nan_et_al", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.9, "from": "system:webnlg", "full_evidence": "WebNLG is another commonly used dataset for data-to-text evaluation.", "relation_type": "PROPOSED_BY", "source_name": "WebNLG", "target_name": "Gardent et al.", "title": "WebNLG PROPOSED_BY Gardent et al.\nConfidence: 90%\nEvidence: WebNLG is another commonly used dataset for data-to-text evaluation.", "to": "researcher:gardent_et_al", "width": 2.25}, {"arrows": "to", "color": "#FFA726", "edge_confidence": 1.0, "from": "system:lora_prefixembed", "full_evidence": "LoRA+PrefixEmbed (LoRA+PE) combines LoRA with prefix-embedding tuning...", "relation_type": "IMPLEMENTS", "source_name": "LoRA+PrefixEmbed", "target_name": "Low-Rank Adaptation", "title": "LoRA+PrefixEmbed IMPLEMENTS Low-Rank Adaptation\nConfidence: 100%\nEvidence: LoRA+PrefixEmbed (LoRA+PE) combines LoRA with prefix-embedding tuning...", "to": "method:low_rank_adaptation", "width": 2.5}, {"arrows": "to", "color": "#FFA726", "edge_confidence": 1.0, "from": "system:lora_prefixlayer", "full_evidence": "LoRA+PrefixLayer (LoRA+PL) combines LoRA with prefix-layer tuning...", "relation_type": "IMPLEMENTS", "source_name": "LoRA+PrefixLayer", "target_name": "Low-Rank Adaptation", "title": "LoRA+PrefixLayer IMPLEMENTS Low-Rank Adaptation\nConfidence: 100%\nEvidence: LoRA+PrefixLayer (LoRA+PL) combines LoRA with prefix-layer tuning...", "to": "method:low_rank_adaptation", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "The findings demonstrate that this approach can significantly outperform traditional prompting methods, achieving state-of-the-art results on benchmarks like GSM8K for math word problems.", "relation_type": "SUPPORTS", "source_name": "Chain-of-Thought Prompting", "target_name": "arithmetic reasoning", "title": "Chain-of-Thought Prompting SUPPORTS arithmetic reasoning\nConfidence: 100%\nEvidence: The findings demonstrate that this approach can significantly outperform traditional prompting methods, achieving state-of-the-art results on benchmar...", "to": "phenomenon:arithmetic_reasoning", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "the symbolic reasoning datasets were created synthetically", "relation_type": "APPLIED_TO", "source_name": "Chain-of-Thought Prompting", "target_name": "arithmetic reasoning", "title": "Chain-of-Thought Prompting APPLIED_TO arithmetic reasoning\nConfidence: 100%\nEvidence: the symbolic reasoning datasets were created synthetically", "to": "phenomenon:arithmetic_reasoning", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.8, "from": "method:chain_of_thought_prompting", "full_evidence": "leading to improved performance on complex tasks such as arithmetic and commonsense reasoning.", "relation_type": "INVESTIGATES", "source_name": "Chain-of-Thought Prompting", "target_name": "arithmetic reasoning", "title": "Chain-of-Thought Prompting INVESTIGATES arithmetic reasoning\nConfidence: 80%\nEvidence: leading to improved performance on complex tasks such as arithmetic and commonsense reasoning.", "to": "phenomenon:arithmetic_reasoning", "width": 2.0}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "The findings demonstrate that this approach can significantly outperform traditional prompting methods, achieving state-of-the-art results on benchmarks like GSM8K for math word problems.", "relation_type": "SUPPORTS", "source_name": "Chain-of-Thought Prompting", "target_name": "CommonSense Reasoning", "title": "Chain-of-Thought Prompting SUPPORTS CommonSense Reasoning\nConfidence: 100%\nEvidence: The findings demonstrate that this approach can significantly outperform traditional prompting methods, achieving state-of-the-art results on benchmar...", "to": "phenomenon:commonsense_reasoning", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 0.9, "from": "method:chain_of_thought_prompting", "full_evidence": "the language-based nature of chain-of-thought actually makes it applicable to a broad class of commonsense reasoning problems", "relation_type": "EXPLAINS", "source_name": "Chain-of-Thought Prompting", "target_name": "CommonSense Reasoning", "title": "Chain-of-Thought Prompting EXPLAINS CommonSense Reasoning\nConfidence: 90%\nEvidence: the language-based nature of chain-of-thought actually makes it applicable to a broad class of commonsense reasoning problems", "to": "phenomenon:commonsense_reasoning", "width": 2.25}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "the symbolic reasoning datasets were created synthetically", "relation_type": "APPLIED_TO", "source_name": "Chain-of-Thought Prompting", "target_name": "CommonSense Reasoning", "title": "Chain-of-Thought Prompting APPLIED_TO CommonSense Reasoning\nConfidence: 100%\nEvidence: the symbolic reasoning datasets were created synthetically", "to": "phenomenon:commonsense_reasoning", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.8, "from": "method:chain_of_thought_prompting", "full_evidence": "leading to improved performance on complex tasks such as arithmetic and commonsense reasoning.", "relation_type": "INVESTIGATES", "source_name": "Chain-of-Thought Prompting", "target_name": "CommonSense Reasoning", "title": "Chain-of-Thought Prompting INVESTIGATES CommonSense Reasoning\nConfidence: 80%\nEvidence: leading to improved performance on complex tasks such as arithmetic and commonsense reasoning.", "to": "phenomenon:commonsense_reasoning", "width": 2.0}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "although in this paper we focused on multi-step reasoning tasks (arithmetic, commonsense, and symbolic)", "relation_type": "SUPPORTS", "source_name": "Chain-of-Thought Prompting", "target_name": "symbolic reasoning", "title": "Chain-of-Thought Prompting SUPPORTS symbolic reasoning\nConfidence: 100%\nEvidence: although in this paper we focused on multi-step reasoning tasks (arithmetic, commonsense, and symbolic)", "to": "phenomenon:symbolic_reasoning", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 0.9, "from": "method:chain_of_thought_prompting", "full_evidence": "we show that chain-of-thought prompting not only enables language models to perform symbolic reasoning tasks", "relation_type": "EXPLAINS", "source_name": "Chain-of-Thought Prompting", "target_name": "symbolic reasoning", "title": "Chain-of-Thought Prompting EXPLAINS symbolic reasoning\nConfidence: 90%\nEvidence: we show that chain-of-thought prompting not only enables language models to perform symbolic reasoning tasks", "to": "phenomenon:symbolic_reasoning", "width": 2.25}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.9, "from": "method:chain_of_thought_prompting", "full_evidence": "chain-of-thought prompting not only enables language models to perform symbolic reasoning tasks", "relation_type": "APPLIED_TO", "source_name": "Chain-of-Thought Prompting", "target_name": "symbolic reasoning", "title": "Chain-of-Thought Prompting APPLIED_TO symbolic reasoning\nConfidence: 90%\nEvidence: chain-of-thought prompting not only enables language models to perform symbolic reasoning tasks", "to": "phenomenon:symbolic_reasoning", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "investigates the effectiveness of \u0027chain-of-thought prompting,\u0027 a method that enhances the reasoning capabilities of large language models", "relation_type": "PROPOSED_BY", "source_name": "Chain-of-Thought Prompting", "target_name": "Jason Wei", "title": "Chain-of-Thought Prompting PROPOSED_BY Jason Wei\nConfidence: 100%\nEvidence: investigates the effectiveness of \u0027chain-of-thought prompting,\u0027 a method that enhances the reasoning capabilities of large language models", "to": "researcher:jason_wei", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "investigates the effectiveness of \u0027chain-of-thought prompting,\u0027 a method that enhances the reasoning capabilities of large language models", "relation_type": "PROPOSED_BY", "source_name": "Chain-of-Thought Prompting", "target_name": "Xuezhi Wang", "title": "Chain-of-Thought Prompting PROPOSED_BY Xuezhi Wang\nConfidence: 100%\nEvidence: investigates the effectiveness of \u0027chain-of-thought prompting,\u0027 a method that enhances the reasoning capabilities of large language models", "to": "researcher:xuezhi_wang", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "investigates the effectiveness of \u0027chain-of-thought prompting,\u0027 a method that enhances the reasoning capabilities of large language models", "relation_type": "PROPOSED_BY", "source_name": "Chain-of-Thought Prompting", "target_name": "Denny Zhou", "title": "Chain-of-Thought Prompting PROPOSED_BY Denny Zhou\nConfidence: 100%\nEvidence: investigates the effectiveness of \u0027chain-of-thought prompting,\u0027 a method that enhances the reasoning capabilities of large language models", "to": "researcher:denny_zhou", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "The recent success of large-scale language models has led to growing interest in improving their capability to perform tasks via prompting (Brown et al.)", "relation_type": "PROPOSED_BY", "source_name": "Chain-of-Thought Prompting", "target_name": "Brown et al.", "title": "Chain-of-Thought Prompting PROPOSED_BY Brown et al.\nConfidence: 100%\nEvidence: The recent success of large-scale language models has led to growing interest in improving their capability to perform tasks via prompting (Brown et a...", "to": "researcher:brown_et_al", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "chain-of-thought prompting with PaLM 540B outperforms standard prompting by a large margin and achieves new state-of-the-art performance.", "relation_type": "PROPOSED_BY", "source_name": "Chain-of-Thought Prompting", "target_name": "Cobbe et al.", "title": "Chain-of-Thought Prompting PROPOSED_BY Cobbe et al.\nConfidence: 100%\nEvidence: chain-of-thought prompting with PaLM 540B outperforms standard prompting by a large margin and achieves new state-of-the-art performance.", "to": "researcher:cobbe_et_al", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "chain-of-thought prompting is an emergent ability of model scale", "relation_type": "SUPPORTS", "source_name": "Chain-of-Thought Prompting", "target_name": "emergent ability of model scale", "title": "Chain-of-Thought Prompting SUPPORTS emergent ability of model scale\nConfidence: 100%\nEvidence: chain-of-thought prompting is an emergent ability of model scale", "to": "finding:emergent_ability_of_model_scale", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "chain-of-thought prompting has larger performance gains for more-complicated problems", "relation_type": "SUPPORTS", "source_name": "Chain-of-Thought Prompting", "target_name": "performance gains for complicated problems", "title": "Chain-of-Thought Prompting SUPPORTS performance gains for complicated problems\nConfidence: 100%\nEvidence: chain-of-thought prompting has larger performance gains for more-complicated problems", "to": "finding:performance_gains_for_complicated_problems", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "method:chain_of_thought_prompting", "full_evidence": "the findings demonstrate that this approach can significantly outperform traditional prompting methods, achieving state-of-the-art results on benchmarks like GSM8K", "relation_type": "SUPPORTS", "source_name": "Chain-of-Thought Prompting", "target_name": "GSM8K", "title": "Chain-of-Thought Prompting SUPPORTS GSM8K\nConfidence: 90%\nEvidence: the findings demonstrate that this approach can significantly outperform traditional prompting methods, achieving state-of-the-art results on benchmar...", "to": "system:gsm8k", "width": 2.25}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "achieving state-of-the-art results on benchmarks like GSM8K for math word problems.", "relation_type": "APPLIED_TO", "source_name": "Chain-of-Thought Prompting", "target_name": "GSM8K", "title": "Chain-of-Thought Prompting APPLIED_TO GSM8K\nConfidence: 100%\nEvidence: achieving state-of-the-art results on benchmarks like GSM8K for math word problems.", "to": "system:gsm8k", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 0.9, "from": "method:chain_of_thought_prompting", "full_evidence": "investigates the effectiveness of \u0027chain-of-thought prompting,\u0027 a method that enhances the reasoning capabilities of large language models by providing intermediate reasoning steps in prompts, leading to improved performance on complex tasks such as arithmetic and commonsense reasoning", "relation_type": "EXPLAINS", "source_name": "Chain-of-Thought Prompting", "target_name": "arithmetic and commonsense reasoning", "title": "Chain-of-Thought Prompting EXPLAINS arithmetic and commonsense reasoning\nConfidence: 90%\nEvidence: investigates the effectiveness of \u0027chain-of-thought prompting,\u0027 a method that enhances the reasoning capabilities of large language models by providin...", "to": "phenomenon:arithmetic_and_commonsense_reasoning", "width": 2.25}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 0.9, "from": "method:chain_of_thought_prompting", "full_evidence": "investigates the effectiveness of \u0027chain-of-thought prompting,\u0027 a method that enhances the reasoning capabilities of large language models", "relation_type": "EXPLAINS", "source_name": "Chain-of-Thought Prompting", "target_name": "large language models", "title": "Chain-of-Thought Prompting EXPLAINS large language models\nConfidence: 90%\nEvidence: investigates the effectiveness of \u0027chain-of-thought prompting,\u0027 a method that enhances the reasoning capabilities of large language models", "to": "phenomenon:large_language_models", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "the GSM8K dataset (Cobbe et al., 2021) conveniently provides a training set with reasoning chains written by crowd compute workers", "relation_type": "PROPOSED_BY", "source_name": "Chain-of-Thought Prompting", "target_name": "Cobbe et al. (2021)", "title": "Chain-of-Thought Prompting PROPOSED_BY Cobbe et al. (2021)\nConfidence: 100%\nEvidence: the GSM8K dataset (Cobbe et al., 2021) conveniently provides a training set with reasoning chains written by crowd compute workers", "to": "publication:cobbe_et_al_2021", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "the goal of chain-of-thought prompting is to allow models to decompose multi-hop reasoning tasks into multiple steps", "relation_type": "EXTENDS", "source_name": "Chain-of-Thought Prompting", "target_name": "natural language explanations", "title": "Chain-of-Thought Prompting EXTENDS natural language explanations\nConfidence: 100%\nEvidence: the goal of chain-of-thought prompting is to allow models to decompose multi-hop reasoning tasks into multiple steps", "to": "concept:natural_language_explanations", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "Using intermediate reasoning steps has a long history in program synthesis and execution", "relation_type": "ASSOCIATED_WITH", "source_name": "Chain-of-Thought Prompting", "target_name": "program synthesis and execution", "title": "Chain-of-Thought Prompting ASSOCIATED_WITH program synthesis and execution\nConfidence: 100%\nEvidence: Using intermediate reasoning steps has a long history in program synthesis and execution", "to": "concept:program_synthesis_and_execution", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "Numeric and logical reasoning has been a long-studied task in machine learning and natural language processing", "relation_type": "ASSOCIATED_WITH", "source_name": "Chain-of-Thought Prompting", "target_name": "numeric and logical reasoning", "title": "Chain-of-Thought Prompting ASSOCIATED_WITH numeric and logical reasoning\nConfidence: 100%\nEvidence: Numeric and logical reasoning has been a long-studied task in machine learning and natural language processing", "to": "concept:numeric_and_logical_reasoning", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "Extensive prior work has shown the benefits of endowing neural networks with the ability to produce intermediate steps", "relation_type": "ASSOCIATED_WITH", "source_name": "Chain-of-Thought Prompting", "target_name": "intermediate language steps", "title": "Chain-of-Thought Prompting ASSOCIATED_WITH intermediate language steps\nConfidence: 100%\nEvidence: Extensive prior work has shown the benefits of endowing neural networks with the ability to produce intermediate steps", "to": "concept:intermediate_language_steps", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 0.8, "from": "method:chain_of_thought_prompting", "full_evidence": "Improvingthefactualityoflanguagemodelgenerationswithrespecttocontextandworldknowledge isanimportantdirectionopenproblemsinlanguagemodelresearchandcouldalsobeexpectedto potentiallyimprovemulti-stepreasoningabilitiesoflanguagemodels", "relation_type": "EXPLAINS", "source_name": "Chain-of-Thought Prompting", "target_name": "multi-step reasoning abilities", "title": "Chain-of-Thought Prompting EXPLAINS multi-step reasoning abilities\nConfidence: 80%\nEvidence: Improvingthefactualityoflanguagemodelgenerationswithrespecttocontextandworldknowledge isanimportantdirectionopenproblemsinlanguagemodelresearchandcoul...", "to": "concept:multi_step_reasoning_abilities", "width": 2.0}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "the findings demonstrate that this approach can significantly outperform traditional prompting methods", "relation_type": "SUPPORTS", "source_name": "Chain-of-Thought Prompting", "target_name": "math word problems", "title": "Chain-of-Thought Prompting SUPPORTS math word problems\nConfidence: 100%\nEvidence: the findings demonstrate that this approach can significantly outperform traditional prompting methods", "to": "phenomenon:math_word_problems", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "Examples of correct and incorrect chains of thought produced by LaMDA 137B", "relation_type": "SUPPORTS", "source_name": "Chain-of-Thought Prompting", "target_name": "LaMDA", "title": "Chain-of-Thought Prompting SUPPORTS LaMDA\nConfidence: 100%\nEvidence: Examples of correct and incorrect chains of thought produced by LaMDA 137B", "to": "system:lamda", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:chain_of_thought_prompting", "full_evidence": "Examples of correct and incorrect chains of thought produced by PaLM 540B", "relation_type": "SUPPORTS", "source_name": "Chain-of-Thought Prompting", "target_name": "PaLM", "title": "Chain-of-Thought Prompting SUPPORTS PaLM\nConfidence: 100%\nEvidence: Examples of correct and incorrect chains of thought produced by PaLM 540B", "to": "system:palm", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.8, "from": "method:chain_of_thought_prompting", "full_evidence": "the question of why model scale improves chain-of-thought prompting is certainly multi-faceted", "relation_type": "INVESTIGATES", "source_name": "Chain-of-Thought Prompting", "target_name": "model scale", "title": "Chain-of-Thought Prompting INVESTIGATES model scale\nConfidence: 80%\nEvidence: the question of why model scale improves chain-of-thought prompting is certainly multi-faceted", "to": "concept:model_scale", "width": 2.0}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.9, "from": "system:gsm8k", "full_evidence": "the findings demonstrate that this approach can significantly outperform traditional prompting methods", "relation_type": "USES_METHOD", "source_name": "GSM8K", "target_name": "Chain-of-Thought Prompting", "title": "GSM8K USES_METHOD Chain-of-Thought Prompting\nConfidence: 90%\nEvidence: the findings demonstrate that this approach can significantly outperform traditional prompting methods", "to": "method:chain_of_thought_prompting", "width": 2.25}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "method:standard_prompting", "full_evidence": "the improvement of chain-of-thought prompting over standard prompting remains robust", "relation_type": "CONTRADICTS", "source_name": "standard prompting", "target_name": "Chain-of-Thought Prompting", "title": "standard prompting CONTRADICTS Chain-of-Thought Prompting\nConfidence: 100%\nEvidence: the improvement of chain-of-thought prompting over standard prompting remains robust", "to": "method:chain_of_thought_prompting", "width": 2.5}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "method:standard_prompting", "full_evidence": "standard prompting fails for both tasks", "relation_type": "CONTRADICTS", "source_name": "standard prompting", "target_name": "arithmetic reasoning", "title": "standard prompting CONTRADICTS arithmetic reasoning\nConfidence: 100%\nEvidence: standard prompting fails for both tasks", "to": "phenomenon:arithmetic_reasoning", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:lamda", "full_evidence": "we find that with the same prompts, chain-of-thought prompting improves performance across all three models (LaMDA, GPT-3, and PaLM)", "relation_type": "USES_METHOD", "source_name": "LaMDA", "target_name": "Chain-of-Thought Prompting", "title": "LaMDA USES_METHOD Chain-of-Thought Prompting\nConfidence: 100%\nEvidence: we find that with the same prompts, chain-of-thought prompting improves performance across all three models (LaMDA, GPT-3, and PaLM)", "to": "method:chain_of_thought_prompting", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.9, "from": "system:palm", "full_evidence": "With chain-of-thought prompting, PaLM540B achieved strong performance relative to baselines", "relation_type": "USES_METHOD", "source_name": "PaLM", "target_name": "Chain-of-Thought Prompting", "title": "PaLM USES_METHOD Chain-of-Thought Prompting\nConfidence: 90%\nEvidence: With chain-of-thought prompting, PaLM540B achieved strong performance relative to baselines", "to": "method:chain_of_thought_prompting", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "concept:intermediate_steps", "full_evidence": "Ling et al. (2017) pioneered the idea of using natural language rationales to solve math word problems", "relation_type": "PROPOSED_BY", "source_name": "intermediate steps", "target_name": "Ling et al. (2017)", "title": "intermediate steps PROPOSED_BY Ling et al. (2017)\nConfidence: 100%\nEvidence: Ling et al. (2017) pioneered the idea of using natural language rationales to solve math word problems", "to": "researcher:ling_et_al_2017", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "researcher:nye_et_al_2021", "full_evidence": "Nye et al. (2021) leverage language models to predict the final outputs of Python programs", "relation_type": "PROPOSED_BY", "source_name": "Nye et al. (2021)", "target_name": "symbolic reasoning", "title": "Nye et al. (2021) PROPOSED_BY symbolic reasoning\nConfidence: 100%\nEvidence: Nye et al. (2021) leverage language models to predict the final outputs of Python programs", "to": "phenomenon:symbolic_reasoning", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.7, "from": "method:error_analysis", "full_evidence": "this small analysis involved manually reading 45 errors made by PaLM 62B", "relation_type": "USES_METHOD", "source_name": "error analysis", "target_name": "PaLM", "title": "error analysis USES_METHOD PaLM\nConfidence: 70%\nEvidence: this small analysis involved manually reading 45 errors made by PaLM 62B", "to": "system:palm", "width": 1.75}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "publication:cobbe_et_al_2021", "full_evidence": "Cobbe et al. (2021) extend Ling et al. (2017) by creating a larger dataset", "relation_type": "EXTENDS", "source_name": "Cobbe et al. (2021)", "target_name": "Ling et al. (2017)", "title": "Cobbe et al. (2021) EXTENDS Ling et al. (2017)\nConfidence: 100%\nEvidence: Cobbe et al. (2021) extend Ling et al. (2017) by creating a larger dataset", "to": "researcher:ling_et_al_2017", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:lamda137b", "full_evidence": "examples of correct and incorrect chains of thought produced by LaMDA137B", "relation_type": "USES_METHOD", "source_name": "LaMDA137B", "target_name": "Chain-of-Thought Prompting", "title": "LaMDA137B USES_METHOD Chain-of-Thought Prompting\nConfidence: 100%\nEvidence: examples of correct and incorrect chains of thought produced by LaMDA137B", "to": "method:chain_of_thought_prompting", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.7, "from": "finding:calculator_error", "full_evidence": "applyinganexternalcalculatortoequations, asdonein Cobbeetal.(2021)", "relation_type": "PROPOSED_BY", "source_name": "calculator error", "target_name": "Cobbe et al. (2021)", "title": "calculator error PROPOSED_BY Cobbe et al. (2021)\nConfidence: 70%\nEvidence: applyinganexternalcalculatortoequations, asdonein Cobbeetal.(2021)", "to": "publication:cobbe_et_al_2021", "width": 1.75}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.7, "from": "concept:multi_step_reasoning_abilities", "full_evidence": "thoughthisrequirestrainingtheverifier(Cobbeetal., 2021;Shenetal., 2021;Thoppilanetal.,2022)", "relation_type": "PROPOSED_BY", "source_name": "multi-step reasoning abilities", "target_name": "Thoppilan et al. (2022)", "title": "multi-step reasoning abilities PROPOSED_BY Thoppilan et al. (2022)\nConfidence: 70%\nEvidence: thoughthisrequirestrainingtheverifier(Cobbeetal., 2021;Shenetal., 2021;Thoppilanetal.,2022)", "to": "publication:thoppilan_et_al_2022", "width": 1.75}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "The document is a research paper titled \u0027FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness,\u0027 authored by Tri Dao.", "relation_type": "PROPOSED_BY", "source_name": "FlashAttention", "target_name": "Tri Dao", "title": "FlashAttention PROPOSED_BY Tri Dao\nConfidence: 100%\nEvidence: The document is a research paper titled \u0027FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness,\u0027 authored by Tri Dao.", "to": "researcher:tri_dao", "width": 2.5}, {"arrows": "to", "color": "#FFA726", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "discusses the development of FlashAttention, an innovative attention algorithm designed to enhance the efficiency of Transformer models", "relation_type": "IMPLEMENTS", "source_name": "FlashAttention", "target_name": "Transformer", "title": "FlashAttention IMPLEMENTS Transformer\nConfidence: 100%\nEvidence: discusses the development of FlashAttention, an innovative attention algorithm designed to enhance the efficiency of Transformer models", "to": "theory:transformer", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "FlashAttention is designed to enhance the efficiency of Transformer models.", "relation_type": "EXTENDS", "source_name": "FlashAttention", "target_name": "Transformer", "title": "FlashAttention EXTENDS Transformer\nConfidence: 100%\nEvidence: FlashAttention is designed to enhance the efficiency of Transformer models.", "to": "theory:transformer", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "we further show that FlashAttention can serve as a useful primitive by extending it to handle block-sparse attention.", "relation_type": "EXTENDS", "source_name": "FlashAttention", "target_name": "block-sparse attention", "title": "FlashAttention EXTENDS block-sparse attention\nConfidence: 100%\nEvidence: we further show that FlashAttention can serve as a useful primitive by extending it to handle block-sparse attention.", "to": "concept:block_sparse_attention", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "15% end-to-end wall-clock speedup on BERT-large.", "relation_type": "SUPPORTS", "source_name": "FlashAttention", "target_name": "BERT-Large", "title": "FlashAttention SUPPORTS BERT-Large\nConfidence: 100%\nEvidence: 15% end-to-end wall-clock speedup on BERT-large.", "to": "system:bert_large", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "We confirm that FlashAttention yields the same validation curves as the baseline implementation from HuggingFace.", "relation_type": "SUPPORTS", "source_name": "FlashAttention", "target_name": "GPT-2", "title": "FlashAttention SUPPORTS GPT-2\nConfidence: 100%\nEvidence: We confirm that FlashAttention yields the same validation curves as the baseline implementation from HuggingFace.", "to": "system:gpt_2", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "the first Transformers to achieve better-than-chance performance on the Path-X challenge.", "relation_type": "INVESTIGATES", "source_name": "FlashAttention", "target_name": "Path-X challenge", "title": "FlashAttention INVESTIGATES Path-X challenge\nConfidence: 100%\nEvidence: the first Transformers to achieve better-than-chance performance on the Path-X challenge.", "to": "phenomenon:path_x_challenge", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "the first Transformers to achieve better-than-chance performance on Path-256.", "relation_type": "INVESTIGATES", "source_name": "FlashAttention", "target_name": "Path-256", "title": "FlashAttention INVESTIGATES Path-256\nConfidence: 100%\nEvidence: the first Transformers to achieve better-than-chance performance on Path-256.", "to": "system:path_256", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "The most common approach to accelerate memory-bound operations is kernel fusion.", "relation_type": "USES_METHOD", "source_name": "FlashAttention", "target_name": "kernel fusion", "title": "FlashAttention USES_METHOD kernel fusion\nConfidence: 100%\nEvidence: The most common approach to accelerate memory-bound operations is kernel fusion.", "to": "method:kernel_fusion", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "P=softmax(S) \u2208R\ud835\udc41\u00d7\ud835\udc41.", "relation_type": "USES_METHOD", "source_name": "FlashAttention", "target_name": "softmax", "title": "FlashAttention USES_METHOD softmax\nConfidence: 100%\nEvidence: P=softmax(S) \u2208R\ud835\udc41\u00d7\ud835\udc41.", "to": "method:softmax", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "The document is a research paper titled \u0027FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness,\u0027 authored by Daniel Y. Fu.", "relation_type": "PROPOSED_BY", "source_name": "FlashAttention", "target_name": "Daniel Y. Fu", "title": "FlashAttention PROPOSED_BY Daniel Y. Fu\nConfidence: 100%\nEvidence: The document is a research paper titled \u0027FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness,\u0027 authored by Daniel Y. Fu.", "to": "researcher:daniel_y_fu", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "The document is a research paper titled \u0027FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness,\u0027 authored by Stefano Ermon.", "relation_type": "PROPOSED_BY", "source_name": "FlashAttention", "target_name": "Stefano Ermon", "title": "FlashAttention PROPOSED_BY Stefano Ermon\nConfidence: 100%\nEvidence: The document is a research paper titled \u0027FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness,\u0027 authored by Stefano Ermon.", "to": "researcher:stefano_ermon", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "The document is a research paper titled \u0027FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness,\u0027 authored by Atri Rudra.", "relation_type": "PROPOSED_BY", "source_name": "FlashAttention", "target_name": "Atri Rudra", "title": "FlashAttention PROPOSED_BY Atri Rudra\nConfidence: 100%\nEvidence: The document is a research paper titled \u0027FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness,\u0027 authored by Atri Rudra.", "to": "researcher:atri_rudra", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "The document is a research paper titled \u0027FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness,\u0027 authored by Christopher R\u00e9.", "relation_type": "PROPOSED_BY", "source_name": "FlashAttention", "target_name": "Christopher R\u00e9", "title": "FlashAttention PROPOSED_BY Christopher R\u00e9\nConfidence: 100%\nEvidence: The document is a research paper titled \u0027FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness,\u0027 authored by Christopher R\u00e9.", "to": "researcher:christopher_re", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "We confirm that FlashAttention yields the same validation curves as the baseline implementation from HuggingFace.", "relation_type": "SUPPORTS", "source_name": "FlashAttention", "target_name": "BERT", "title": "FlashAttention SUPPORTS BERT\nConfidence: 100%\nEvidence: We confirm that FlashAttention yields the same validation curves as the baseline implementation from HuggingFace.", "to": "system:bert", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "We extend FlashAttention to approximate attention: we propose block-sparse FlashAttention...", "relation_type": "EXTENDS", "source_name": "FlashAttention", "target_name": "block-sparse FlashAttention", "title": "FlashAttention EXTENDS block-sparse FlashAttention\nConfidence: 100%\nEvidence: We extend FlashAttention to approximate attention: we propose block-sparse FlashAttention...", "to": "system:block_sparse_flashattention", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "FlashAttention achieves up 2.4\u00d7 speed-up compared to standard attention.", "relation_type": "SUPPORTS", "source_name": "FlashAttention", "target_name": "Long-range arena", "title": "FlashAttention SUPPORTS Long-range arena\nConfidence: 100%\nEvidence: FlashAttention achieves up 2.4\u00d7 speed-up compared to standard attention.", "to": "field:long_range_arena", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 0.9, "from": "system:flashattention", "full_evidence": "we fix the sparsity pattern to be the butterfly pattern through training, and observe that it performs almost as well as the (dense) FlashAttention on the Long-range Arena tasks", "relation_type": "INVESTIGATES", "source_name": "FlashAttention", "target_name": "Long-range arena", "title": "FlashAttention INVESTIGATES Long-range arena\nConfidence: 90%\nEvidence: we fix the sparsity pattern to be the butterfly pattern through training, and observe that it performs almost as well as the (dense) FlashAttention on...", "to": "field:long_range_arena", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "Training Transformers with longer sequences with FlashAttention improves performance on the MIMIC-III [47] and ECtHR [6, 7] datasets.", "relation_type": "SUPPORTS", "source_name": "FlashAttention", "target_name": "MIMIC-III", "title": "FlashAttention SUPPORTS MIMIC-III\nConfidence: 100%\nEvidence: Training Transformers with longer sequences with FlashAttention improves performance on the MIMIC-III [47] and ECtHR [6, 7] datasets.", "to": "system:mimic_iii", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "Training Transformers with longer sequences with FlashAttention improves performance on the MIMIC-III [47] and ECtHR [6, 7] datasets.", "relation_type": "SUPPORTS", "source_name": "FlashAttention", "target_name": "ECtHR", "title": "FlashAttention SUPPORTS ECtHR\nConfidence: 100%\nEvidence: Training Transformers with longer sequences with FlashAttention improves performance on the MIMIC-III [47] and ECtHR [6, 7] datasets.", "to": "system:ecthr", "width": 2.5}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "FlashAttention is still 2\u00d7 more efficient than Linformer.", "relation_type": "CONTRADICTS", "source_name": "FlashAttention", "target_name": "Linformer", "title": "FlashAttention CONTRADICTS Linformer\nConfidence: 100%\nEvidence: FlashAttention is still 2\u00d7 more efficient than Linformer.", "to": "system:linformer", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "we compare against reference implementations of Linformer Attention", "relation_type": "ASSOCIATED_WITH", "source_name": "FlashAttention", "target_name": "Linformer", "title": "FlashAttention ASSOCIATED_WITH Linformer\nConfidence: 100%\nEvidence: we compare against reference implementations of Linformer Attention", "to": "system:linformer", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "system:flashattention", "full_evidence": "FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "relation_type": "SUPPORTS", "source_name": "FlashAttention", "target_name": "Linformer", "title": "FlashAttention SUPPORTS Linformer\nConfidence: 90%\nEvidence: FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "to": "system:linformer", "width": 2.25}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "FlashAttention is still 2\u00d7 more efficient than Linformer.", "relation_type": "CONTRADICTS", "source_name": "FlashAttention", "target_name": "Linear Attention", "title": "FlashAttention CONTRADICTS Linear Attention\nConfidence: 100%\nEvidence: FlashAttention is still 2\u00d7 more efficient than Linformer.", "to": "system:linear_attention", "width": 2.5}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "FlashAttention is still 2\u00d7 more efficient than Linformer.", "relation_type": "CONTRADICTS", "source_name": "FlashAttention", "target_name": "Performer", "title": "FlashAttention CONTRADICTS Performer\nConfidence: 100%\nEvidence: FlashAttention is still 2\u00d7 more efficient than Linformer.", "to": "system:performer", "width": 2.5}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "FlashAttention is still 2\u00d7 more efficient than Linformer.", "relation_type": "CONTRADICTS", "source_name": "FlashAttention", "target_name": "Local Attention", "title": "FlashAttention CONTRADICTS Local Attention\nConfidence: 100%\nEvidence: FlashAttention is still 2\u00d7 more efficient than Linformer.", "to": "system:local_attention", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "we compare against reference implementations of Local Attention", "relation_type": "ASSOCIATED_WITH", "source_name": "FlashAttention", "target_name": "Local Attention", "title": "FlashAttention ASSOCIATED_WITH Local Attention\nConfidence: 100%\nEvidence: we compare against reference implementations of Local Attention", "to": "system:local_attention", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "system:flashattention", "full_evidence": "FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "relation_type": "SUPPORTS", "source_name": "FlashAttention", "target_name": "Local Attention", "title": "FlashAttention SUPPORTS Local Attention\nConfidence: 90%\nEvidence: FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "to": "system:local_attention", "width": 2.25}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "FlashAttention is still 2\u00d7 more efficient than Linformer.", "relation_type": "CONTRADICTS", "source_name": "FlashAttention", "target_name": "Reformer", "title": "FlashAttention CONTRADICTS Reformer\nConfidence: 100%\nEvidence: FlashAttention is still 2\u00d7 more efficient than Linformer.", "to": "system:reformer", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "we compare against reference implementations of Reformer", "relation_type": "ASSOCIATED_WITH", "source_name": "FlashAttention", "target_name": "Reformer", "title": "FlashAttention ASSOCIATED_WITH Reformer\nConfidence: 100%\nEvidence: we compare against reference implementations of Reformer", "to": "system:reformer", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "system:flashattention", "full_evidence": "FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "relation_type": "SUPPORTS", "source_name": "FlashAttention", "target_name": "Reformer", "title": "FlashAttention SUPPORTS Reformer\nConfidence: 90%\nEvidence: FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "to": "system:reformer", "width": 2.25}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "FlashAttention is still 2\u00d7 more efficient than Linformer.", "relation_type": "CONTRADICTS", "source_name": "FlashAttention", "target_name": "SMYRF", "title": "FlashAttention CONTRADICTS SMYRF\nConfidence: 100%\nEvidence: FlashAttention is still 2\u00d7 more efficient than Linformer.", "to": "system:smyrf", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "we compare against reference implementations of Smyrf", "relation_type": "ASSOCIATED_WITH", "source_name": "FlashAttention", "target_name": "SMYRF", "title": "FlashAttention ASSOCIATED_WITH SMYRF\nConfidence: 100%\nEvidence: we compare against reference implementations of Smyrf", "to": "system:smyrf", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "system:flashattention", "full_evidence": "FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "relation_type": "SUPPORTS", "source_name": "FlashAttention", "target_name": "SMYRF", "title": "FlashAttention SUPPORTS SMYRF\nConfidence: 90%\nEvidence: FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "to": "system:smyrf", "width": 2.25}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.8, "from": "system:flashattention", "full_evidence": "Our IO-aware implementation of attention is optimal within constants for computing attention on a single GPU.", "relation_type": "USES_METHOD", "source_name": "FlashAttention", "target_name": "Multi-GPU IO-Aware Methods", "title": "FlashAttention USES_METHOD Multi-GPU IO-Aware Methods\nConfidence: 80%\nEvidence: Our IO-aware implementation of attention is optimal within constants for computing attention on a single GPU.", "to": "method:multi_gpu_io_aware_methods", "width": 2.0}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "designed to enhance the efficiency of Transformer models by reducing memory access and computation time, particularly for long sequences.", "relation_type": "EXPLAINS", "source_name": "FlashAttention", "target_name": "long sequences", "title": "FlashAttention EXPLAINS long sequences\nConfidence: 100%\nEvidence: designed to enhance the efficiency of Transformer models by reducing memory access and computation time, particularly for long sequences.", "to": "phenomenon:long_sequences", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "The paper highlights the algorithm\u0027s significant performance improvements over existing methods.", "relation_type": "SUPPORTS", "source_name": "FlashAttention", "target_name": "performance improvements", "title": "FlashAttention SUPPORTS performance improvements\nConfidence: 100%\nEvidence: The paper highlights the algorithm\u0027s significant performance improvements over existing methods.", "to": "finding:performance_improvements", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "We describe the FlashAttention algorithm to implement both the forward and the backward passes on GPUs that reduces HBM accesses", "relation_type": "USES_METHOD", "source_name": "FlashAttention", "target_name": "I/O complexity", "title": "FlashAttention USES_METHOD I/O complexity\nConfidence: 100%\nEvidence: We describe the FlashAttention algorithm to implement both the forward and the backward passes on GPUs that reduces HBM accesses", "to": "concept:i_o_complexity", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.8, "from": "system:flashattention", "full_evidence": "Rabe and Staats suggests that the backward pass can be done without quadratic extra memory by applying gradient checkpointing to the memory-efficient forward pass.", "relation_type": "USES_METHOD", "source_name": "FlashAttention", "target_name": "gradient checkpointing", "title": "FlashAttention USES_METHOD gradient checkpointing\nConfidence: 80%\nEvidence: Rabe and Staats suggests that the backward pass can be done without quadratic extra memory by applying gradient checkpointing to the memory-efficient ...", "to": "method:gradient_checkpointing", "width": 2.0}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "FlashAttention instead simplifies the backward pass analytically.", "relation_type": "EXTENDS", "source_name": "FlashAttention", "target_name": "standard attention", "title": "FlashAttention EXTENDS standard attention\nConfidence: 100%\nEvidence: FlashAttention instead simplifies the backward pass analytically.", "to": "method:standard_attention", "width": 2.5}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "The first major difference is that Rabe and Staats focuses on the reducing the total memory footprint while FlashAttention focuses on reducing memory accesses.", "relation_type": "CONTRADICTS", "source_name": "FlashAttention", "target_name": "Rabe and Staats", "title": "FlashAttention CONTRADICTS Rabe and Staats\nConfidence: 100%\nEvidence: The first major difference is that Rabe and Staats focuses on the reducing the total memory footprint while FlashAttention focuses on reducing memory ...", "to": "researcher:rabe_and_staats", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "FlashAttention backward pass (Algorithm 4) requires \u0398(N2d2M\u22121) HBM accesses.", "relation_type": "SUPPORTS", "source_name": "FlashAttention", "target_name": "\u0398(N2d2M\u22121)", "title": "FlashAttention SUPPORTS \u0398(N2d2M\u22121)\nConfidence: 100%\nEvidence: FlashAttention backward pass (Algorithm 4) requires \u0398(N2d2M\u22121) HBM accesses.", "to": "finding:th_n2d2m_1", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 0.9, "from": "system:flashattention", "full_evidence": "We discuss here a few potential extensions of the IO-aware approach to speed up deep learning training.", "relation_type": "USES_METHOD", "source_name": "FlashAttention", "target_name": "Multi-GPU Attention", "title": "FlashAttention USES_METHOD Multi-GPU Attention\nConfidence: 90%\nEvidence: We discuss here a few potential extensions of the IO-aware approach to speed up deep learning training.", "to": "concept:multi_gpu_attention", "width": 2.25}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "apply two well-established techniques (tiling and recomputation)", "relation_type": "USES_METHOD", "source_name": "FlashAttention", "target_name": "tiling", "title": "FlashAttention USES_METHOD tiling\nConfidence: 100%\nEvidence: apply two well-established techniques (tiling and recomputation)", "to": "method:tiling", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "apply two well-established techniques (tiling and recomputation)", "relation_type": "USES_METHOD", "source_name": "FlashAttention", "target_name": "recomputation", "title": "FlashAttention USES_METHOD recomputation\nConfidence: 100%\nEvidence: apply two well-established techniques (tiling and recomputation)", "to": "method:recomputation", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "We compare our method/implementation with Apex FMHA", "relation_type": "ASSOCIATED_WITH", "source_name": "FlashAttention", "target_name": "Apex FMHA", "title": "FlashAttention ASSOCIATED_WITH Apex FMHA\nConfidence: 100%\nEvidence: We compare our method/implementation with Apex FMHA", "to": "system:apex_fmha", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "We compare against reference implementations for exact attention from PyTorch/HuggingFace", "relation_type": "ASSOCIATED_WITH", "source_name": "FlashAttention", "target_name": "PyTorch", "title": "FlashAttention ASSOCIATED_WITH PyTorch\nConfidence: 100%\nEvidence: We compare against reference implementations for exact attention from PyTorch/HuggingFace", "to": "system:pytorch", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "we compare against reference implementations of Longformer", "relation_type": "ASSOCIATED_WITH", "source_name": "FlashAttention", "target_name": "Longformer", "title": "FlashAttention ASSOCIATED_WITH Longformer\nConfidence: 100%\nEvidence: we compare against reference implementations of Longformer", "to": "system:longformer", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "system:flashattention", "full_evidence": "FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "relation_type": "SUPPORTS", "source_name": "FlashAttention", "target_name": "Longformer", "title": "FlashAttention SUPPORTS Longformer\nConfidence: 90%\nEvidence: FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "to": "system:longformer", "width": 2.25}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:flashattention", "full_evidence": "we compare against reference implementations of BigBird Attention", "relation_type": "ASSOCIATED_WITH", "source_name": "FlashAttention", "target_name": "BigBird", "title": "FlashAttention ASSOCIATED_WITH BigBird\nConfidence: 100%\nEvidence: we compare against reference implementations of BigBird Attention", "to": "system:bigbird", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "system:flashattention", "full_evidence": "FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "relation_type": "SUPPORTS", "source_name": "FlashAttention", "target_name": "BigBird", "title": "FlashAttention SUPPORTS BigBird\nConfidence: 90%\nEvidence: FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "to": "system:bigbird", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "system:flashattention", "full_evidence": "FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "relation_type": "SUPPORTS", "source_name": "FlashAttention", "target_name": "PyTorch Attention", "title": "FlashAttention SUPPORTS PyTorch Attention\nConfidence: 90%\nEvidence: FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "to": "system:pytorch_attention", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "system:flashattention", "full_evidence": "FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "relation_type": "SUPPORTS", "source_name": "FlashAttention", "target_name": "Megatron", "title": "FlashAttention SUPPORTS Megatron\nConfidence: 90%\nEvidence: FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "to": "system:megatron", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "system:flashattention", "full_evidence": "FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "relation_type": "SUPPORTS", "source_name": "FlashAttention", "target_name": "LSformer", "title": "FlashAttention SUPPORTS LSformer\nConfidence: 90%\nEvidence: FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "to": "system:lsformer", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "system:flashattention", "full_evidence": "FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "relation_type": "SUPPORTS", "source_name": "FlashAttention", "target_name": "Block Sparse", "title": "FlashAttention SUPPORTS Block Sparse\nConfidence: 90%\nEvidence: FlashAttention 0.11 0.16 0.52 1.62 5.45 21.57 84.75 336.00 1338.56 5343.19", "to": "system:block_sparse", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.8, "from": "system:flashattention", "full_evidence": "We gratefully acknowledge the support of NIH under No. U54EB020405 (Mobilize)", "relation_type": "PROPOSED_BY", "source_name": "FlashAttention", "target_name": "NIH", "title": "FlashAttention PROPOSED_BY NIH\nConfidence: 80%\nEvidence: We gratefully acknowledge the support of NIH under No. U54EB020405 (Mobilize)", "to": "researcher:nih", "width": 2.0}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.8, "from": "system:flashattention", "full_evidence": "We gratefully acknowledge the support of NSF under Nos. CCF1763315 (Beyond Sparsity)", "relation_type": "PROPOSED_BY", "source_name": "FlashAttention", "target_name": "NSF", "title": "FlashAttention PROPOSED_BY NSF\nConfidence: 80%\nEvidence: We gratefully acknowledge the support of NSF under Nos. CCF1763315 (Beyond Sparsity)", "to": "researcher:nsf", "width": 2.0}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "method:algorithm_1", "full_evidence": "Algorithm 1 FlashAttention", "relation_type": "ASSOCIATED_WITH", "source_name": "Algorithm 1", "target_name": "FlashAttention", "title": "Algorithm 1 ASSOCIATED_WITH FlashAttention\nConfidence: 100%\nEvidence: Algorithm 1 FlashAttention", "to": "system:flashattention", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "concept:io_aware_implementations", "full_evidence": "We hope our work inspires IO-aware implementations of additional modules.", "relation_type": "EXTENDS", "source_name": "IO-aware implementations", "target_name": "FlashAttention", "title": "IO-aware implementations EXTENDS FlashAttention\nConfidence: 100%\nEvidence: We hope our work inspires IO-aware implementations of additional modules.", "to": "system:flashattention", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.9, "from": "concept:io_aware_implementations", "full_evidence": "We believe that the IO-aware approach can extend beyond attention.", "relation_type": "EXTENDS", "source_name": "IO-aware implementations", "target_name": "Transformer", "title": "IO-aware implementations EXTENDS Transformer\nConfidence: 90%\nEvidence: We believe that the IO-aware approach can extend beyond attention.", "to": "theory:transformer", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.9, "from": "concept:sparse_models", "full_evidence": "the lottery ticket hypothesis suggests that there are a set of small sub-networks derived from a larger dense network that performs as well as the original dense network", "relation_type": "SUPPORTS", "source_name": "sparse models", "target_name": "lottery ticket hypothesis", "title": "sparse models SUPPORTS lottery ticket hypothesis\nConfidence: 90%\nEvidence: the lottery ticket hypothesis suggests that there are a set of small sub-networks derived from a larger dense network that performs as well as the ori...", "to": "theory:lottery_ticket_hypothesis", "width": 2.25}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.8, "from": "method:gradient_checkpointing", "full_evidence": "Rabe and Staats suggests that the backward pass can be done without quadratic extra memory by applying gradient checkpointing.", "relation_type": "PROPOSED_BY", "source_name": "gradient checkpointing", "target_name": "Rabe and Staats", "title": "gradient checkpointing PROPOSED_BY Rabe and Staats\nConfidence: 80%\nEvidence: Rabe and Staats suggests that the backward pass can be done without quadratic extra memory by applying gradient checkpointing.", "to": "researcher:rabe_and_staats", "width": 2.0}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 0.9, "from": "method:attention_backward_pass", "full_evidence": "We now make two observations about FlashAttention backward pass.", "relation_type": "EXPLAINS", "source_name": "Attention Backward Pass", "target_name": "FlashAttention", "title": "Attention Backward Pass EXPLAINS FlashAttention\nConfidence: 90%\nEvidence: We now make two observations about FlashAttention backward pass.", "to": "system:flashattention", "width": 2.25}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "method:standard_attention", "full_evidence": "FlashAttention requires many times fewer HBM accesses than standard implementation.", "relation_type": "CONTRADICTS", "source_name": "standard attention", "target_name": "FlashAttention", "title": "standard attention CONTRADICTS FlashAttention\nConfidence: 100%\nEvidence: FlashAttention requires many times fewer HBM accesses than standard implementation.", "to": "system:flashattention", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:standard_attention", "full_evidence": "Standard attention (Algorithm 0) backward pass requires \u0398(Nd + N2) HBM accesses.", "relation_type": "SUPPORTS", "source_name": "standard attention", "target_name": "\u0398(Nd + N2)", "title": "standard attention SUPPORTS \u0398(Nd + N2)\nConfidence: 100%\nEvidence: Standard attention (Algorithm 0) backward pass requires \u0398(Nd + N2) HBM accesses.", "to": "finding:th_nd_n2", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "field:long_range_arena", "full_evidence": "We compare vanilla Transformer (with either standard implementation or FlashAttention) on the long-range arena (LRA [80]) benchmark...", "relation_type": "INVESTIGATES", "source_name": "Long-range arena", "target_name": "FlashAttention", "title": "Long-range arena INVESTIGATES FlashAttention\nConfidence: 100%\nEvidence: We compare vanilla Transformer (with either standard implementation or FlashAttention) on the long-range arena (LRA [80]) benchmark...", "to": "system:flashattention", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:apex_fmha", "full_evidence": "FMHA targets BERT models", "relation_type": "APPLIED_TO", "source_name": "Apex FMHA", "target_name": "BERT", "title": "Apex FMHA APPLIED_TO BERT\nConfidence: 100%\nEvidence: FMHA targets BERT models", "to": "system:bert", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "fine-tune our supervised learning baseline to maximize this reward using the PPO algorithm", "relation_type": "USES_METHOD", "source_name": "InstructGPT", "target_name": "proximal policy optimization", "title": "InstructGPT USES_METHOD proximal policy optimization\nConfidence: 100%\nEvidence: fine-tune our supervised learning baseline to maximize this reward using the PPO algorithm", "to": "method:proximal_policy_optimization", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "As measured by human evaluations on the TruthfulQA dataset, our PPO models show small but significant improvements in generating truthful and informative outputs compared to GPT-3.", "relation_type": "SUPPORTS", "source_name": "InstructGPT", "target_name": "TruthfulQA", "title": "InstructGPT SUPPORTS TruthfulQA\nConfidence: 100%\nEvidence: As measured by human evaluations on the TruthfulQA dataset, our PPO models show small but significant improvements in generating truthful and informat...", "to": "system:truthfulqa", "width": 2.5}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "we observe performance regressions compared to GPT-3 on certain public NLP datasets, notably SQuAD", "relation_type": "CONTRADICTS", "source_name": "InstructGPT", "target_name": "SQuAD", "title": "InstructGPT CONTRADICTS SQuAD\nConfidence: 100%\nEvidence: we observe performance regressions compared to GPT-3 on certain public NLP datasets, notably SQuAD", "to": "system:squad", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "The performance of the PPO-ptx model still lags behind GPT-3 on DROP, SQuAD v2, and translation; more work is needed to study and further eliminate these performance regressions.", "relation_type": "APPLIED_TO", "source_name": "InstructGPT", "target_name": "SQuAD", "title": "InstructGPT APPLIED_TO SQuAD\nConfidence: 100%\nEvidence: The performance of the PPO-ptx model still lags behind GPT-3 on DROP, SQuAD v2, and translation; more work is needed to study and further eliminate th...", "to": "system:squad", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "Our initial RLHF experiments showed regressions on public NLP datasets, such as SQuAD v2.", "relation_type": "SUPPORTS", "source_name": "InstructGPT", "target_name": "SQuAD", "title": "InstructGPT SUPPORTS SQuAD\nConfidence: 100%\nEvidence: Our initial RLHF experiments showed regressions on public NLP datasets, such as SQuAD v2.", "to": "system:squad", "width": 2.5}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "labelers significantly prefer InstructGPT to these models", "relation_type": "CONTRADICTS", "source_name": "InstructGPT", "target_name": "FLAN", "title": "InstructGPT CONTRADICTS FLAN\nConfidence: 100%\nEvidence: labelers significantly prefer InstructGPT to these models", "to": "system:flan", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "We compare InstructGPT to our 175B GPT-3 baselines fine-tuned on the FLAN dataset.", "relation_type": "SUPPORTS", "source_name": "InstructGPT", "target_name": "FLAN", "title": "InstructGPT SUPPORTS FLAN\nConfidence: 100%\nEvidence: We compare InstructGPT to our 175B GPT-3 baselines fine-tuned on the FLAN dataset.", "to": "system:flan", "width": 2.5}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "labelers significantly prefer InstructGPT to these models", "relation_type": "CONTRADICTS", "source_name": "InstructGPT", "target_name": "T0", "title": "InstructGPT CONTRADICTS T0\nConfidence: 100%\nEvidence: labelers significantly prefer InstructGPT to these models", "to": "system:t0", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "We compare InstructGPT to our 175B GPT-3 baselines fine-tuned on the T0 dataset.", "relation_type": "SUPPORTS", "source_name": "InstructGPT", "target_name": "T0", "title": "InstructGPT SUPPORTS T0\nConfidence: 100%\nEvidence: We compare InstructGPT to our 175B GPT-3 baselines fine-tuned on the T0 dataset.", "to": "system:t0", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "The document is a research paper authored by a team from OpenAI, including key contributors like Long Ouyang.", "relation_type": "PROPOSED_BY", "source_name": "InstructGPT", "target_name": "Long Ouyang", "title": "InstructGPT PROPOSED_BY Long Ouyang\nConfidence: 100%\nEvidence: The document is a research paper authored by a team from OpenAI, including key contributors like Long Ouyang.", "to": "researcher:long_ouyang", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "The document is a research paper authored by a team from OpenAI, including key contributors like Jeff Wu.", "relation_type": "PROPOSED_BY", "source_name": "InstructGPT", "target_name": "Jeff Wu", "title": "InstructGPT PROPOSED_BY Jeff Wu\nConfidence: 100%\nEvidence: The document is a research paper authored by a team from OpenAI, including key contributors like Jeff Wu.", "to": "researcher:jeff_wu", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "The document is a research paper authored by a team from OpenAI, including key contributors like Paul Christiano.", "relation_type": "PROPOSED_BY", "source_name": "InstructGPT", "target_name": "Paul Christiano", "title": "InstructGPT PROPOSED_BY Paul Christiano\nConfidence: 100%\nEvidence: The document is a research paper authored by a team from OpenAI, including key contributors like Paul Christiano.", "to": "researcher:paul_christiano", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "We apply our default training method for PPO with pretraining mix.", "relation_type": "USES_METHOD", "source_name": "InstructGPT", "target_name": "PPO", "title": "InstructGPT USES_METHOD PPO\nConfidence: 100%\nEvidence: We apply our default training method for PPO with pretraining mix.", "to": "method:ppo", "width": 2.5}, {"arrows": "to", "color": "#FFA726", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "InstructGPT utilizes reinforcement learning from human feedback.", "relation_type": "IMPLEMENTS", "source_name": "InstructGPT", "target_name": "reinforcement learning", "title": "InstructGPT IMPLEMENTS reinforcement learning\nConfidence: 100%\nEvidence: InstructGPT utilizes reinforcement learning from human feedback.", "to": "method:reinforcement_learning", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "InstructGPT utilizes reinforcement learning from human feedback.", "relation_type": "USES_METHOD", "source_name": "InstructGPT", "target_name": "reinforcement learning", "title": "InstructGPT USES_METHOD reinforcement learning\nConfidence: 100%\nEvidence: InstructGPT utilizes reinforcement learning from human feedback.", "to": "method:reinforcement_learning", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "This research is part of our broader research program to align AI systems with human intentions.", "relation_type": "SUPPORTS", "source_name": "InstructGPT", "target_name": "reinforcement learning", "title": "InstructGPT SUPPORTS reinforcement learning\nConfidence: 100%\nEvidence: This research is part of our broader research program to align AI systems with human intentions.", "to": "method:reinforcement_learning", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "We fine-tune GPT-3 on our labeler demonstrations using supervised learning.", "relation_type": "USES_METHOD", "source_name": "InstructGPT", "target_name": "supervised learning", "title": "InstructGPT USES_METHOD supervised learning\nConfidence: 100%\nEvidence: We fine-tune GPT-3 on our labeler demonstrations using supervised learning.", "to": "method:supervised_learning", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "InstructGPT outputs are less likely to \u0027hallucinate\u0027 (meaning, making up information on closed domain tasks)", "relation_type": "SUPPORTS", "source_name": "InstructGPT", "target_name": "hallucinations", "title": "InstructGPT SUPPORTS hallucinations\nConfidence: 100%\nEvidence: InstructGPT outputs are less likely to \u0027hallucinate\u0027 (meaning, making up information on closed domain tasks)", "to": "finding:hallucinations", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "The performance of the PPO-ptx model still lags behind GPT-3 on DROP, SQuAD v2, and translation; more work is needed to study and further eliminate these performance regressions.", "relation_type": "APPLIED_TO", "source_name": "InstructGPT", "target_name": "HellaSwag", "title": "InstructGPT APPLIED_TO HellaSwag\nConfidence: 100%\nEvidence: The performance of the PPO-ptx model still lags behind GPT-3 on DROP, SQuAD v2, and translation; more work is needed to study and further eliminate th...", "to": "system:hellaswag", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "The performance of the PPO-ptx model still lags behind GPT-3 on DROP, SQuAD v2, and translation; more work is needed to study and further eliminate these performance regressions.", "relation_type": "APPLIED_TO", "source_name": "InstructGPT", "target_name": "DROP", "title": "InstructGPT APPLIED_TO DROP\nConfidence: 100%\nEvidence: The performance of the PPO-ptx model still lags behind GPT-3 on DROP, SQuAD v2, and translation; more work is needed to study and further eliminate th...", "to": "system:drop", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "Our initial RLHF experiments showed regressions on public NLP datasets, such as DROP.", "relation_type": "SUPPORTS", "source_name": "InstructGPT", "target_name": "DROP", "title": "InstructGPT SUPPORTS DROP\nConfidence: 100%\nEvidence: Our initial RLHF experiments showed regressions on public NLP datasets, such as DROP.", "to": "system:drop", "width": 2.5}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "they still generate toxic or biased outputs", "relation_type": "CONTRADICTS", "source_name": "InstructGPT", "target_name": "toxic outputs", "title": "InstructGPT CONTRADICTS toxic outputs\nConfidence: 100%\nEvidence: they still generate toxic or biased outputs", "to": "finding:toxic_outputs", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "The findings indicate that InstructGPT outperforms the original GPT-3 model in various evaluations.", "relation_type": "SUPPORTS", "source_name": "InstructGPT", "target_name": "truthfulness", "title": "InstructGPT SUPPORTS truthfulness\nConfidence: 100%\nEvidence: The findings indicate that InstructGPT outperforms the original GPT-3 model in various evaluations.", "to": "phenomenon:truthfulness", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "reduce toxicity, and improve truthfulness in outputs.", "relation_type": "SUPPORTS", "source_name": "InstructGPT", "target_name": "toxicity", "title": "InstructGPT SUPPORTS toxicity\nConfidence: 100%\nEvidence: reduce toxicity, and improve truthfulness in outputs.", "to": "concept:toxicity", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "InstructGPT enhances its ability to follow instructions, reduce toxicity, and improve truthfulness in outputs.", "relation_type": "SUPPORTS", "source_name": "InstructGPT", "target_name": "toxicity reduction", "title": "InstructGPT SUPPORTS toxicity reduction\nConfidence: 100%\nEvidence: InstructGPT enhances its ability to follow instructions, reduce toxicity, and improve truthfulness in outputs.", "to": "finding:toxicity_reduction", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "InstructGPT enhances its ability to follow instructions, reduce toxicity, and improve truthfulness in outputs.", "relation_type": "SUPPORTS", "source_name": "InstructGPT", "target_name": "truthfulness improvement", "title": "InstructGPT SUPPORTS truthfulness improvement\nConfidence: 100%\nEvidence: InstructGPT enhances its ability to follow instructions, reduce toxicity, and improve truthfulness in outputs.", "to": "finding:truthfulness_improvement", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "InstructGPT outperforms the original GPT-3 model in various evaluations.", "relation_type": "SUPPORTS", "source_name": "InstructGPT", "target_name": "GPT-2", "title": "InstructGPT SUPPORTS GPT-2\nConfidence: 100%\nEvidence: InstructGPT outperforms the original GPT-3 model in various evaluations.", "to": "system:gpt_2", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "InstructGPT outperforms the original GPT-3 model in various evaluations.", "relation_type": "EXTENDS", "source_name": "InstructGPT", "target_name": "GPT-2", "title": "InstructGPT EXTENDS GPT-2\nConfidence: 100%\nEvidence: InstructGPT outperforms the original GPT-3 model in various evaluations.", "to": "system:gpt_2", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "We experimented with a few variants of the SFT models.", "relation_type": "USES_METHOD", "source_name": "InstructGPT", "target_name": "SFT", "title": "InstructGPT USES_METHOD SFT\nConfidence: 100%\nEvidence: We experimented with a few variants of the SFT models.", "to": "method:sft", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "the organization behind the development of InstructGPT", "relation_type": "PROPOSED_BY", "source_name": "InstructGPT", "target_name": "OpenAI", "title": "InstructGPT PROPOSED_BY OpenAI\nConfidence: 100%\nEvidence: the organization behind the development of InstructGPT", "to": "researcher:openai", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "we asked labelers to write prompts themselves.", "relation_type": "PROPOSED_BY", "source_name": "InstructGPT", "target_name": "labeler", "title": "InstructGPT PROPOSED_BY labeler\nConfidence: 100%\nEvidence: we asked labelers to write prompts themselves.", "to": "researcher:labeler", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "We first evaluate our models on the RealToxicityPrompts dataset.", "relation_type": "SUPPORTS", "source_name": "InstructGPT", "target_name": "RealToxicity Prompts", "title": "InstructGPT SUPPORTS RealToxicity Prompts\nConfidence: 100%\nEvidence: We first evaluate our models on the RealToxicityPrompts dataset.", "to": "system:realtoxicity_prompts", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:instructgpt", "full_evidence": "All models are trained with the Adam optimizer.", "relation_type": "USES_METHOD", "source_name": "InstructGPT", "target_name": "Adam", "title": "InstructGPT USES_METHOD Adam\nConfidence: 100%\nEvidence: All models are trained with the Adam optimizer.", "to": "method:adam", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "concept:alignment", "full_evidence": "our aim is to train models that act in accordance with user intentions", "relation_type": "EXPLAINS", "source_name": "alignment", "target_name": "InstructGPT", "title": "alignment EXPLAINS InstructGPT\nConfidence: 100%\nEvidence: our aim is to train models that act in accordance with user intentions", "to": "system:instructgpt", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "publication:stiennon_et_al_2020", "full_evidence": "we follow Stiennon et al. (2020) in our approach.", "relation_type": "SUPPORTS", "source_name": "Stiennon et al. (2020)", "target_name": "InstructGPT", "title": "Stiennon et al. (2020) SUPPORTS InstructGPT\nConfidence: 100%\nEvidence: we follow Stiennon et al. (2020) in our approach.", "to": "system:instructgpt", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "publication:ziegler_et_al_2019", "full_evidence": "compared to earlier work that collects human preference data on the task of summarization.", "relation_type": "SUPPORTS", "source_name": "Ziegler et al. (2019)", "target_name": "InstructGPT", "title": "Ziegler et al. (2019) SUPPORTS InstructGPT\nConfidence: 100%\nEvidence: compared to earlier work that collects human preference data on the task of summarization.", "to": "system:instructgpt", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "publication:brown_et_al_2020", "full_evidence": "we start with the GPT-3 pretrained language models from Brown et al. (2020).", "relation_type": "SUPPORTS", "source_name": "Brown et al. (2020)", "target_name": "InstructGPT", "title": "Brown et al. (2020) SUPPORTS InstructGPT\nConfidence: 100%\nEvidence: we start with the GPT-3 pretrained language models from Brown et al. (2020).", "to": "system:instructgpt", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "method:sft", "full_evidence": "We experimented with a few variants of the SFT models.", "relation_type": "APPLIED_TO", "source_name": "SFT", "target_name": "InstructGPT", "title": "SFT APPLIED_TO InstructGPT\nConfidence: 100%\nEvidence: We experimented with a few variants of the SFT models.", "to": "system:instructgpt", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 0.7, "from": "concept:alignment_tax", "full_evidence": "Gabriel (2020) advocate for a principle-based approach to alignment...", "relation_type": "PROPOSED_BY", "source_name": "alignment tax", "target_name": "Gabriel", "title": "alignment tax PROPOSED_BY Gabriel\nConfidence: 70%\nEvidence: Gabriel (2020) advocate for a principle-based approach to alignment...", "to": "researcher:gabriel", "width": 1.75}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "concept:alignment_techniques", "full_evidence": "we have aligned to a set of labelers\u2019 preferences", "relation_type": "EXPLAINS", "source_name": "alignment techniques", "target_name": "human preferences", "title": "alignment techniques EXPLAINS human preferences\nConfidence: 100%\nEvidence: we have aligned to a set of labelers\u2019 preferences", "to": "phenomenon:human_preferences", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "concept:alignment_with_user_intent", "full_evidence": "focusing on improving language models\u0027 alignment with user intent through human feedback.", "relation_type": "APPLIED_TO", "source_name": "alignment with user intent", "target_name": "InstructGPT", "title": "alignment with user intent APPLIED_TO InstructGPT\nConfidence: 100%\nEvidence: focusing on improving language models\u0027 alignment with user intent through human feedback.", "to": "system:instructgpt", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "system:realtoxicity_prompts", "full_evidence": "In the RealToxicity Prompts task, we measure toxicity via the Perspective API.", "relation_type": "INVESTIGATES", "source_name": "RealToxicity Prompts", "target_name": "toxicity", "title": "RealToxicity Prompts INVESTIGATES toxicity\nConfidence: 100%\nEvidence: In the RealToxicity Prompts task, we measure toxicity via the Perspective API.", "to": "concept:toxicity", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "Key participants include Hugo Touvron, Thibaut Lavril, Gautier Izacard, and several others.", "relation_type": "PROPOSED_BY", "source_name": "LLaMA", "target_name": "Hugo Touvron", "title": "LLaMA PROPOSED_BY Hugo Touvron\nConfidence: 100%\nEvidence: Key participants include Hugo Touvron, Thibaut Lavril, Gautier Izacard, and several others.", "to": "researcher:hugo_touvron", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "Key participants include Hugo Touvron, Thibaut Lavril, Gautier Izacard, and several others.", "relation_type": "PROPOSED_BY", "source_name": "LLaMA", "target_name": "Thibaut Lavril", "title": "LLaMA PROPOSED_BY Thibaut Lavril\nConfidence: 100%\nEvidence: Key participants include Hugo Touvron, Thibaut Lavril, Gautier Izacard, and several others.", "to": "researcher:thibaut_lavril", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "Key participants include Hugo Touvron, Thibaut Lavril, Gautier Izacard, and several others.", "relation_type": "PROPOSED_BY", "source_name": "LLaMA", "target_name": "Gautier Izacard", "title": "LLaMA PROPOSED_BY Gautier Izacard\nConfidence: 100%\nEvidence: Key participants include Hugo Touvron, Thibaut Lavril, Gautier Izacard, and several others.", "to": "researcher:gautier_izacard", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "Our models are trained using the AdamW optimizer (Loshchilov and Hutter, 2017)", "relation_type": "USES_METHOD", "source_name": "LLaMA", "target_name": "AdamW optimizer", "title": "LLaMA USES_METHOD AdamW optimizer\nConfidence: 100%\nEvidence: Our models are trained using the AdamW optimizer (Loshchilov and Hutter, 2017)", "to": "method:adamw_optimizer", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "We include the publicly available C4 dataset (Raffel et al., 2020) in our data.", "relation_type": "APPLIED_TO", "source_name": "LLaMA", "target_name": "C4", "title": "LLaMA APPLIED_TO C4\nConfidence: 100%\nEvidence: We include the publicly available C4 dataset (Raffel et al., 2020) in our data.", "to": "system:c4", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "We add Wikipedia dumps from the June-August 2022 period.", "relation_type": "APPLIED_TO", "source_name": "LLaMA", "target_name": "Wikipedia", "title": "LLaMA APPLIED_TO Wikipedia\nConfidence: 100%\nEvidence: We add Wikipedia dumps from the June-August 2022 period.", "to": "system:wikipedia", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "We tokenize the data with the byte-pair encoding (BPE) algorithm (Sennrich et al., 2015)", "relation_type": "USES_METHOD", "source_name": "LLaMA", "target_name": "BPE algorithm", "title": "LLaMA USES_METHOD BPE algorithm\nConfidence: 100%\nEvidence: We tokenize the data with the byte-pair encoding (BPE) algorithm (Sennrich et al., 2015)", "to": "method:bpe_algorithm", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "We consider eight standard common sense reasoning benchmarks.", "relation_type": "SUPPORTS", "source_name": "LLaMA", "target_name": "CommonSense Reasoning", "title": "LLaMA SUPPORTS CommonSense Reasoning\nConfidence: 100%\nEvidence: We consider eight standard common sense reasoning benchmarks.", "to": "phenomenon:commonsense_reasoning", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "Our models are trained using the AdamW optimizer.", "relation_type": "USES_METHOD", "source_name": "LLaMA", "target_name": "AdamW", "title": "LLaMA USES_METHOD AdamW\nConfidence: 100%\nEvidence: Our models are trained using the AdamW optimizer.", "to": "method:adamw", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "We replace the ReLU non-linearity by the SwiGLU activation function.", "relation_type": "USES_METHOD", "source_name": "LLaMA", "target_name": "SwiGLU", "title": "LLaMA USES_METHOD SwiGLU\nConfidence: 100%\nEvidence: We replace the ReLU non-linearity by the SwiGLU activation function.", "to": "method:swiglu", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "We add rotary positional embeddings (RoPE), introduced by Su et al. (2021).", "relation_type": "USES_METHOD", "source_name": "LLaMA", "target_name": "Rotary Positional Embeddings (RoPE)", "title": "LLaMA USES_METHOD Rotary Positional Embeddings (RoPE)\nConfidence: 100%\nEvidence: We add rotary positional embeddings (RoPE), introduced by Su et al. (2021).", "to": "method:rotary_positional_embeddings_rope", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval.", "relation_type": "APPLIED_TO", "source_name": "LLaMA", "target_name": "HumanEval", "title": "LLaMA APPLIED_TO HumanEval\nConfidence: 100%\nEvidence: We evaluate the ability of our models to write code from a natural language description on two benchmarks: HumanEval.", "to": "system:humaneval", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "We report the pass@ score on HumanEval and MBPP.", "relation_type": "EXPLAINS", "source_name": "LLaMA", "target_name": "HumanEval", "title": "LLaMA EXPLAINS HumanEval\nConfidence: 100%\nEvidence: We report the pass@ score on HumanEval and MBPP.", "to": "system:humaneval", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "We evaluate the ability of our models to write code from a natural language description on two benchmarks: MBPP.", "relation_type": "APPLIED_TO", "source_name": "LLaMA", "target_name": "MBPP", "title": "LLaMA APPLIED_TO MBPP\nConfidence: 100%\nEvidence: We evaluate the ability of our models to write code from a natural language description on two benchmarks: MBPP.", "to": "system:mbpp", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "We report the pass@ score on HumanEval and MBPP.", "relation_type": "EXPLAINS", "source_name": "LLaMA", "target_name": "MBPP", "title": "LLaMA EXPLAINS MBPP\nConfidence: 100%\nEvidence: We report the pass@ score on HumanEval and MBPP.", "to": "system:mbpp", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "We evaluate our models on two mathematical reasoning benchmarks: MATH.", "relation_type": "APPLIED_TO", "source_name": "LLaMA", "target_name": "MATH", "title": "LLaMA APPLIED_TO MATH\nConfidence: 100%\nEvidence: We evaluate our models on two mathematical reasoning benchmarks: MATH.", "to": "system:math", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "We evaluate our models on two mathematical reasoning benchmarks: GSM8k.", "relation_type": "APPLIED_TO", "source_name": "LLaMA", "target_name": "GSM8K", "title": "LLaMA APPLIED_TO GSM8K\nConfidence: 100%\nEvidence: We evaluate our models on two mathematical reasoning benchmarks: GSM8k.", "to": "system:gsm8k", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "Most notably, LLaMA-13B outperforms GPT-3 while being more than 10\u00d7 smaller.", "relation_type": "SUPPORTS", "source_name": "LLaMA", "target_name": "GPT-2", "title": "LLaMA SUPPORTS GPT-2\nConfidence: 100%\nEvidence: Most notably, LLaMA-13B outperforms GPT-3 while being more than 10\u00d7 smaller.", "to": "system:gpt_2", "width": 2.5}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 0.8, "from": "system:llama", "full_evidence": "LLaMA compares slightly favorably to both models on average.", "relation_type": "CONTRADICTS", "source_name": "LLaMA", "target_name": "GPT-2", "title": "LLaMA CONTRADICTS GPT-2\nConfidence: 80%\nEvidence: LLaMA compares slightly favorably to both models on average.", "to": "system:gpt_2", "width": 2.0}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "LLaMA-65B is competitive with Chinchilla-70B and PaLM-540B.", "relation_type": "SUPPORTS", "source_name": "LLaMA", "target_name": "Chinchilla", "title": "LLaMA SUPPORTS Chinchilla\nConfidence: 100%\nEvidence: LLaMA-65B is competitive with Chinchilla-70B and PaLM-540B.", "to": "system:chinchilla", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "LLaMA-65B is competitive with Chinchilla-70B and PaLM-540B.", "relation_type": "SUPPORTS", "source_name": "LLaMA", "target_name": "PaLM", "title": "LLaMA SUPPORTS PaLM\nConfidence: 100%\nEvidence: LLaMA-65B is competitive with Chinchilla-70B and PaLM-540B.", "to": "system:palm", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "In this section, we show that briefly finetuning on LLaMA-I (65B) outperforms existing instruction finetuned models of moderate sizes.", "relation_type": "SUPPORTS", "source_name": "LLaMA", "target_name": "MMLU", "title": "LLaMA SUPPORTS MMLU\nConfidence: 100%\nEvidence: In this section, we show that briefly finetuning on LLaMA-I (65B) outperforms existing instruction finetuned models of moderate sizes.", "to": "system:mmlu", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.8, "from": "system:llama", "full_evidence": "we look at the WinoGender benchmark (Rudinger et al., 2018), a co-reference resolution dataset.", "relation_type": "SUPPORTS", "source_name": "LLaMA", "target_name": "WinoGender", "title": "LLaMA SUPPORTS WinoGender\nConfidence: 80%\nEvidence: we look at the WinoGender benchmark (Rudinger et al., 2018), a co-reference resolution dataset.", "to": "system:winogender", "width": 2.0}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.8, "from": "system:llama", "full_evidence": "We evaluate the biases in our model on the CrowS-Pairs (Nangia et al., 2020).", "relation_type": "SUPPORTS", "source_name": "LLaMA", "target_name": "CrowS-Pairs", "title": "LLaMA SUPPORTS CrowS-Pairs\nConfidence: 80%\nEvidence: We evaluate the biases in our model on the CrowS-Pairs (Nangia et al., 2020).", "to": "system:crows_pairs", "width": 2.0}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 0.8, "from": "system:llama", "full_evidence": "TruthfulQA (Lin et al., 2021) aims to measure the truthfulness of a model.", "relation_type": "SUPPORTS", "source_name": "LLaMA", "target_name": "TruthfulQA", "title": "LLaMA SUPPORTS TruthfulQA\nConfidence: 80%\nEvidence: TruthfulQA (Lin et al., 2021) aims to measure the truthfulness of a model.", "to": "system:truthfulqa", "width": 2.0}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 0.8, "from": "system:llama", "full_evidence": "LLaMA compares slightly favorably to both models on average.", "relation_type": "CONTRADICTS", "source_name": "LLaMA", "target_name": "OPT-175B", "title": "LLaMA CONTRADICTS OPT-175B\nConfidence: 80%\nEvidence: LLaMA compares slightly favorably to both models on average.", "to": "system:opt_175b", "width": 2.0}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "Heafield et al. (2013) later showed how to scale Kneser-Ney smoothing to Web-scale data.", "relation_type": "USES_METHOD", "source_name": "LLaMA", "target_name": "Kneser-Ney smoothing", "title": "LLaMA USES_METHOD Kneser-Ney smoothing\nConfidence: 100%\nEvidence: Heafield et al. (2013) later showed how to scale Kneser-Ney smoothing to Web-scale data.", "to": "method:kneser_ney_smoothing", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "While this work relied on a simple smoothing technique, called Stupid Backoff.", "relation_type": "USES_METHOD", "source_name": "LLaMA", "target_name": "Stupid Backoff", "title": "LLaMA USES_METHOD Stupid Backoff\nConfidence: 100%\nEvidence: While this work relied on a simple smoothing technique, called Stupid Backoff.", "to": "method:stupid_backoff", "width": 2.5}, {"arrows": "to", "color": "#FFA726", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "We evaluate LLaMA on Natural Questions and TriviaQA.", "relation_type": "IMPLEMENTS", "source_name": "LLaMA", "target_name": "Natural Questions", "title": "LLaMA IMPLEMENTS Natural Questions\nConfidence: 100%\nEvidence: We evaluate LLaMA on Natural Questions and TriviaQA.", "to": "system:natural_questions", "width": 2.5}, {"arrows": "to", "color": "#FFA726", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "We evaluate LLaMA on Natural Questions and TriviaQA.", "relation_type": "IMPLEMENTS", "source_name": "LLaMA", "target_name": "TriviaQA", "title": "LLaMA IMPLEMENTS TriviaQA\nConfidence: 100%\nEvidence: We evaluate LLaMA on Natural Questions and TriviaQA.", "to": "system:triviaqa", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "We generate answers using greedy decoding.", "relation_type": "USES_METHOD", "source_name": "LLaMA", "target_name": "greedy decoding", "title": "LLaMA USES_METHOD greedy decoding\nConfidence: 100%\nEvidence: We generate answers using greedy decoding.", "to": "method:greedy_decoding", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "Generated answers are evaluated with the standard exact match metric.", "relation_type": "USES_METHOD", "source_name": "LLaMA", "target_name": "exact match metric", "title": "LLaMA USES_METHOD exact match metric\nConfidence: 100%\nEvidence: Generated answers are evaluated with the standard exact match metric.", "to": "method:exact_match_metric", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "Our training approach is similar to the methods described in previous work (Brown et al., 2020; Chowdhery et al., 2022), and is inspired by the Chinchilla scaling laws (Hoffmann et al., 2022).", "relation_type": "APPLIED_TO", "source_name": "LLaMA", "target_name": "Common Crawl", "title": "LLaMA APPLIED_TO Common Crawl\nConfidence: 100%\nEvidence: Our training approach is similar to the methods described in previous work (Brown et al., 2020; Chowdhery et al., 2022), and is inspired by the Chinch...", "to": "system:common_crawl", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:llama", "full_evidence": "To understand the potential harm of LLaMA-65B, we evaluate on different benchmarks that measure toxic content production and stereotypes detection.", "relation_type": "ASSOCIATED_WITH", "source_name": "LLaMA", "target_name": "RealToxicity Prompts", "title": "LLaMA ASSOCIATED_WITH RealToxicity Prompts\nConfidence: 100%\nEvidence: To understand the potential harm of LLaMA-65B, we evaluate on different benchmarks that measure toxic content production and stereotypes detection.", "to": "system:realtoxicity_prompts", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "The document is a research paper presented at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) by authors Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn", "relation_type": "PROPOSED_BY", "source_name": "Direct Preference Optimization", "target_name": "Rafael Rafailov", "title": "Direct Preference Optimization PROPOSED_BY Rafael Rafailov\nConfidence: 100%\nEvidence: The document is a research paper presented at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) by authors Rafael Rafailov, ...", "to": "researcher:rafael_rafailov", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "The document is a research paper presented at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) by authors Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn", "relation_type": "PROPOSED_BY", "source_name": "Direct Preference Optimization", "target_name": "Archit Sharma", "title": "Direct Preference Optimization PROPOSED_BY Archit Sharma\nConfidence: 100%\nEvidence: The document is a research paper presented at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) by authors Rafael Rafailov, ...", "to": "researcher:archit_sharma", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "The document is a research paper presented at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) by authors Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn", "relation_type": "PROPOSED_BY", "source_name": "Direct Preference Optimization", "target_name": "Eric Mitchell", "title": "Direct Preference Optimization PROPOSED_BY Eric Mitchell\nConfidence: 100%\nEvidence: The document is a research paper presented at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) by authors Rafael Rafailov, ...", "to": "researcher:eric_mitchell", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "The document is a research paper presented at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) by authors Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn", "relation_type": "PROPOSED_BY", "source_name": "Direct Preference Optimization", "target_name": "Stefano Ermon", "title": "Direct Preference Optimization PROPOSED_BY Stefano Ermon\nConfidence: 100%\nEvidence: The document is a research paper presented at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) by authors Rafael Rafailov, ...", "to": "researcher:stefano_ermon", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "The document is a research paper presented at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) by authors Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn", "relation_type": "PROPOSED_BY", "source_name": "Direct Preference Optimization", "target_name": "Christopher D. Manning", "title": "Direct Preference Optimization PROPOSED_BY Christopher D. Manning\nConfidence: 100%\nEvidence: The document is a research paper presented at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) by authors Rafael Rafailov, ...", "to": "researcher:christopher_d_manning", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "The document is a research paper presented at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) by authors Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn", "relation_type": "PROPOSED_BY", "source_name": "Direct Preference Optimization", "target_name": "Chelsea Finn", "title": "Direct Preference Optimization PROPOSED_BY Chelsea Finn\nConfidence: 100%\nEvidence: The document is a research paper presented at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) by authors Rafael Rafailov, ...", "to": "researcher:chelsea_finn", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "DPO... enables training a language model to satisfy human preferences directly.", "relation_type": "SUPPORTS", "source_name": "Direct Preference Optimization", "target_name": "human preferences", "title": "Direct Preference Optimization SUPPORTS human preferences\nConfidence: 100%\nEvidence: DPO... enables training a language model to satisfy human preferences directly.", "to": "phenomenon:human_preferences", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "optimizing them based on human preferences", "relation_type": "EXPLAINS", "source_name": "Direct Preference Optimization", "target_name": "human preferences", "title": "Direct Preference Optimization EXPLAINS human preferences\nConfidence: 100%\nEvidence: optimizing them based on human preferences", "to": "phenomenon:human_preferences", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.9, "from": "method:direct_preference_optimization", "full_evidence": "we evaluate fine-tuning performance of DPO on summarization...", "relation_type": "APPLIED_TO", "source_name": "Direct Preference Optimization", "target_name": "TL;DR summarization dataset", "title": "Direct Preference Optimization APPLIED_TO TL;DR summarization dataset\nConfidence: 90%\nEvidence: we evaluate fine-tuning performance of DPO on summarization...", "to": "system:tl_dr_summarization_dataset", "width": 2.25}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.9, "from": "method:direct_preference_optimization", "full_evidence": "we evaluate the different methods on the subset of the test split of the Anthropic HH dataset...", "relation_type": "APPLIED_TO", "source_name": "Direct Preference Optimization", "target_name": "Anthropic HH dataset", "title": "Direct Preference Optimization APPLIED_TO Anthropic HH dataset\nConfidence: 90%\nEvidence: we evaluate the different methods on the subset of the test split of the Anthropic HH dataset...", "to": "system:anthropic_hh_dataset", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "DPO performs similarly or better than existing RLHF algorithms, including those based on PPO.", "relation_type": "SUPPORTS", "source_name": "Direct Preference Optimization", "target_name": "PPO", "title": "Direct Preference Optimization SUPPORTS PPO\nConfidence: 100%\nEvidence: DPO performs similarly or better than existing RLHF algorithms, including those based on PPO.", "to": "method:ppo", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "design iterations for GPT-4 evaluation (particularly summarization);", "relation_type": "ASSOCIATED_WITH", "source_name": "Direct Preference Optimization", "target_name": "GPT-2", "title": "Direct Preference Optimization ASSOCIATED_WITH GPT-2\nConfidence: 100%\nEvidence: design iterations for GPT-4 evaluation (particularly summarization);", "to": "system:gpt_2", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "A key component of our experimental setup is GPT-4 winrate judgments.", "relation_type": "APPLIED_TO", "source_name": "Direct Preference Optimization", "target_name": "GPT-2", "title": "Direct Preference Optimization APPLIED_TO GPT-2\nConfidence: 100%\nEvidence: A key component of our experimental setup is GPT-4 winrate judgments.", "to": "system:gpt_2", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.8, "from": "method:direct_preference_optimization", "full_evidence": "We can further expand on these results.", "relation_type": "EXTENDS", "source_name": "Direct Preference Optimization", "target_name": "KL-Constrained Reward Maximization Objective", "title": "Direct Preference Optimization EXTENDS KL-Constrained Reward Maximization Objective\nConfidence: 80%\nEvidence: We can further expand on these results.", "to": "concept:kl_constrained_reward_maximization_objective", "width": 2.0}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.9, "from": "method:direct_preference_optimization", "full_evidence": "Deriving the DPO Objective Under the Bradley-Terry Model", "relation_type": "EXTENDS", "source_name": "Direct Preference Optimization", "target_name": "Bradley-Terry model", "title": "Direct Preference Optimization EXTENDS Bradley-Terry model\nConfidence: 90%\nEvidence: Deriving the DPO Objective Under the Bradley-Terry Model", "to": "theory:bradley_terry_model", "width": 2.25}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "our procedure is equivalent to fitting a parametrized Bradley-Terry model.", "relation_type": "SUPPORTS", "source_name": "Direct Preference Optimization", "target_name": "Bradley-Terry model", "title": "Direct Preference Optimization SUPPORTS Bradley-Terry model\nConfidence: 100%\nEvidence: our procedure is equivalent to fitting a parametrized Bradley-Terry model.", "to": "theory:bradley_terry_model", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 0.9, "from": "method:direct_preference_optimization", "full_evidence": "Deriving the DPO Objective Under the Plackett-Luce Model", "relation_type": "EXTENDS", "source_name": "Direct Preference Optimization", "target_name": "Plackett-Luce models", "title": "Direct Preference Optimization EXTENDS Plackett-Luce models\nConfidence: 90%\nEvidence: Deriving the DPO Objective Under the Plackett-Luce Model", "to": "theory:plackett_luce_models", "width": 2.25}, {"arrows": "to", "color": "#FFA726", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "PyTorch code for the DPO loss is provided below:", "relation_type": "IMPLEMENTS", "source_name": "Direct Preference Optimization", "target_name": "DPO loss", "title": "Direct Preference Optimization IMPLEMENTS DPO loss\nConfidence: 100%\nEvidence: PyTorch code for the DPO loss is provided below:", "to": "method:dpo_loss", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "The prompts are prefixes from the IMDB dataset of length 2-8 tokens.", "relation_type": "APPLIED_TO", "source_name": "Direct Preference Optimization", "target_name": "IMDB dataset", "title": "Direct Preference Optimization APPLIED_TO IMDB dataset\nConfidence: 100%\nEvidence: The prompts are prefixes from the IMDB dataset of length 2-8 tokens.", "to": "system:imdb_dataset", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "The document is a research paper presented at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) by authors Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn from Stanford University...", "relation_type": "PROPOSED_BY", "source_name": "Direct Preference Optimization", "target_name": "Stanford University", "title": "Direct Preference Optimization PROPOSED_BY Stanford University\nConfidence: 100%\nEvidence: The document is a research paper presented at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) by authors Rafael Rafailov, ...", "to": "field:stanford_university", "width": 2.5}, {"arrows": "to", "color": "#26C6DA", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "The document is a research paper presented at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) by authors Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, and Chelsea Finn from... CZ Biohub.", "relation_type": "PROPOSED_BY", "source_name": "Direct Preference Optimization", "target_name": "CZ Biohub", "title": "Direct Preference Optimization PROPOSED_BY CZ Biohub\nConfidence: 100%\nEvidence: The document is a research paper presented at the 37th Conference on Neural Information Processing Systems (NeurIPS 2023) by authors Rafael Rafailov, ...", "to": "field:cz_biohub", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "In order to validate the usage of GPT-4 for computing win rates, our human study collects human preference data for several matchups", "relation_type": "SUPPORTS", "source_name": "Direct Preference Optimization", "target_name": "human preference data", "title": "Direct Preference Optimization SUPPORTS human preference data\nConfidence: 100%\nEvidence: In order to validate the usage of GPT-4 for computing win rates, our human study collects human preference data for several matchups", "to": "finding:human_preference_data", "width": 2.5}, {"arrows": "to", "color": "#EF5350", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "DPO is simpler, more stable, and effective in aligning language models with human preferences compared to existing reinforcement learning from human feedback (RLHF) approaches.", "relation_type": "CONTRADICTS", "source_name": "Direct Preference Optimization", "target_name": "reinforcement learning", "title": "Direct Preference Optimization CONTRADICTS reinforcement learning\nConfidence: 100%\nEvidence: DPO is simpler, more stable, and effective in aligning language models with human preferences compared to existing reinforcement learning from human f...", "to": "method:reinforcement_learning", "width": 2.5}, {"arrows": "to", "color": "#AB47BC", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "DPO is simpler, more stable, and effective in aligning language models with human preferences compared to existing reinforcement learning from human feedback (RLHF) approaches.", "relation_type": "EXTENDS", "source_name": "Direct Preference Optimization", "target_name": "reinforcement learning", "title": "Direct Preference Optimization EXTENDS reinforcement learning\nConfidence: 100%\nEvidence: DPO is simpler, more stable, and effective in aligning language models with human preferences compared to existing reinforcement learning from human f...", "to": "method:reinforcement_learning", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "DPO is simpler, more stable, and effective in aligning language models with human preferences compared to existing reinforcement learning from human feedback (RLHF) approaches.", "relation_type": "SUPPORTS", "source_name": "Direct Preference Optimization", "target_name": "reinforcement learning", "title": "Direct Preference Optimization SUPPORTS reinforcement learning\nConfidence: 100%\nEvidence: DPO is simpler, more stable, and effective in aligning language models with human preferences compared to existing reinforcement learning from human f...", "to": "method:reinforcement_learning", "width": 2.5}, {"arrows": "to", "color": "#4CAF50", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "DPO is simpler, more stable, and effective in aligning language models with human preferences compared to existing reinforcement learning from human feedback (RLHF) approaches.", "relation_type": "EXPLAINS", "source_name": "Direct Preference Optimization", "target_name": "reinforcement learning", "title": "Direct Preference Optimization EXPLAINS reinforcement learning\nConfidence: 100%\nEvidence: DPO is simpler, more stable, and effective in aligning language models with human preferences compared to existing reinforcement learning from human f...", "to": "method:reinforcement_learning", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "method:direct_preference_optimization", "full_evidence": "DPO is simpler, more stable, and effective in aligning language models with human preferences compared to existing reinforcement learning from human feedback (RLHF) approaches.", "relation_type": "USES_METHOD", "source_name": "Direct Preference Optimization", "target_name": "reinforcement learning", "title": "Direct Preference Optimization USES_METHOD reinforcement learning\nConfidence: 100%\nEvidence: DPO is simpler, more stable, and effective in aligning language models with human preferences compared to existing reinforcement learning from human f...", "to": "method:reinforcement_learning", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "method:maximum_likelihood_estimation", "full_evidence": "we can parametrize a reward model and estimate the parameters via maximum likelihood.", "relation_type": "USES_METHOD", "source_name": "maximum likelihood estimation", "target_name": "Direct Preference Optimization", "title": "maximum likelihood estimation USES_METHOD Direct Preference Optimization\nConfidence: 100%\nEvidence: we can parametrize a reward model and estimate the parameters via maximum likelihood.", "to": "method:direct_preference_optimization", "width": 2.5}, {"arrows": "to", "color": "#78909C", "edge_confidence": 1.0, "from": "system:language_model", "full_evidence": "the policy network represents both the language model and the (implicit) reward.", "relation_type": "ASSOCIATED_WITH", "source_name": "language model", "target_name": "Direct Preference Optimization", "title": "language model ASSOCIATED_WITH Direct Preference Optimization\nConfidence: 100%\nEvidence: the policy network represents both the language model and the (implicit) reward.", "to": "method:direct_preference_optimization", "width": 2.5}, {"arrows": "to", "color": "#66BB6A", "edge_confidence": 1.0, "from": "method:best_of_n_baseline", "full_evidence": "We find that the Best of N baseline is a strong (although computationally expensive, requiring sampling many times) baseline in our experiments.", "relation_type": "SUPPORTS", "source_name": "Best of N baseline", "target_name": "Direct Preference Optimization", "title": "Best of N baseline SUPPORTS Direct Preference Optimization\nConfidence: 100%\nEvidence: We find that the Best of N baseline is a strong (although computationally expensive, requiring sampling many times) baseline in our experiments.", "to": "method:direct_preference_optimization", "width": 2.5}, {"arrows": "to", "color": "#42A5F5", "edge_confidence": 1.0, "from": "method:dpo_loss", "full_evidence": "We use the RMSprop optimizer with a learning rate of 1e-6 by default.", "relation_type": "USES_METHOD", "source_name": "DPO loss", "target_name": "RMSprop", "title": "DPO loss USES_METHOD RMSprop\nConfidence: 100%\nEvidence: We use the RMSprop optimizer with a learning rate of 1e-6 by default.", "to": "method:rmsprop", "width": 2.5}, {"arrows": "to", "color": "#7E57C2", "edge_confidence": 1.0, "from": "finding:human_preference_data", "full_evidence": "We sample 150 random comparisons of DPO vs PPO-0 and 100 random comparisons PPO-1 vs PPO-0, assigning two humans to each comparison", "relation_type": "INVESTIGATES", "source_name": "human preference data", "target_name": "GPT-2", "title": "human preference data INVESTIGATES GPT-2\nConfidence: 100%\nEvidence: We sample 150 random comparisons of DPO vs PPO-0 and 100 random comparisons PPO-1 vs PPO-0, assigning two humans to each comparison", "to": "system:gpt_2", "width": 2.5}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {"physics": {"forceAtlas2Based": {"gravitationalConstant": -350, "centralGravity": 0.002, "springLength": 400, "springConstant": 0.03, "damping": 0.4, "avoidOverlap": 0.9}, "solver": "forceAtlas2Based", "stabilization": {"enabled": true, "iterations": 300}, "enabled": true}, "edges": {"arrows": {"to": {"enabled": true, "scaleFactor": 0.4}}, "smooth": {"type": "curvedCW", "roundness": 0.1}, "color": {"opacity": 0.2}, "font": {"size": 0}}, "nodes": {"font": {"size": 0, "face": "Inter,sans-serif"}, "borderWidth": 1.5, "borderWidthSelected": 3}, "interaction": {"hover": true, "tooltipDelay": 999999, "zoomView": true, "dragView": true, "hideEdgesOnDrag": true, "hideEdgesOnZoom": true}};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  
                      network.on("stabilizationProgress", function(params) {
                          document.getElementById('loadingBar').removeAttribute("style");
                          var maxWidth = 496;
                          var minWidth = 20;
                          var widthFactor = params.iterations/params.total;
                          var width = Math.max(minWidth,maxWidth * widthFactor);
                          document.getElementById('bar').style.width = width + 'px';
                          document.getElementById('text').innerHTML = Math.round(widthFactor*100) + '%';
                      });
                      network.once("stabilizationIterationsDone", function() {
                          document.getElementById('text').innerHTML = '100%';
                          document.getElementById('bar').style.width = '496px';
                          document.getElementById('loadingBar').style.opacity = 0;
                          // really clean the dom element
                          setTimeout(function () {document.getElementById('loadingBar').style.display = 'none';}, 500);
                      });
                  

                  return network;

              }
              drawGraph();
        </script>
    
    <style>
        #sift-controls {
            position:fixed; top:12px; left:12px; z-index:999;
            background:rgba(26,26,46,0.95); border:1px solid #333;
            border-radius:10px; padding:14px 16px;
            font-family:Inter,system-ui,sans-serif; font-size:13px;
            color:#e0e0e0; width:320px;
            box-shadow: 0 4px 20px rgba(0,0,0,0.4);
            max-height: calc(100vh - 24px);
            overflow-y: auto;
        }
        #sift-controls::-webkit-scrollbar { width: 4px; }
        #sift-controls::-webkit-scrollbar-thumb { background: #444; border-radius: 2px; }
        .section-header {
            font-weight:600; margin:12px 0 6px; font-size:11px;
            color:#888; text-transform:uppercase; letter-spacing:0.5px;
            border-top: 1px solid #333; padding-top: 10px;
        }
        .section-header:first-of-type { border-top: none; margin-top: 6px; }
        .type-row {
            display:flex; align-items:center; gap:6px; margin:3px 0; cursor:pointer;
        }
        .type-row input[type="checkbox"] { margin:0; cursor:pointer; }
        .type-row input[type="color"] {
            width:18px; height:18px; border:none; padding:0;
            background:none; cursor:pointer; border-radius:3px;
        }
        .type-label { font-size:11px; white-space:nowrap; overflow:hidden; text-overflow:ellipsis; }
        #search-input {
            width:100%; padding:6px 10px; border-radius:6px;
            border:1px solid #444; background:#16213e;
            color:#e0e0e0; font-size:12px; margin-bottom:4px;
            box-sizing:border-box; outline:none;
        }
        #search-input:focus { border-color:#4FC3F7; }
        /* Detail sidebar */
        #detail-panel {
            position:fixed; top:0; right:0; z-index:998;
            width:320px; height:100vh;
            background:rgba(26,26,46,0.97); border-left:1px solid #333;
            font-family:Inter,system-ui,sans-serif; font-size:13px;
            color:#e0e0e0; display:none; flex-direction:column;
            overflow:hidden;
        }
        #detail-panel.open { display:flex; }
        #detail-header {
            padding:12px 14px; border-bottom:1px solid #333;
            display:flex; align-items:center; justify-content:space-between;
        }
        #detail-header h3 {
            margin:0; font-size:14px; font-weight:600; color:#fff;
            overflow:hidden; text-overflow:ellipsis; white-space:nowrap;
            max-width:240px;
        }
        #detail-close {
            background:none; border:none; color:#888; cursor:pointer;
            font-size:18px; padding:0 4px; line-height:1;
        }
        #detail-close:hover { color:#fff; }
        #detail-body {
            flex:1; overflow-y:auto; padding:12px 14px;
        }
        #detail-body::-webkit-scrollbar { width: 4px; }
        #detail-body::-webkit-scrollbar-thumb { background: #444; border-radius: 2px; }
        .d-field { margin-bottom:8px; }
        .d-label {
            font-size:10px; text-transform:uppercase; letter-spacing:0.5px;
            color:#666; margin-bottom:2px;
        }
        .d-val { font-size:13px; color:#e0e0e0; word-wrap:break-word; line-height:1.4; }
        .d-badge {
            display:inline-block; padding:2px 8px; border-radius:4px;
            font-size:11px; font-weight:600;
        }
        .d-conn {
            padding:5px 0; border-bottom:1px solid #2a2a3e;
            font-size:12px; cursor:pointer;
        }
        .d-conn:hover { color:#4FC3F7; }
        .d-conn.active { background:rgba(79,195,247,0.15); color:#4FC3F7; border-left:2px solid #4FC3F7; padding-left:6px; }
        .d-evidence {
            font-size:12px; color:#ccc; line-height:1.6;
            background:rgba(255,255,255,0.03); border-radius:6px;
            padding:10px 12px; border-left:3px solid #4FC3F7;
            white-space:pre-wrap;
        }
        /* Focus mode banner */
        #focus-banner {
            position:fixed; top:12px; left:50%; transform:translateX(-50%);
            z-index:1000; background:rgba(66,165,245,0.95);
            color:#fff; padding:8px 18px; border-radius:8px;
            font-family:Inter,system-ui,sans-serif; font-size:13px;
            font-weight:600; display:none; align-items:center; gap:10px;
            box-shadow:0 2px 12px rgba(0,0,0,0.3);
        }
        #focus-banner.visible { display:flex; }
        #focus-exit {
            background:none; border:none; color:#fff; cursor:pointer;
            font-size:18px; padding:0 2px; line-height:1; opacity:0.8;
        }
        #focus-exit:hover { opacity:1; }
    </style>
    <div id="sift-controls">
        <div style="font-weight:700;margin-bottom:10px;font-size:15px;color:#fff">sift-kg</div>
        <input id="search-input" type="text" placeholder="Search entities..." oninput="searchEntity(this.value)">

        <div style="margin:8px 0 4px">
            <label style="font-size:11px;color:#888">Min connections: <span id="deg-val">2</span></label>
            <input id="deg-slider" type="range" min="0" max="20" value="2" style="width:100%;margin:2px 0;accent-color:#4FC3F7" oninput="filterByDegree(this.value)">
        </div>

        <div class="section-header" style="border-top:none">Communities</div><div class="type-row"><input type="checkbox" checked data-community="Attention Mechanisms and Vision Models" onchange="toggleCommunity(this)"><span style="display:inline-block;width:12px;height:12px;border-radius:50%;background:#e86262;border:1px solid #555;flex-shrink:0"></span><span class="type-label">Attention Mechanisms and Vision Models</span></div><div class="type-row"><input type="checkbox" checked data-community="BERT and Language Model Fine-Tuning" onchange="toggleCommunity(this)"><span style="display:inline-block;width:12px;height:12px;border-radius:50%;background:#62e889;border:1px solid #555;flex-shrink:0"></span><span class="type-label">BERT and Language Model Fine-Tuning</span></div><div class="type-row"><input type="checkbox" checked data-community="Chain-of-Thought and Reasoning Techniques" onchange="toggleCommunity(this)"><span style="display:inline-block;width:12px;height:12px;border-radius:50%;background:#b062e8;border:1px solid #555;flex-shrink:0"></span><span class="type-label">Chain-of-Thought and Reasoning Techniques</span></div><div class="type-row"><input type="checkbox" checked data-community="Efficient Attention Mechanisms and Implementations" onchange="toggleCommunity(this)"><span style="display:inline-block;width:12px;height:12px;border-radius:50%;background:#e8d862;border:1px solid #555;flex-shrink:0"></span><span class="type-label">Efficient Attention Mechanisms and Implementations</span></div><div class="type-row"><input type="checkbox" checked data-community="Human Feedback and Reinforcement Learning" onchange="toggleCommunity(this)"><span style="display:inline-block;width:12px;height:12px;border-radius:50%;background:#62d2e8;border:1px solid #555;flex-shrink:0"></span><span class="type-label">Human Feedback and Reinforcement Learning</span></div><div class="type-row"><input type="checkbox" checked data-community="In-Context Learning and Bias Studies" onchange="toggleCommunity(this)"><span style="display:inline-block;width:12px;height:12px;border-radius:50%;background:#e862ab;border:1px solid #555;flex-shrink:0"></span><span class="type-label">In-Context Learning and Bias Studies</span></div><div class="type-row"><input type="checkbox" checked data-community="Language Model Pioneers and Publications" onchange="toggleCommunity(this)"><span style="display:inline-block;width:12px;height:12px;border-radius:50%;background:#84e862;border:1px solid #555;flex-shrink:0"></span><span class="type-label">Language Model Pioneers and Publications</span></div><div class="type-row"><input type="checkbox" checked data-community="Question Answering and Evaluation Datasets" onchange="toggleCommunity(this)"><span style="display:inline-block;width:12px;height:12px;border-radius:50%;background:#6862e8;border:1px solid #555;flex-shrink:0"></span><span class="type-label">Question Answering and Evaluation Datasets</span></div><div class="type-row"><input type="checkbox" checked data-community="Scaling Laws and Efficiency Research" onchange="toggleCommunity(this)"><span style="display:inline-block;width:12px;height:12px;border-radius:50%;background:#e88f62;border:1px solid #555;flex-shrink:0"></span><span class="type-label">Scaling Laws and Efficiency Research</span></div>

        <div class="section-header">Entity Types</div>
        <div class="type-row"><input type="checkbox" checked data-etype="CONCEPT" onchange="toggleEntityType(this)"><input type="color" value="#EF5350" data-etype-color="CONCEPT" onchange="changeEntityColor(this)"><span class="type-label">CONCEPT</span></div><div class="type-row"><input type="checkbox" checked data-etype="DATASET" onchange="toggleEntityType(this)"><input type="color" value="#FF7043" data-etype-color="DATASET" onchange="changeEntityColor(this)"><span class="type-label">DATASET</span></div><div class="type-row"><input type="checkbox" checked data-etype="FIELD" onchange="toggleEntityType(this)"><input type="color" value="#EC407A" data-etype-color="FIELD" onchange="changeEntityColor(this)"><span class="type-label">FIELD</span></div><div class="type-row"><input type="checkbox" checked data-etype="FINDING" onchange="toggleEntityType(this)"><input type="color" value="#FFA726" data-etype-color="FINDING" onchange="changeEntityColor(this)"><span class="type-label">FINDING</span></div><div class="type-row"><input type="checkbox" checked data-etype="METHOD" onchange="toggleEntityType(this)"><input type="color" value="#FFEE58" data-etype-color="METHOD" onchange="changeEntityColor(this)"><span class="type-label">METHOD</span></div><div class="type-row"><input type="checkbox" checked data-etype="PHENOMENON" onchange="toggleEntityType(this)"><input type="color" value="#66BB6A" data-etype-color="PHENOMENON" onchange="changeEntityColor(this)"><span class="type-label">PHENOMENON</span></div><div class="type-row"><input type="checkbox" checked data-etype="PUBLICATION" onchange="toggleEntityType(this)"><input type="color" value="#9CCC65" data-etype-color="PUBLICATION" onchange="changeEntityColor(this)"><span class="type-label">PUBLICATION</span></div><div class="type-row"><input type="checkbox" checked data-etype="RESEARCHER" onchange="toggleEntityType(this)"><input type="color" value="#AB47BC" data-etype-color="RESEARCHER" onchange="changeEntityColor(this)"><span class="type-label">RESEARCHER</span></div><div class="type-row"><input type="checkbox" checked data-etype="SYSTEM" onchange="toggleEntityType(this)"><input type="color" value="#26C6DA" data-etype-color="SYSTEM" onchange="changeEntityColor(this)"><span class="type-label">SYSTEM</span></div><div class="type-row"><input type="checkbox" checked data-etype="THEORY" onchange="toggleEntityType(this)"><input type="color" value="#42A5F5" data-etype-color="THEORY" onchange="changeEntityColor(this)"><span class="type-label">THEORY</span></div>

        <div class="section-header">Relation Types</div>
        <div class="type-row"><input type="checkbox" checked data-rtype="SUPPORTS" onchange="toggleRelationType(this)"><span class="type-label">SUPPORTS</span><span style="margin-left:auto;font-size:10px;color:#666;flex-shrink:0">120</span></div><div class="type-row"><input type="checkbox" checked data-rtype="PROPOSED_BY" onchange="toggleRelationType(this)"><span class="type-label">PROPOSED_BY</span><span style="margin-left:auto;font-size:10px;color:#666;flex-shrink:0">113</span></div><div class="type-row"><input type="checkbox" checked data-rtype="USES_METHOD" onchange="toggleRelationType(this)"><span class="type-label">USES_METHOD</span><span style="margin-left:auto;font-size:10px;color:#666;flex-shrink:0">89</span></div><div class="type-row"><input type="checkbox" checked data-rtype="APPLIED_TO" onchange="toggleRelationType(this)"><span class="type-label">APPLIED_TO</span><span style="margin-left:auto;font-size:10px;color:#666;flex-shrink:0">61</span></div><div class="type-row"><input type="checkbox" checked data-rtype="EXPLAINS" onchange="toggleRelationType(this)"><span class="type-label">EXPLAINS</span><span style="margin-left:auto;font-size:10px;color:#666;flex-shrink:0">50</span></div><div class="type-row"><input type="checkbox" checked data-rtype="INVESTIGATES" onchange="toggleRelationType(this)"><span class="type-label">INVESTIGATES</span><span style="margin-left:auto;font-size:10px;color:#666;flex-shrink:0">47</span></div><div class="type-row"><input type="checkbox" checked data-rtype="ASSOCIATED_WITH" onchange="toggleRelationType(this)"><span class="type-label">ASSOCIATED_WITH</span><span style="margin-left:auto;font-size:10px;color:#666;flex-shrink:0">43</span></div><div class="type-row"><input type="checkbox" checked data-rtype="EXTENDS" onchange="toggleRelationType(this)"><span class="type-label">EXTENDS</span><span style="margin-left:auto;font-size:10px;color:#666;flex-shrink:0">30</span></div><div class="type-row"><input type="checkbox" checked data-rtype="CONTRADICTS" onchange="toggleRelationType(this)"><span class="type-label">CONTRADICTS</span><span style="margin-left:auto;font-size:10px;color:#666;flex-shrink:0">29</span></div><div class="type-row"><input type="checkbox" checked data-rtype="IMPLEMENTS" onchange="toggleRelationType(this)"><span class="type-label">IMPLEMENTS</span><span style="margin-left:auto;font-size:10px;color:#666;flex-shrink:0">11</span></div>

        <div style="margin-top:12px;font-size:11px;color:#555;border-top:1px solid #333;padding-top:8px">
            413 entities &middot; 593 relations
        </div>
    </div>
    <div id="focus-banner">
        <span id="focus-label">Focused on: </span>
        <button id="focus-exit" onclick="exitFocusMode()">&times;</button>
    </div>
    <div id="detail-panel">
        <div id="detail-header">
            <h3 id="detail-title">Detail</h3>
            <button id="detail-close" onclick="closeDetail()">&times;</button>
        </div>
        <div id="detail-body"></div>
    </div>
    
    <script>
    var allNodes = nodes.get();
    var allEdges = edges.get();

    // --- Community region data ---
    var communityHulls = {};   // comm -> [{x,y}, ...] padded convex hull points
    var communityCentroids = {}; // comm -> {x, y}
    var communityColors = {"Attention Mechanisms and Vision Models": "#e86262", "BERT and Language Model Fine-Tuning": "#62e889", "Chain-of-Thought and Reasoning Techniques": "#b062e8", "Efficient Attention Mechanisms and Implementations": "#e8d862", "Human Feedback and Reinforcement Learning": "#62d2e8", "In-Context Learning and Bias Studies": "#e862ab", "Language Model Pioneers and Publications": "#84e862", "Question Answering and Evaluation Datasets": "#6862e8", "Scaling Laws and Efficiency Research": "#e88f62"};

    // Convex hull (Graham scan)
    function convexHull(points) {
        if (points.length < 3) return points.slice();
        points.sort(function(a, b) { return a.x === b.x ? a.y - b.y : a.x - b.x; });
        var lower = [];
        for (var i = 0; i < points.length; i++) {
            while (lower.length >= 2 && cross(lower[lower.length - 2], lower[lower.length - 1], points[i]) <= 0) lower.pop();
            lower.push(points[i]);
        }
        var upper = [];
        for (var i = points.length - 1; i >= 0; i--) {
            while (upper.length >= 2 && cross(upper[upper.length - 2], upper[upper.length - 1], points[i]) <= 0) upper.pop();
            upper.push(points[i]);
        }
        upper.pop(); lower.pop();
        return lower.concat(upper);
    }
    function cross(o, a, b) { return (a.x - o.x) * (b.y - o.y) - (a.y - o.y) * (b.x - o.x); }

    // Pad hull outward from centroid
    function padHull(hull, cx, cy, padding) {
        return hull.map(function(p) {
            var dx = p.x - cx, dy = p.y - cy;
            var dist = Math.sqrt(dx * dx + dy * dy) || 1;
            return { x: p.x + (dx / dist) * padding, y: p.y + (dy / dist) * padding };
        });
    }

    function computeCommunityRegions() {
        var positions = network.getPositions();
        var commPoints = {};
        allNodes.forEach(function(n) {
            if (!n.community) return;
            var p = positions[n.id];
            if (!p) return;
            if (!commPoints[n.community]) commPoints[n.community] = [];
            commPoints[n.community].push({ x: p.x, y: p.y });
        });
        communityHulls = {};
        communityCentroids = {};
        for (var comm in commPoints) {
            var pts = commPoints[comm];
            // Centroid
            var cx = 0, cy = 0;
            for (var i = 0; i < pts.length; i++) { cx += pts[i].x; cy += pts[i].y; }
            cx /= pts.length; cy /= pts.length;
            communityCentroids[comm] = { x: cx, y: cy };
            // Hull with padding
            if (pts.length < 3) {
                communityHulls[comm] = padHull(pts, cx, cy, 80);
            } else {
                var hull = convexHull(pts);
                communityHulls[comm] = padHull(hull, cx, cy, 80);
            }
        }
    }

    network.once('stabilizationIterationsDone', function() {
        network.setOptions({ physics: { enabled: false } });
        computeCommunityRegions();
    });

    // Draw filled community regions BEHIND nodes
    network.on('beforeDrawing', function(ctx) {
        if (focusedNodeId !== null) return;
        for (var comm in communityHulls) {
            var hull = communityHulls[comm];
            if (hull.length < 2) continue;
            var color = communityColors[comm] || '#ffffff';
            var r = parseInt(color.slice(1,3), 16);
            var g = parseInt(color.slice(3,5), 16);
            var b = parseInt(color.slice(5,7), 16);

            ctx.save();
            ctx.beginPath();
            // Draw smooth rounded hull using quadratic curves
            if (hull.length === 2) {
                ctx.moveTo(hull[0].x, hull[0].y);
                ctx.lineTo(hull[1].x, hull[1].y);
            } else {
                // Start at midpoint of first edge
                var mx = (hull[0].x + hull[hull.length - 1].x) / 2;
                var my = (hull[0].y + hull[hull.length - 1].y) / 2;
                ctx.moveTo(mx, my);
                for (var i = 0; i < hull.length; i++) {
                    var next = (i + 1) % hull.length;
                    var mx2 = (hull[i].x + hull[next].x) / 2;
                    var my2 = (hull[i].y + hull[next].y) / 2;
                    ctx.quadraticCurveTo(hull[i].x, hull[i].y, mx2, my2);
                }
            }
            ctx.closePath();
            ctx.fillStyle = 'rgba(' + r + ',' + g + ',' + b + ',0.08)';
            ctx.fill();
            ctx.strokeStyle = 'rgba(' + r + ',' + g + ',' + b + ',0.25)';
            ctx.lineWidth = 1;
            ctx.stroke();
            ctx.restore();
        }
    });

    // Draw community labels ON TOP of nodes  scale-compensated
    network.on('afterDrawing', function(ctx) {
        if (focusedNodeId !== null) return;
        var scale = network.getScale();
        var fontSize = Math.round(16 / scale);
        var strokeW = Math.max(2, Math.round(3 / scale));
        for (var comm in communityCentroids) {
            var pos = communityCentroids[comm];
            var color = communityColors[comm] || '#ffffff';
            ctx.save();
            ctx.font = '700 ' + fontSize + 'px Inter, system-ui, sans-serif';
            ctx.textAlign = 'center';
            ctx.textBaseline = 'middle';
            ctx.strokeStyle = '#1a1a2e';
            ctx.lineWidth = strokeW;
            ctx.lineJoin = 'round';
            ctx.strokeText(comm, pos.x, pos.y);
            ctx.fillStyle = color;
            ctx.fillText(comm, pos.x, pos.y);
            ctx.restore();
        }
    });

    var hiddenEntityTypes = new Set();
    var hiddenRelationTypes = new Set();
    var hiddenCommunities = new Set();
    var focusedNodeId = null;
    var focusConnIndex = -1;
    var focusHistory = [];

    // --- Detail sidebar ---
    var dp = document.getElementById('detail-panel');
    var dt = document.getElementById('detail-title');
    var db = document.getElementById('detail-body');

    function esc(s) {
        var d = document.createElement('div');
        d.textContent = String(s);
        return d.innerHTML;
    }

    function closeDetail() { dp.classList.remove('open'); }

    function focusNode(nid) {
        network.focus(nid, { scale: 1.5, animation: { duration: 400 } });
        network.selectNodes([nid]);
        showNodeDetail(nid);
    }

    // event delegation for clickable connections
    db.addEventListener('click', function(ev) {
        var el = ev.target.closest('[data-nid]');
        if (el) focusNode(el.getAttribute('data-nid'));
    });

    network.on('click', function(params) {
        if (focusedNodeId !== null && params.nodes && params.nodes.length > 0) {
            // In focus mode: click neighbor to shift focus
            focusHistory.push(focusedNodeId);
            enterFocusMode(params.nodes[0]);
            return;
        }
        if (focusedNodeId !== null && (!params.nodes || params.nodes.length === 0) && (!params.edges || params.edges.length === 0)) {
            // Click empty canvas  exit focus
            exitFocusMode();
            return;
        }
        if (params.nodes && params.nodes.length > 0) {
            showNodeDetail(params.nodes[0]);
        } else if (params.edges && params.edges.length > 0) {
            showEdgeDetail(params.edges[0]);
        }
    });

    function showNodeDetail(nodeId) {
        var node = nodes.get(nodeId);
        if (!node) return;
        dt.textContent = node.full_name || node.label || nodeId;
        dp.classList.add('open');

        // gather connections
        var conns = [];
        allEdges.forEach(function(e) {
            if (e.from === nodeId) conns.push({ rel: e.relation_type, name: e.target_name || e.to, dir: '\u2192', nid: e.to });
            if (e.to === nodeId) conns.push({ rel: e.relation_type, name: e.source_name || e.from, dir: '\u2190', nid: e.from });
        });
        conns.sort(function(a, b) { return a.rel.localeCompare(b.rel); });
        window._conns = conns;

        var h = '';
        // type
        var tc = node.color || '#B0BEC5';
        if (typeof tc === 'object') tc = tc.background || '#B0BEC5';
        h += '<div class="d-field"><div class="d-label">Type</div>';
        h += '<span class="d-badge" style="background:' + esc(tc) + ';color:#1a1a2e">' + esc(node.entity_type || 'UNKNOWN') + '</span></div>';

        // community
        if (node.community) {
            h += '<div class="d-field"><div class="d-label">Community</div>';
            h += '<div class="d-val">' + esc(node.community) + '</div></div>';
        }

        // narrative description
        if (node.description) {
            h += '<div class="d-field"><div class="d-label">Description</div>';
            h += '<div class="d-evidence">' + esc(node.description) + '</div></div>';
        }

        // parse tooltip fields
        var lines = (node.title || '').split('\n');
        for (var i = 1; i < lines.length; i++) {
            var ln = lines[i].trim();
            if (!ln) continue;
            if (ln.startsWith('Community:')) continue;
            var ci = ln.indexOf(': ');
            if (ci > 0) {
                h += '<div class="d-field"><div class="d-label">' + esc(ln.substring(0, ci)) + '</div>';
                h += '<div class="d-val">' + esc(ln.substring(ci + 2)) + '</div></div>';
            }
        }

        // unique relation types for filter
        var relTypes = [];
        var seen = {};
        for (var r = 0; r < conns.length; r++) {
            if (!seen[conns[r].rel]) { relTypes.push(conns[r].rel); seen[conns[r].rel] = true; }
        }
        relTypes.sort();

        // filter select + connections header
        h += '<div class="d-field" style="margin-top:14px">';
        h += '<div class="d-label">Connections (' + conns.length + ')</div>';
        if (relTypes.length > 1) {
            h += '<select id="conn-filter" onchange="filterConns(this.value)" style="width:100%;padding:4px 6px;margin:4px 0 6px;border-radius:4px;border:1px solid #444;background:#16213e;color:#e0e0e0;font-size:11px;outline:none">';
            h += '<option value="">All types</option>';
            for (var t = 0; t < relTypes.length; t++) {
                var cnt = conns.filter(function(c){ return c.rel === relTypes[t]; }).length;
                h += '<option value="' + esc(relTypes[t]) + '">' + esc(relTypes[t]) + ' (' + cnt + ')</option>';
            }
            h += '</select>';
        }
        h += '<div id="conn-list"></div></div>';

        db.innerHTML = h;
        filterConns('');
    }

    function filterConns(relFilter) {
        var list = document.getElementById('conn-list');
        if (!list) return;
        var conns = window._conns || [];
        var h = '';
        var shown = 0;
        for (var j = 0; j < conns.length; j++) {
            var c = conns[j];
            if (relFilter && c.rel !== relFilter) continue;
            shown++;
            h += '<div class="d-conn" data-nid="' + esc(c.nid) + '">';
            h += '<span style="color:#888;font-size:10px;text-transform:uppercase">' + esc(c.dir + ' ' + c.rel) + '</span><br>';
            h += '<span>' + esc(c.name) + '</span></div>';
        }
        list.innerHTML = h;
    }

    function showEdgeDetail(edgeId) {
        var edge = edges.get(edgeId);
        if (!edge) return;
        var rt = edge.relation_type || 'UNKNOWN';
        dt.textContent = rt;
        dp.classList.add('open');

        var ec = edge.color || '#555';
        if (typeof ec === 'object') ec = ec.color || '#555';

        var h = '';
        h += '<div class="d-field"><span class="d-badge" style="background:' + esc(ec) + ';color:#1a1a2e">' + esc(rt) + '</span></div>';
        h += '<div class="d-field"><div class="d-label">From</div>';
        h += '<div class="d-val" style="cursor:pointer;color:#4FC3F7" data-nid="' + esc(edge.from) + '">' + esc(edge.source_name || edge.from) + '</div></div>';
        h += '<div class="d-field"><div class="d-label">To</div>';
        h += '<div class="d-val" style="cursor:pointer;color:#4FC3F7" data-nid="' + esc(edge.to) + '">' + esc(edge.target_name || edge.to) + '</div></div>';

        if (edge.edge_confidence) {
            h += '<div class="d-field"><div class="d-label">Confidence</div>';
            h += '<div class="d-val">' + Math.round(edge.edge_confidence * 100) + '%</div></div>';
        }
        if (edge.full_evidence) {
            h += '<div class="d-field"><div class="d-label">Evidence</div>';
            h += '<div class="d-evidence">' + esc(edge.full_evidence) + '</div></div>';
        }
        db.innerHTML = h;
    }

    // --- Entity type toggle ---
    function toggleEntityType(cb) {
        var type = cb.dataset.etype;
        if (cb.checked) hiddenEntityTypes.delete(type);
        else hiddenEntityTypes.add(type);
        applyFilters();
    }

    // --- Community toggle ---
    function toggleCommunity(cb) {
        var comm = cb.dataset.community;
        if (cb.checked) hiddenCommunities.delete(comm);
        else hiddenCommunities.add(comm);
        applyFilters();
    }

    // --- Relation type toggle ---
    function toggleRelationType(cb) {
        var type = cb.dataset.rtype;
        if (cb.checked) hiddenRelationTypes.delete(type);
        else hiddenRelationTypes.add(type);
        applyEdgeFilters();
    }

    // --- Entity color picker ---
    function changeEntityColor(input) {
        var type = input.dataset.etypeColor;
        var color = input.value;
        var updates = [];
        allNodes.forEach(function(n) {
            if (n.entity_type === type) {
                var c = n.color;
                var border = (typeof c === 'object' && c.border) ? c.border : '#333';
                updates.push({ id: n.id, color: { background: color, border: border, highlight: { background: color, border: border } } });
            }
        });
        nodes.update(updates);
        allNodes = nodes.get();
    }

    function applyFilters() {
        var updates = [];
        allNodes.forEach(function(node) {
            var hidden = hiddenEntityTypes.has(node.entity_type) ||
                         (node.community && hiddenCommunities.has(node.community)) ||
                         (node.node_degree || 0) < minDegree;
            updates.push({ id: node.id, hidden: hidden });
        });
        nodes.update(updates);
    }

    function applyEdgeFilters() {
        var updates = [];
        allEdges.forEach(function(edge) {
            updates.push({ id: edge.id, hidden: hiddenRelationTypes.has(edge.relation_type) });
        });
        edges.update(updates);
    }

    // --- Degree filter ---
    var minDegree = 2;
    function filterByDegree(val) {
        minDegree = parseInt(val, 10);
        document.getElementById('deg-val').textContent = minDegree;
        applyFilters();
    }

    // --- Startup: apply smart defaults ---
    (function() {
        // MENTIONED_IN starts unchecked  add to hidden set
        var mentionedCb = document.querySelector('[data-rtype="MENTIONED_IN"]');
        if (mentionedCb && !mentionedCb.checked) {
            hiddenRelationTypes.add('MENTIONED_IN');
        }
        applyEdgeFilters();
        applyFilters();
    })();

    // --- Search ---
    function searchEntity(query) {
        if (!query || query.length < 2) {
            var reset = allNodes.map(function(n) {
                return { id: n.id, opacity: 1.0, font: { size: 0 }, borderWidth: n.community ? 2 : 1.5 };
            });
            nodes.update(reset);
            return;
        }
        query = query.toLowerCase();
        var matchIds = new Set();
        allNodes.forEach(function(n) {
            var name = (n.full_name || n.label || '').toLowerCase();
            var als = (n.aliases || '').toLowerCase();
            if (name.includes(query) || als.includes(query)) matchIds.add(n.id);
        });
        var neighborIds = new Set();
        allEdges.forEach(function(e) {
            if (matchIds.has(e.from)) neighborIds.add(e.to);
            if (matchIds.has(e.to)) neighborIds.add(e.from);
        });
        var updates = allNodes.map(function(n) {
            if (matchIds.has(n.id))
                return { id: n.id, opacity: 1.0, font: { size: 18, color: '#ffffff' }, borderWidth: 3 };
            else if (neighborIds.has(n.id))
                return { id: n.id, opacity: 0.8, font: { size: 12 }, borderWidth: n.community ? 2 : 1.5 };
            else
                return { id: n.id, opacity: 0.1, font: { size: 0 }, borderWidth: 1 };
        });
        nodes.update(updates);
        if (matchIds.size > 0) {
            network.focus(matchIds.values().next().value, { scale: 1.5, animation: { duration: 500 } });
        }
    }

    // --- Focus mode (ego-graph explorer) ---
    function formatRelLabel(rt) {
        return rt.toLowerCase().replace(/_/g, ' ');
    }

    network.on('doubleClick', function(params) {
        if (params.nodes && params.nodes.length > 0) {
            enterFocusMode(params.nodes[0]);
        }
    });

    document.addEventListener('keydown', function(ev) {
        if (ev.key === 'Escape') {
            exitFocusMode();
            return;
        }
        if (focusedNodeId === null) return;
        var rows = document.querySelectorAll('#conn-list .d-conn');
        if (!rows.length) return;

        if (ev.key === 'ArrowDown' || ev.key === 'ArrowUp') {
            ev.preventDefault();
            if (ev.key === 'ArrowDown') focusConnIndex = Math.min(focusConnIndex + 1, rows.length - 1);
            else focusConnIndex = focusConnIndex - 1;
            if (focusConnIndex < 0) {
                // Back to full neighborhood view
                focusConnIndex = -1;
                rows.forEach(function(r) { r.classList.remove('active'); });
                var restoreId = focusedNodeId;
                focusedNodeId = null;  // clear so enterFocusMode guard allows re-entry
                enterFocusMode(restoreId);
                return;
            }
            highlightConn(focusConnIndex);
        } else if (ev.key === 'ArrowRight' || ev.key === 'Enter') {
            ev.preventDefault();
            if (focusConnIndex >= 0 && focusConnIndex < rows.length) {
                focusHistory.push(focusedNodeId);
                enterFocusMode(rows[focusConnIndex].getAttribute('data-nid'));
            }
        } else if (ev.key === 'Backspace' || ev.key === 'Delete' || ev.key === 'ArrowLeft') {
            ev.preventDefault();
            if (focusHistory.length > 0) {
                var prevId = focusHistory.pop();
                focusedNodeId = null;
                enterFocusMode(prevId);
            }
        }
    });

    function highlightConn(idx) {
        var rows = document.querySelectorAll('#conn-list .d-conn');
        rows.forEach(function(r, i) { r.classList.toggle('active', i === idx); });
        if (rows[idx]) rows[idx].scrollIntoView({ block: 'nearest', behavior: 'smooth' });
        if (idx < 0 || idx >= rows.length) return;
        var c = { nid: rows[idx].getAttribute('data-nid') };

        network.selectNodes([c.nid]);

        // Find neighbor's adjacents, ranked by degree  cap at 10
        var adjList = [];
        var adjDeg = {};
        allEdges.forEach(function(e) {
            var other = null;
            if (e.from === c.nid && e.to !== focusedNodeId) other = e.to;
            if (e.to === c.nid && e.from !== focusedNodeId) other = e.from;
            if (other && !adjDeg[other]) {
                adjDeg[other] = 0;
                adjList.push(other);
            }
            if (other) adjDeg[other]++;
        });
        adjList.sort(function(a, b) {
            var da = 0, db = 0;
            allNodes.forEach(function(n) {
                if (n.id === a) da = n.node_degree || 0;
                if (n.id === b) db = n.node_degree || 0;
            });
            return db - da;
        });
        var MAX_ADJ = 10;
        var adjIds = new Set(adjList.slice(0, MAX_ADJ));

        // Nodes: primary pair full, adjacents ghosted
        var nodeUpdates = [];
        allNodes.forEach(function(n) {
            var isPrimary = n.id === focusedNodeId || n.id === c.nid;
            var isAdj = adjIds.has(n.id);
            nodeUpdates.push({ id: n.id, hidden: !(isPrimary || isAdj), opacity: isAdj ? 0.35 : 1.0 });
        });
        nodes.update(nodeUpdates);

        // Edges: primary thick + labeled, adjacent thin + unlabeled
        var edgeUpdates = [];
        allEdges.forEach(function(e) {
            var isPrimary = (e.from === focusedNodeId && e.to === c.nid) || (e.to === focusedNodeId && e.from === c.nid);
            var isAdj = (e.from === c.nid && adjIds.has(e.to)) || (e.to === c.nid && adjIds.has(e.from));
            var show = (isPrimary || isAdj) && !hiddenRelationTypes.has(e.relation_type);
            edgeUpdates.push({
                id: e.id,
                hidden: !show,
                color: { opacity: isPrimary ? 0.9 : 0.4 },
                label: isPrimary ? formatRelLabel(e.relation_type) : '',
                width: isPrimary ? 4 : 1
            });
        });
        edges.update(edgeUpdates);

        // Camera: center on PRIMARY PAIR only, adjacents are peripheral
        var positions = network.getPositions([focusedNodeId, c.nid]);
        var p1 = positions[focusedNodeId];
        var p2 = positions[c.nid];
        var midX = (p1.x + p2.x) / 2;
        var midY = (p1.y + p2.y) / 2;

        var pad = 250;
        var rangeX = Math.abs(p1.x - p2.x) + pad * 2;
        var rangeY = Math.abs(p1.y - p2.y) + pad * 2;

        var canvasEl = network.canvas.frame.canvas;
        var totalW = canvasEl.clientWidth;
        var totalH = canvasEl.clientHeight;
        var leftW = 352;
        var rightW = dp.classList.contains('open') ? 320 : 0;
        var visW = totalW - leftW - rightW;
        var visH = totalH - 80;

        var scale = Math.min(visW / rangeX, visH / rangeY, 1.5);

        var visCenterPx = leftW + visW / 2;
        var shiftPx = visCenterPx - totalW / 2;

        network.moveTo({
            position: { x: midX - shiftPx / scale, y: midY },
            scale: scale,
            animation: { duration: 300, easingFunction: 'easeInOutQuad' }
        });

        // Fonts: primary pair large + white, adjacents small + dim
        (function() {
            var nodeFontSize = Math.round(20 / scale);
            var adjFontSize = Math.round(9 / scale);
            var edgeFontSize = Math.round(16 / scale);
            var strokeW = Math.max(3, Math.round(3 / scale));

            var fontUpdatesN = [];
            allNodes.forEach(function(n) {
                if (n.id === focusedNodeId || n.id === c.nid) {
                    fontUpdatesN.push({ id: n.id, font: { size: nodeFontSize, color: '#ffffff', strokeWidth: strokeW, strokeColor: '#1a1a2e' } });
                } else if (adjIds.has(n.id)) {
                    fontUpdatesN.push({ id: n.id, font: { size: adjFontSize, color: '#555555', strokeWidth: strokeW, strokeColor: '#1a1a2e' } });
                }
            });
            nodes.update(fontUpdatesN);

            var fontUpdatesE = [];
            allEdges.forEach(function(e) {
                var isPrimary = (e.from === focusedNodeId && e.to === c.nid) || (e.to === focusedNodeId && e.from === c.nid);
                if (isPrimary && !hiddenRelationTypes.has(e.relation_type)) {
                    fontUpdatesE.push({ id: e.id, font: { size: edgeFontSize, color: '#ffffff', strokeWidth: strokeW, strokeColor: '#1a1a2e' } });
                }
            });
            edges.update(fontUpdatesE);
        })();
    }

    // --- Overview hover preview: show name + highlight connections ---
    var overviewHoveredId = null;
    network.on('hoverNode', function(params) {
        if (focusedNodeId !== null) return;  // focus mode handles its own display
        var nid = params.node;
        overviewHoveredId = nid;
        var scale = network.getScale();
        var labelSize = Math.round(12 / scale);
        var neighborSize = Math.round(9 / scale);
        var strokeW = Math.max(2, Math.round(2 / scale));

        // Find connected neighbors
        var neighborIds = new Set();
        var connEdgeIds = new Set();
        allEdges.forEach(function(e) {
            if (e.from === nid) { neighborIds.add(e.to); connEdgeIds.add(e.id); }
            if (e.to === nid) { neighborIds.add(e.from); connEdgeIds.add(e.id); }
        });

        // Show hovered node label + dim neighbor labels
        var nodeUpdates = [];
        nodeUpdates.push({ id: nid, font: { size: labelSize, color: '#ffffff', strokeWidth: strokeW, strokeColor: '#1a1a2e' } });
        neighborIds.forEach(function(id) {
            nodeUpdates.push({ id: id, font: { size: neighborSize, color: '#999999', strokeWidth: strokeW, strokeColor: '#1a1a2e' } });
        });
        nodes.update(nodeUpdates);

        // Brighten connected edges
        var edgeUpdates = [];
        connEdgeIds.forEach(function(eid) {
            edgeUpdates.push({ id: eid, color: { opacity: 0.7 } });
        });
        edges.update(edgeUpdates);
    });

    network.on('blurNode', function(params) {
        if (focusedNodeId !== null) return;
        if (overviewHoveredId === null) return;
        overviewHoveredId = null;

        // Reset all node fonts to 0 (overview default)
        var nodeResets = [];
        allNodes.forEach(function(n) {
            nodeResets.push({ id: n.id, font: { size: 0 } });
        });
        nodes.update(nodeResets);

        // Reset all edge opacities
        var edgeResets = [];
        allEdges.forEach(function(e) {
            edgeResets.push({ id: e.id, color: { opacity: 0.2 } });
        });
        edges.update(edgeResets);
    });

    // Hover-to-reveal edge labels in focus mode (for dense neighborhoods)
    network.on('hoverEdge', function(params) {
        if (focusedNodeId === null) return;
        if (focusConnIndex >= 0) return;  // pair view has its own labels
        var e = edges.get(params.edge);
        if (e) {
            edges.update({ id: e.id, font: { size: 12, color: '#fff', strokeWidth: 3, strokeColor: '#1a1a2e' }, label: formatRelLabel(e.relation_type) });
        }
    });
    network.on('blurEdge', function(params) {
        if (focusedNodeId === null) return;
        if (focusConnIndex >= 0) return;
        var e = edges.get(params.edge);
        if (!e) return;
        edges.update({ id: e.id, font: { size: 0 }, label: '' });
    });

    function enterFocusMode(nodeId) {
        if (focusedNodeId === nodeId && focusConnIndex < 0) return;  // already in neighborhood view
        overviewHoveredId = null;  // clear any hover preview state
        focusedNodeId = nodeId;
        var node = nodes.get(nodeId);
        if (!node) return;

        // Show banner
        var banner = document.getElementById('focus-banner');
        document.getElementById('focus-label').textContent = 'Focused on: ' + (node.full_name || node.label || nodeId);
        banner.classList.add('visible');

        // Find all 1-hop neighbors, ranked by degree
        var allNeighbors = [];
        var neighborDeg = {};
        var connectedEdgeIds = new Set();
        allEdges.forEach(function(e) {
            if (e.from === nodeId) { connectedEdgeIds.add(e.id); if (!neighborDeg[e.to]) { neighborDeg[e.to] = 0; allNeighbors.push(e.to); } neighborDeg[e.to]++; }
            if (e.to === nodeId) { connectedEdgeIds.add(e.id); if (!neighborDeg[e.from]) { neighborDeg[e.from] = 0; allNeighbors.push(e.from); } neighborDeg[e.from]++; }
        });

        // Sort by global degree, cap visible neighbors for dense hubs
        allNeighbors.sort(function(a, b) {
            var da = 0, db = 0;
            allNodes.forEach(function(n) { if (n.id === a) da = n.node_degree || 0; if (n.id === b) db = n.node_degree || 0; });
            return db - da;
        });
        var MAX_NEIGHBORS = 25;
        var visibleNeighbors = new Set(allNeighbors.slice(0, MAX_NEIGHBORS));
        visibleNeighbors.add(nodeId);

        // Show top neighbors, hide rest
        var nodeUpdates = [];
        allNodes.forEach(function(n) {
            var isVisible = visibleNeighbors.has(n.id);
            var isFocused = n.id === nodeId;
            var belowDegree = (n.node_degree || 0) < minDegree;
            nodeUpdates.push({ id: n.id, hidden: !isVisible || (!isFocused && belowDegree), opacity: 1.0, font: { size: 14, color: '#e0e0e0' } });
        });
        nodes.update(nodeUpdates);

        // Count parallel edges per node pair to offset curves
        var pairCount = {};
        var pairIndex = {};
        allEdges.forEach(function(e) {
            if (!connectedEdgeIds.has(e.id)) return;
            var key = [e.from, e.to].sort().join('||');
            if (!pairCount[key]) pairCount[key] = 0;
            pairIndex[e.id] = pairCount[key];
            pairCount[key]++;
        });

        // Show static edge labels only for small neighborhoods
        var showStaticLabels = visibleNeighbors.size <= 20;

        // Show edges only to visible neighbors
        var edgeUpdates = [];
        allEdges.forEach(function(e) {
            if (connectedEdgeIds.has(e.id)) {
                var other = e.from === nodeId ? e.to : e.from;
                if (!visibleNeighbors.has(other)) {
                    edgeUpdates.push({ id: e.id, hidden: true });
                    return;
                }
                var key = [e.from, e.to].sort().join('||');
                var total = pairCount[key] || 1;
                var idx = pairIndex[e.id] || 0;
                var roundness = total > 1 ? 0.15 + idx * 0.2 : 0.1;
                edgeUpdates.push({
                    id: e.id,
                    hidden: hiddenRelationTypes.has(e.relation_type),
                    color: { opacity: 0.6 },
                    font: { size: showStaticLabels ? 11 : 0, color: '#ccc', strokeWidth: 3, strokeColor: '#1a1a2e' },
                    label: showStaticLabels ? formatRelLabel(e.relation_type) : '',
                    smooth: { type: 'curvedCW', roundness: roundness }
                });
            } else {
                edgeUpdates.push({ id: e.id, hidden: true });
            }
        });
        edges.update(edgeUpdates);

        focusConnIndex = -1;

        // Sidebar-aware camera fit
        var fitIds = [];
        visibleNeighbors.forEach(function(nid) { fitIds.push(nid); });
        var positions = network.getPositions(fitIds);
        var minX = Infinity, maxX = -Infinity, minY = Infinity, maxY = -Infinity;
        fitIds.forEach(function(nid) {
            var p = positions[nid];
            if (!p) return;
            if (p.x < minX) minX = p.x;
            if (p.x > maxX) maxX = p.x;
            if (p.y < minY) minY = p.y;
            if (p.y > maxY) maxY = p.y;
        });
        var midX = (minX + maxX) / 2;
        var midY = (minY + maxY) / 2;

        var pad = 150;
        var rangeX = (maxX - minX) + pad * 2;
        var rangeY = (maxY - minY) + pad * 2;

        var canvasEl = network.canvas.frame.canvas;
        var totalW = canvasEl.clientWidth;
        var totalH = canvasEl.clientHeight;
        var leftW = 352;
        var rightW = dp.classList.contains('open') ? 320 : 0;
        var visW = totalW - leftW - rightW;
        var visH = totalH - 80;

        var scale = Math.min(visW / rangeX, visH / rangeY, 1.2);

        var visCenterPx = leftW + visW / 2;
        var shiftPx = visCenterPx - totalW / 2;

        network.moveTo({
            position: { x: midX - shiftPx / scale, y: midY },
            scale: scale,
            animation: { duration: 400, easingFunction: 'easeInOutQuad' }
        });

        // After camera settles, apply scale-aware labels on top neighbors
        setTimeout(function() {
            var s = network.getScale();
            var fontSize = Math.round(14 / s);
            var strokeW = Math.max(2, Math.round(2 / s));

            // Label top 15 by degree + focused node
            var maxLabeled = 15;
            var labeledSet = new Set();
            labeledSet.add(nodeId);
            for (var i = 0; i < Math.min(maxLabeled, allNeighbors.length); i++) {
                if (visibleNeighbors.has(allNeighbors[i])) labeledSet.add(allNeighbors[i]);
            }

            var updates = [];
            allNodes.forEach(function(n) {
                if (visibleNeighbors.has(n.id)) {
                    var show = labeledSet.has(n.id);
                    updates.push({ id: n.id, font: { size: show ? fontSize : 0, color: '#e0e0e0', strokeWidth: strokeW, strokeColor: '#1a1a2e' } });
                }
            });
            nodes.update(updates);
        }, 450);

        showNodeDetail(nodeId);
    }

    function exitFocusMode() {
        if (focusedNodeId === null) {
            closeDetail();
            return;
        }
        focusedNodeId = null;
        focusConnIndex = -1;
        focusHistory = [];

        // Hide banner
        document.getElementById('focus-banner').classList.remove('visible');

        // Restore all nodes per current filters + reset fonts to overview (no labels)
        applyFilters();
        var fontResets = [];
        allNodes.forEach(function(n) {
            fontResets.push({ id: n.id, font: { size: 0, color: '#e0e0e0' }, opacity: 1.0 });
        });
        nodes.update(fontResets);

        // Restore edges  re-apply edge filters, reset labels and curves
        var edgeUpdates = [];
        allEdges.forEach(function(e) {
            edgeUpdates.push({
                id: e.id,
                hidden: hiddenRelationTypes.has(e.relation_type),
                color: { opacity: 0.2 },
                font: { size: 0 },
                label: '',
                smooth: { type: 'curvedCW', roundness: 0.1 }
            });
        });
        edges.update(edgeUpdates);

        // Fit camera back to full graph
        network.fit({ animation: { duration: 400, easingFunction: 'easeInOutQuad' } });
    }
    </script>
    </body>
</html>